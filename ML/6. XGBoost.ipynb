{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53c5300f",
   "metadata": {},
   "source": [
    "# Import bibliotek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb05258f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import *\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from operator import itemgetter\n",
    "import time\n",
    "from xgboost import XGBRegressor\n",
    "import typing\n",
    "SEED = 17"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081f343b",
   "metadata": {},
   "source": [
    "# Ładowanie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d7509bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pages</th>\n",
       "      <th>stars</th>\n",
       "      <th>reviews</th>\n",
       "      <th>series</th>\n",
       "      <th>mix</th>\n",
       "      <th>character</th>\n",
       "      <th>plot</th>\n",
       "      <th>funny</th>\n",
       "      <th>lighthearted</th>\n",
       "      <th>emotional</th>\n",
       "      <th>...</th>\n",
       "      <th>author_stars</th>\n",
       "      <th>Fiction</th>\n",
       "      <th>Nonfiction</th>\n",
       "      <th>Literary</th>\n",
       "      <th>Fantasy</th>\n",
       "      <th>Crime</th>\n",
       "      <th>Social</th>\n",
       "      <th>Children</th>\n",
       "      <th>Romans</th>\n",
       "      <th>Realism</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>273</td>\n",
       "      <td>4.00</td>\n",
       "      <td>2017</td>\n",
       "      <td>0</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.91</td>\n",
       "      <td>...</td>\n",
       "      <td>4.305000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>302</td>\n",
       "      <td>3.78</td>\n",
       "      <td>7330</td>\n",
       "      <td>0</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.18</td>\n",
       "      <td>...</td>\n",
       "      <td>3.670000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>400</td>\n",
       "      <td>4.15</td>\n",
       "      <td>16761</td>\n",
       "      <td>0</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.88</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>459</td>\n",
       "      <td>4.16</td>\n",
       "      <td>2128</td>\n",
       "      <td>1</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>160</td>\n",
       "      <td>3.65</td>\n",
       "      <td>6634</td>\n",
       "      <td>1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>4.115000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6925</th>\n",
       "      <td>432</td>\n",
       "      <td>4.15</td>\n",
       "      <td>30643</td>\n",
       "      <td>0</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.40</td>\n",
       "      <td>...</td>\n",
       "      <td>3.856667</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6926</th>\n",
       "      <td>352</td>\n",
       "      <td>3.62</td>\n",
       "      <td>1058</td>\n",
       "      <td>0</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6927</th>\n",
       "      <td>535</td>\n",
       "      <td>3.88</td>\n",
       "      <td>30975</td>\n",
       "      <td>1</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.31</td>\n",
       "      <td>...</td>\n",
       "      <td>3.870000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6928</th>\n",
       "      <td>472</td>\n",
       "      <td>3.88</td>\n",
       "      <td>5914</td>\n",
       "      <td>1</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.36</td>\n",
       "      <td>...</td>\n",
       "      <td>3.660000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6929</th>\n",
       "      <td>350</td>\n",
       "      <td>4.27</td>\n",
       "      <td>67909</td>\n",
       "      <td>0</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.78</td>\n",
       "      <td>...</td>\n",
       "      <td>4.315833</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6930 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pages  stars  reviews  series   mix  character  plot  funny  \\\n",
       "0       273   4.00     2017       0  0.44       0.51  0.02   0.27   \n",
       "1       302   3.78     7330       0  0.39       0.42  0.17   0.03   \n",
       "2       400   4.15    16761       0  0.51       0.39  0.08   0.02   \n",
       "3       459   4.16     2128       1  0.48       0.10  0.40   0.04   \n",
       "4       160   3.65     6634       1  0.28       0.16  0.54   0.92   \n",
       "...     ...    ...      ...     ...   ...        ...   ...    ...   \n",
       "6925    432   4.15    30643       0  0.48       0.05  0.46   0.00   \n",
       "6926    352   3.62     1058       0  0.55       0.13  0.30   0.15   \n",
       "6927    535   3.88    30975       1  0.45       0.08  0.45   0.14   \n",
       "6928    472   3.88     5914       1  0.64       0.12  0.22   0.07   \n",
       "6929    350   4.27    67909       0  0.37       0.56  0.05   0.74   \n",
       "\n",
       "      lighthearted  emotional  ...  author_stars  Fiction  Nonfiction  \\\n",
       "0             0.37       0.91  ...      4.305000        1           1   \n",
       "1             0.01       0.18  ...      3.670000        1           0   \n",
       "2             0.01       0.88  ...      0.000000        1           0   \n",
       "3             0.02       0.07  ...      0.000000        1           0   \n",
       "4             0.73       0.00  ...      4.115000        1           0   \n",
       "...            ...        ...  ...           ...      ...         ...   \n",
       "6925          0.00       0.40  ...      3.856667        1           0   \n",
       "6926          0.10       0.25  ...      3.700000        1           0   \n",
       "6927          0.19       0.31  ...      3.870000        1           0   \n",
       "6928          0.00       0.36  ...      3.660000        1           0   \n",
       "6929          0.28       0.78  ...      4.315833        1           0   \n",
       "\n",
       "      Literary  Fantasy  Crime  Social  Children  Romans  Realism  \n",
       "0            0        0      0       1         0       1        1  \n",
       "1            0        0      1       0         0       0        0  \n",
       "2            1        0      0       0         0       0        0  \n",
       "3            0        1      0       0         0       0        0  \n",
       "4            0        1      0       0         0       0        0  \n",
       "...        ...      ...    ...     ...       ...     ...      ...  \n",
       "6925         0        1      1       0         0       0        0  \n",
       "6926         0        1      0       1         0       0        0  \n",
       "6927         0        1      0       0         1       0        0  \n",
       "6928         0        1      0       0         1       0        0  \n",
       "6929         1        0      1       0         0       0        1  \n",
       "\n",
       "[6930 rows x 32 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv(\"../data/data_eda.csv\")\n",
    "data=data.drop(columns=['Unnamed: 0'])\n",
    "features=data.columns.tolist()\n",
    "features.remove('stars')\n",
    "target='stars'\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea67d23",
   "metadata": {},
   "source": [
    "$\\text{Podział danych na zbiór treningowy i testowy}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8dc49010",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52706254",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_cv(X: pd.DataFrame, y: pd.Series, algorithm: typing.Any, cv: typing.Any = KFold(n_splits=5, shuffle=True, random_state=SEED), metric: typing.Any = mean_squared_error) -> typing.List[float]:\n",
    "    \"\"\"\n",
    "    Perform cross-validation and return list of scores\n",
    "    \n",
    "    Args:\n",
    "        X (pd.DataFrame): input data\n",
    "        y (pd.Series): target data\n",
    "        algorithm (typing.Any): algorithm to use for training and prediction\n",
    "        cv (typing.Any): cross-validation strategy\n",
    "        metric (typing.Any): metric to use for evaluation\n",
    "    \n",
    "    Returns:\n",
    "        typing.List[float]: list of scores in order: train_scores, validation_scores\n",
    "    \"\"\"\n",
    "    train_scores = []\n",
    "    validation_scores = []\n",
    "    for train_idx, val_idx in cv.split(X, y):\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "        algorithm.fit(X_train, y_train)\n",
    "        y_train_pred = algorithm.predict(X_train)\n",
    "        y_val_pred = algorithm.predict(X_val)\n",
    "        train_scores.append(metric(y_train, y_train_pred, squared=False))\n",
    "        validation_scores.append(metric(y_val, y_val_pred, squared=False))\n",
    "    return np.mean(train_scores), np.mean(validation_scores)\n",
    "\n",
    "def evaluation(X_train: pd.DataFrame, y_train: pd.Series, X_test: pd.DataFrame, y_test: pd.Series, algorithm: typing.Any, metric: typing.Any = mean_squared_error) -> typing.Tuple[float, float, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Train the algorithm on the train data and evaluate on the train and test data\n",
    "    \n",
    "    Args:\n",
    "        X_train (pd.DataFrame): input train data\n",
    "        y_train (pd.Series): target train data\n",
    "        X_test (pd.DataFrame): input test data\n",
    "        y_test (pd.Series): target test data\n",
    "        algorithm (typing.Any): algorithm to use for training and prediction\n",
    "        metric (typing.Any): metric to use for evaluation\n",
    "    \n",
    "    Returns:\n",
    "        typing.Tuple[float, float, np.ndarray]: train_score, test_score, predictions on test data\n",
    "    \"\"\"\n",
    "    algorithm.fit(X_train, y_train)\n",
    "    y_train_pred = algorithm.predict(X_train)\n",
    "    y_test_pred = algorithm.predict(X_test)\n",
    "    train_results = metric(y_train, y_train_pred, squared=False)\n",
    "    test_results = metric(y_test, y_test_pred, squared=False)\n",
    "    return train_results, test_results, y_test_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79754d13",
   "metadata": {},
   "source": [
    "## Model bez feature engineeringu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65a77600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 0.06206850002022659\n",
      "Validation RMSE: 0.19808813044143286\n"
     ]
    }
   ],
   "source": [
    "model = XGBRegressor(random_state=SEED, n_jobs=-1)\n",
    "train_scores, validation_scores = perform_cv(train_data[features], train_data[target], model)\n",
    "print(\"Train RMSE:\", train_scores)\n",
    "print(\"Validation RMSE:\", validation_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38152c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 0.0716487447885672 Valid RMSE: 0.19973691488499062\n",
      "Train RMSE: 0.07188839435902632 Valid RMSE: 0.19262187347958723\n",
      "Train RMSE: 0.07570376617210013 Valid RMSE: 0.19117966471671766\n",
      "Train RMSE: 0.07493703710297953 Valid RMSE: 0.20097964298490753\n",
      "Train RMSE: 0.0729050190576533 Valid RMSE: 0.19670199834049415\n",
      "0.19624401888133944\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "features=[]\n",
    "df=pd.DataFrame()\n",
    "def CVTestXGB(nFolds = 5, randomState=2024, debug=False, features=features, *args, **kwargs):\n",
    "    kf = KFold(n_splits=nFolds, shuffle=True, random_state=randomState)\n",
    "    # Listy z wynikami\n",
    "    testResults = []\n",
    "    trainResults = []\n",
    "    predictions = []\n",
    "    indices = []\n",
    "    # Pętla walidująca model na kolejnych foldach\n",
    "    for train, test in kf.split(df.index.values):\n",
    "        # Przygotowanie estymatora\n",
    "        clf = XGBRegressor(*args, **kwargs)\n",
    "        # Trenowanie modelu\n",
    "        clf.fit(df.iloc[train][features], df.iloc[train][target])\n",
    "        # Przygotowanie prognoz dla zbioru treningowego i testowego\n",
    "        predsTrain = clf.predict(df.iloc[train][features])\n",
    "        preds = clf.predict(df.iloc[test][features])\n",
    "        # Zachowajmy informacje o predykcjach dla tego foldu\n",
    "        predictions.append(preds.tolist().copy())\n",
    "        # Razem z indeksami w oryginalnym data frame\n",
    "        indices.append(df.iloc[test].index.tolist().copy())\n",
    "        # Policzenie RMSE dla foldów\n",
    "        trainScore = metrics.mean_squared_error(df.iloc[train][target], predsTrain)**0.5\n",
    "        testScore = metrics.mean_squared_error(df.iloc[test][target], preds)**0.5\n",
    "        # Zapisanie wyników dla foldów\n",
    "        trainResults.append(trainScore)\n",
    "        testResults.append(testScore)\n",
    "        # Informowanie o każdym foldzie razem z wynikami treningowymi możemy opcjonalnie wyświetlać w trakcie\n",
    "        if debug:\n",
    "            print(\"Train RMSE:\", trainScore,\n",
    "                  \"Valid RMSE:\", testScore)\n",
    "        \n",
    "    return trainResults, testResults, predictions, indices\n",
    "df=pd.read_csv(\"../data/data_eda.csv\")\n",
    "df=df.drop(columns=['Unnamed: 0'])\n",
    "features=df.columns.tolist()\n",
    "features.remove('stars')\n",
    "target='stars'\n",
    "trainResults, testResults, predictions, indices = CVTestXGB(nFolds=5, randomState=SEED, debug=True, features=features)\n",
    "print(np.mean(testResults))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29758061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19624401888133944\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(testResults))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9faed461",
   "metadata": {},
   "source": [
    "## Model z interakcjami"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea050cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 0.05993165594028156\n",
      "Validation RMSE: 0.19920281798639167\n"
     ]
    }
   ],
   "source": [
    "data_interactions=pd.read_csv(\"../data/data_add.csv\")\n",
    "data_interactions=data_interactions.drop(columns=['Unnamed: 0'])\n",
    "features_interactions=data_interactions.columns.tolist()\n",
    "features_interactions.remove('stars')\n",
    "train_data_interactions, test_data_interactions = train_test_split(data_interactions, test_size=0.2, random_state=SEED)\n",
    "model = XGBRegressor(random_state=SEED, n_jobs=-1)\n",
    "train_scores, validation_scores = perform_cv(train_data_interactions[features_interactions], train_data_interactions[target], model)\n",
    "print(\"Train RMSE:\", train_scores)\n",
    "print(\"Validation RMSE:\", validation_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b6c6ba",
   "metadata": {},
   "source": [
    "## Model z transformacją zmiennych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8e13ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 0.06740134432400799\n",
      "Validation RMSE: 0.20647785102519228\n"
     ]
    }
   ],
   "source": [
    "data_transformations=pd.read_csv(\"../data/data_fe.csv\")\n",
    "data_transformations=data_transformations.drop(columns=['Unnamed: 0'])\n",
    "features_transformations=data_transformations.columns.tolist()\n",
    "features_transformations.remove('stars')\n",
    "train_data_transformations, test_data_transformations = train_test_split(data_transformations, test_size=0.2, random_state=SEED)\n",
    "model = XGBRegressor(random_state=SEED, n_jobs=-1)\n",
    "train_scores, validation_scores = perform_cv(train_data_transformations[features_transformations], train_data_transformations[target], model)\n",
    "print(\"Train RMSE:\", train_scores)\n",
    "print(\"Validation RMSE:\", validation_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ea5e0d",
   "metadata": {},
   "source": [
    "Widzimy, że dla takiego silnego modelu najlepszy jest zbiór danych bez interakcji i transformacji zmiennych."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387f9f97",
   "metadata": {},
   "source": [
    "Moc predykcji jest już lepsza od poprzedni modeli, ale postramy się ją poprawić poprzez tuning parametrów"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da759da3",
   "metadata": {},
   "source": [
    "# Tuning hiperparametrów XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955b1969",
   "metadata": {},
   "source": [
    "1. Głębokość drzewa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80060a2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max depth: 3; RMSE train: 0.15472; RMSE validation: 0.19491\n",
      "Max depth: 4; RMSE train: 0.12600; RMSE validation: 0.19312\n",
      "Max depth: 5; RMSE train: 0.09536; RMSE validation: 0.19459\n",
      "Max depth: 6; RMSE train: 0.06207; RMSE validation: 0.19809\n",
      "Max depth: 7; RMSE train: 0.03479; RMSE validation: 0.20041\n",
      "Max depth: 8; RMSE train: 0.01770; RMSE validation: 0.20327\n",
      "Max depth: 9; RMSE train: 0.00741; RMSE validation: 0.20310\n"
     ]
    }
   ],
   "source": [
    "for max_depth in range(3, 10):\n",
    "    model = XGBRegressor(max_depth=max_depth, random_state=SEED, n_jobs=-1)\n",
    "    train_scores, validation_scores = perform_cv(train_data[features], train_data[target], model)\n",
    "    print(\"Max depth: {}; RMSE train: {:.5f}; RMSE validation: {:.5f}\".format(max_depth, train_scores, validation_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755ce00b",
   "metadata": {},
   "source": [
    "Najlepszy wynik dla głębokości drzewa równej 4."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0afce0e",
   "metadata": {},
   "source": [
    "2. Subsample - udział wierszy w każdym drzewie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24f80d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subsample: 0.1; RMSE train: 0.19885; RMSE validation: 0.24957\n",
      "Subsample: 0.2; RMSE train: 0.15881; RMSE validation: 0.21682\n",
      "Subsample: 0.3; RMSE train: 0.14388; RMSE validation: 0.20719\n",
      "Subsample: 0.4; RMSE train: 0.13536; RMSE validation: 0.20277\n",
      "Subsample: 0.5; RMSE train: 0.13084; RMSE validation: 0.19711\n",
      "Subsample: 0.6; RMSE train: 0.12781; RMSE validation: 0.19553\n",
      "Subsample: 0.7; RMSE train: 0.12618; RMSE validation: 0.19329\n",
      "Subsample: 0.8; RMSE train: 0.12556; RMSE validation: 0.19357\n",
      "Subsample: 0.9; RMSE train: 0.12407; RMSE validation: 0.19385\n",
      "Subsample: 1.0; RMSE train: 0.12600; RMSE validation: 0.19312\n"
     ]
    }
   ],
   "source": [
    "for subsample in np.linspace(0.1, 1, 10):\n",
    "    model = XGBRegressor(max_depth=4, subsample=subsample, random_state=SEED, n_jobs=-1)\n",
    "    train_scores, validation_scores = perform_cv(train_data[features], train_data[target], model)\n",
    "    print(\"Subsample: {:.1f}; RMSE train: {:.5f}; RMSE validation: {:.5f}\".format(subsample, train_scores, validation_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8a1aa1",
   "metadata": {},
   "source": [
    "Najlepszy wynik w sytuacji, gdy wszystkie wiersze są brane pod uwagę."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8066cd40",
   "metadata": {},
   "source": [
    "3. colsample_bytree - udział kolumn w każdym drzewie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "293a4f03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colsample by tree: 0.1; RMSE train: 0.15362; RMSE validation: 0.20193\n",
      "Colsample by tree: 0.2; RMSE train: 0.13970; RMSE validation: 0.19617\n",
      "Colsample by tree: 0.3; RMSE train: 0.13433; RMSE validation: 0.19445\n",
      "Colsample by tree: 0.4; RMSE train: 0.13239; RMSE validation: 0.19290\n",
      "Colsample by tree: 0.5; RMSE train: 0.12923; RMSE validation: 0.19258\n",
      "Colsample by tree: 0.6; RMSE train: 0.12884; RMSE validation: 0.19227\n",
      "Colsample by tree: 0.7; RMSE train: 0.12931; RMSE validation: 0.19349\n",
      "Colsample by tree: 0.8; RMSE train: 0.12784; RMSE validation: 0.19324\n",
      "Colsample by tree: 0.9; RMSE train: 0.12784; RMSE validation: 0.19362\n",
      "Colsample by tree: 1.0; RMSE train: 0.12600; RMSE validation: 0.19312\n"
     ]
    }
   ],
   "source": [
    "for colsample_bytree in np.linspace(0.1, 1, 10):\n",
    "    model = XGBRegressor(max_depth=4, subsample=1, colsample_bytree=colsample_bytree, random_state=SEED, n_jobs=-1)\n",
    "    train_scores, validation_scores = perform_cv(train_data[features], train_data[target], model)\n",
    "    print(\"Colsample by tree: {:.1f}; RMSE train: {:.5f}; RMSE validation: {:.5f}\".format(colsample_bytree, train_scores, validation_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3d60cf",
   "metadata": {},
   "source": [
    "Rezultaty sugerują, że procent kolumn w każdym drzewie powinien wynosić 50%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd5e67c",
   "metadata": {},
   "source": [
    "4. colsample_bylevel - udział kolumn w każdym poziomie drzewa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ba1955c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colsample by level: 0.1; RMSE train: 0.16347; RMSE validation: 0.20246\n",
      "Colsample by level: 0.2; RMSE train: 0.14417; RMSE validation: 0.19405\n",
      "Colsample by level: 0.3; RMSE train: 0.14062; RMSE validation: 0.19257\n",
      "Colsample by level: 0.4; RMSE train: 0.13757; RMSE validation: 0.19230\n",
      "Colsample by level: 0.5; RMSE train: 0.13594; RMSE validation: 0.19357\n",
      "Colsample by level: 0.6; RMSE train: 0.13452; RMSE validation: 0.19401\n",
      "Colsample by level: 0.7; RMSE train: 0.13347; RMSE validation: 0.19309\n",
      "Colsample by level: 0.8; RMSE train: 0.13220; RMSE validation: 0.19251\n",
      "Colsample by level: 0.9; RMSE train: 0.13093; RMSE validation: 0.19405\n",
      "Colsample by level: 1.0; RMSE train: 0.12923; RMSE validation: 0.19258\n"
     ]
    }
   ],
   "source": [
    "for colsample_bylevel in np.linspace(0.1, 1, 10):\n",
    "    model = XGBRegressor(max_depth=4, subsample=1, colsample_bytree=0.5, colsample_bylevel=colsample_bylevel, random_state=SEED, n_jobs=-1)\n",
    "    train_scores, validation_scores = perform_cv(train_data[features], train_data[target], model)\n",
    "    print(\"Colsample by level: {:.1f}; RMSE train: {:.5f}; RMSE validation: {:.5f}\".format(colsample_bylevel, train_scores, validation_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630532fb",
   "metadata": {},
   "source": [
    "Najlepszy wynik dla 40% kolumn w każdym poziomie drzewa."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe5b014",
   "metadata": {},
   "source": [
    "Widzimy, że jednak nadal wynik na zbiorze treningowym znacząco lepszy niż testowym, więc dostosujemy parametry regularyzacji."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc8df56",
   "metadata": {},
   "source": [
    "# Regularyzacja"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3fba348",
   "metadata": {},
   "source": [
    "Tutaj poszukamy parametru lambda (regularyzacja L2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8843ad2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lambda: 0.01; RMSE train: 0.13391; RMSE validation: 0.19529\n",
      "Lambda: 0.10; RMSE train: 0.13402; RMSE validation: 0.19592\n",
      "Lambda: 0.50; RMSE train: 0.13565; RMSE validation: 0.19428\n",
      "Lambda: 1.00; RMSE train: 0.13757; RMSE validation: 0.19230\n",
      "Lambda: 2.00; RMSE train: 0.13879; RMSE validation: 0.19299\n",
      "Lambda: 4.00; RMSE train: 0.14111; RMSE validation: 0.19171\n",
      "Lambda: 6.00; RMSE train: 0.14290; RMSE validation: 0.19272\n",
      "Lambda: 8.00; RMSE train: 0.14382; RMSE validation: 0.19092\n",
      "Lambda: 10.00; RMSE train: 0.14474; RMSE validation: 0.19269\n",
      "Lambda: 15.00; RMSE train: 0.14815; RMSE validation: 0.19250\n",
      "Lambda: 30.00; RMSE train: 0.15239; RMSE validation: 0.19227\n",
      "Lambda: 50.00; RMSE train: 0.15684; RMSE validation: 0.19330\n",
      "Lambda: 100.00; RMSE train: 0.16278; RMSE validation: 0.19533\n"
     ]
    }
   ],
   "source": [
    "for lambda_ in [0.01, 0.1, 0.5, 1, 2, 4, 6, 8, 10, 15, 30, 50, 100]:\n",
    "    model = XGBRegressor(max_depth=4, subsample=1, colsample_bytree=0.5, colsample_bylevel=0.4, reg_lambda=lambda_, random_state=SEED, n_jobs=-1)\n",
    "    train_scores, validation_scores = perform_cv(train_data[features], train_data[target], model)\n",
    "    print(\"Lambda: {:.2f}; RMSE train: {:.5f}; RMSE validation: {:.5f}\".format(lambda_, train_scores, validation_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e61456",
   "metadata": {},
   "source": [
    "Wraz ze wzrostem wartości lambda, wynik na zbiorze treningowym ulegają pogorszeniu.\n",
    "\n",
    "Najlepszy wynik dla zbioru walidacyjnego otrzymano dla wartości lambda równej 8."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134dd82b",
   "metadata": {},
   "source": [
    "Możemy dokładniej sprawdzić wyniki dla wartości lambda z przedziału [6, 10]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "95b61c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lambda: 6.00; RMSE train: 0.14290; RMSE validation: 0.19272\n",
      "Lambda: 6.50; RMSE train: 0.14207; RMSE validation: 0.19193\n",
      "Lambda: 7.00; RMSE train: 0.14284; RMSE validation: 0.19237\n",
      "Lambda: 7.50; RMSE train: 0.14335; RMSE validation: 0.19262\n",
      "Lambda: 8.00; RMSE train: 0.14382; RMSE validation: 0.19092\n",
      "Lambda: 8.50; RMSE train: 0.14426; RMSE validation: 0.19148\n",
      "Lambda: 9.00; RMSE train: 0.14452; RMSE validation: 0.19193\n",
      "Lambda: 9.50; RMSE train: 0.14409; RMSE validation: 0.19287\n",
      "Lambda: 10.00; RMSE train: 0.14474; RMSE validation: 0.19269\n"
     ]
    }
   ],
   "source": [
    "for lambda_ in [6, 6.5, 7, 7.5, 8, 8.5, 9, 9.5, 10]:\n",
    "    model = XGBRegressor(max_depth=4, subsample=1, colsample_bytree=0.5, colsample_bylevel=0.4, reg_lambda=lambda_, random_state=SEED, n_jobs=-1)\n",
    "    train_scores, validation_scores = perform_cv(train_data[features], train_data[target], model)\n",
    "    print(\"Lambda: {:.2f}; RMSE train: {:.5f}; RMSE validation: {:.5f}\".format(lambda_, train_scores, validation_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fdab4876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lambda: 7.50; RMSE train: 0.14335; RMSE validation: 0.19262\n",
      "Lambda: 7.60; RMSE train: 0.14363; RMSE validation: 0.19154\n",
      "Lambda: 7.70; RMSE train: 0.14355; RMSE validation: 0.19284\n",
      "Lambda: 7.80; RMSE train: 0.14346; RMSE validation: 0.19218\n",
      "Lambda: 7.90; RMSE train: 0.14365; RMSE validation: 0.19093\n",
      "Lambda: 8.00; RMSE train: 0.14382; RMSE validation: 0.19092\n",
      "Lambda: 8.10; RMSE train: 0.14376; RMSE validation: 0.19177\n",
      "Lambda: 8.20; RMSE train: 0.14413; RMSE validation: 0.19084\n",
      "Lambda: 8.30; RMSE train: 0.14431; RMSE validation: 0.19219\n",
      "Lambda: 8.40; RMSE train: 0.14381; RMSE validation: 0.19134\n",
      "Lambda: 8.50; RMSE train: 0.14426; RMSE validation: 0.19148\n"
     ]
    }
   ],
   "source": [
    "for lambda_ in np.linspace(7.5, 8.5, 11):\n",
    "    model = XGBRegressor(max_depth=4, subsample=1, colsample_bytree=0.5, colsample_bylevel=0.4, reg_lambda=lambda_, random_state=SEED, n_jobs=-1)\n",
    "    train_scores, validation_scores = perform_cv(train_data[features], train_data[target], model)\n",
    "    print(\"Lambda: {:.2f}; RMSE train: {:.5f}; RMSE validation: {:.5f}\".format(lambda_, train_scores, validation_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4232e7",
   "metadata": {},
   "source": [
    "Najlepsze wyniki dla lambda równego 8."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920eccce",
   "metadata": {},
   "source": [
    "Gamma to kolejny parametr regularyzacji, który określa minimalną redukcję strat wymaganą do utworzenia nowego liścia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dcfe647b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gamma: 0.00; RMSE train: 0.14382; RMSE validation: 0.19092\n",
      "Gamma: 0.01; RMSE train: 0.14362; RMSE validation: 0.19228\n",
      "Gamma: 0.10; RMSE train: 0.15066; RMSE validation: 0.19182\n",
      "Gamma: 0.50; RMSE train: 0.18415; RMSE validation: 0.20153\n",
      "Gamma: 1.00; RMSE train: 0.20019; RMSE validation: 0.21019\n",
      "Gamma: 2.00; RMSE train: 0.21285; RMSE validation: 0.21891\n",
      "Gamma: 5.00; RMSE train: 0.22834; RMSE validation: 0.23259\n"
     ]
    }
   ],
   "source": [
    "for gamma in [0, 0.01, 0.1, 0.5, 1, 2, 5]:\n",
    "    model = XGBRegressor(max_depth=4, subsample=1, colsample_bytree=0.5, colsample_bylevel=0.4, reg_lambda=8, gamma=gamma, random_state=SEED, n_jobs=-1)\n",
    "    train_scores, validation_scores = perform_cv(train_data[features], train_data[target], model)\n",
    "    print(\"Gamma: {:.2f}; RMSE train: {:.5f}; RMSE validation: {:.5f}\".format(gamma, train_scores, validation_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37daa600",
   "metadata": {},
   "source": [
    "Jak jednak widać, wzrost parametru gamma prowadzi do znacznych spadków wyników dla zarówno zbioru treningowego i walidacyjnego.\n",
    "\n",
    "Tym samym zachowana zostanie domyślna wartość gamma - 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5593d71",
   "metadata": {},
   "source": [
    "## Selekcja zmiennych"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c9f616",
   "metadata": {},
   "source": [
    "Do selekcji zmiennych wykorzystany "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4ebc67c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import typing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import NearestNeighbors, KDTree\n",
    "from scipy.special import digamma\n",
    "\n",
    "class MutualInformation:\n",
    "    \"\"\"Class for calculating mutual information between features and target.\"\"\"\n",
    "\n",
    "    def __init__(self, n_neighbors: int = 3, random_state: int = 17) -> None:\n",
    "        \"\"\"Initialize the class.\n",
    "\n",
    "        Args:\n",
    "            n_neighbors (int, default=3): number of neighbors to consider for continuous features.\n",
    "            random_state (int, default=17): random seed for reproducibility.\n",
    "        \"\"\"\n",
    "        self.n_neighbors_ = n_neighbors\n",
    "        self.random_state_ = random_state\n",
    "        np.random.seed(17)\n",
    "\n",
    "    def check_X(\n",
    "        self, X: typing.Union[pd.DataFrame, pd.Series, np.ndarray]\n",
    "    ) -> np.ndarray:\n",
    "        \"\"\"Check if X is pandas DataFrame, pandas Series or numpy array and convert it to numpy array.\n",
    "\n",
    "        Args:\n",
    "            X: (Union[pd.DataFrame, pd.Series, np.ndarray]): input data.\n",
    "\n",
    "        Returns:\n",
    "            X: (np.ndarray): converted input data.\n",
    "        \"\"\"\n",
    "        if (\n",
    "            not isinstance(X, pd.DataFrame)\n",
    "            and not isinstance(X, pd.Series)\n",
    "            and not isinstance(X, np.ndarray)\n",
    "        ):\n",
    "            raise TypeError(\n",
    "                \"Wrong type of X. It should be pandas DataFrame, pandas Series, numpy array.\"\n",
    "            )\n",
    "        X = np.array(X)\n",
    "        if X.ndim == 1:\n",
    "            X = X[None, :]\n",
    "        return X\n",
    "\n",
    "    def check_y(\n",
    "        self, y: typing.Union[pd.DataFrame, pd.Series, np.ndarray]\n",
    "    ) -> np.ndarray:\n",
    "        \"\"\"Check if y is pandas DataFrame, pandas Series or numpy array and convert it to numpy array.\n",
    "\n",
    "        Args:\n",
    "            y: (Union[pd.DataFrame, pd.Series, np.ndarray]): target data.\n",
    "\n",
    "        Returns:\n",
    "            y: (np.ndarray): converted target data.\n",
    "        \"\"\"\n",
    "        if (\n",
    "            not isinstance(y, pd.DataFrame)\n",
    "            and not isinstance(y, pd.Series)\n",
    "            and not isinstance(y, np.ndarray)\n",
    "        ):\n",
    "            raise TypeError(\n",
    "                \"Wrong type of y. It should be pandas DataFrame, pandas Series, numpy array.\"\n",
    "            )\n",
    "        y = np.array(y)\n",
    "        if y.ndim != 1:\n",
    "            y = y.squeeze()\n",
    "        return y\n",
    "\n",
    "    def check_discrete_features(\n",
    "        self,\n",
    "        X: np.ndarray,\n",
    "        discrete_features: typing.Union[bool, np.ndarray, typing.List],\n",
    "    ) -> np.ndarray:\n",
    "        \"\"\"Check if discrete_features is bool, numpy array or list and convert it to numpy array.\n",
    "\n",
    "        Args:\n",
    "            X: (np.ndarray): input data.\n",
    "            discrete_features: (Union[bool, np.ndarray, List]): discrete features.\n",
    "\n",
    "        Returns:\n",
    "            discrete_features: (np.ndarray): converted discrete features.\n",
    "        \"\"\"\n",
    "        if (\n",
    "            not isinstance(discrete_features, bool)\n",
    "            and not isinstance(discrete_features, np.ndarray)\n",
    "            and not isinstance(discrete_features, typing.List)\n",
    "        ):\n",
    "            raise TypeError(\n",
    "                \"Wrong type of discrete_features. It should be bool, numpy array or List.\"\n",
    "            )\n",
    "        if isinstance(discrete_features, np.ndarray) or isinstance(\n",
    "            discrete_features, typing.List\n",
    "        ):\n",
    "            if len(discrete_features) > X.shape[1]:\n",
    "                raise ValueError(\n",
    "                    \"Length of discrete_features list should be less or equal to the number of features in X.\"\n",
    "                )\n",
    "            if all(isinstance(i, np.bool_) for i in discrete_features):\n",
    "                print(\"A\")\n",
    "                return np.array(discrete_features)\n",
    "            return np.array(\n",
    "                [True if i in discrete_features else False for i in range(X.shape[1])]\n",
    "            )\n",
    "        elif discrete_features == True:\n",
    "            return np.array([True for i in range(X.shape[1])])\n",
    "        return np.array([False for i in range(X.shape[1])])\n",
    "\n",
    "    def check_discrete_target(self, target_discrete: bool) -> bool:\n",
    "        \"\"\"Check if target_discrete is bool.\n",
    "\n",
    "        Args:\n",
    "            target_discrete: (bool): target type.\n",
    "\n",
    "        Returns:\n",
    "            target_discrete: (bool): target type.\n",
    "        \"\"\"\n",
    "        if not isinstance(target_discrete, bool):\n",
    "            raise TypeError(\"Wrong type of target_discrete. It should be bool.\")\n",
    "        return target_discrete\n",
    "\n",
    "    def fit(\n",
    "        self,\n",
    "        X: typing.Union[pd.DataFrame, pd.Series, np.ndarray],\n",
    "        y: typing.Union[pd.DataFrame, pd.Series, np.ndarray],\n",
    "        discrete_features: typing.Union[bool, np.ndarray, typing.List],\n",
    "        target_discrete: bool = True,\n",
    "    ) -> np.ndarray:\n",
    "        \"\"\"Calculate mutual information between features and target.\n",
    "\n",
    "        Args:\n",
    "            X: (Union[pd.DataFrame, pd.Series, np.ndarray]): input data.\n",
    "            y: (Union[pd.DataFrame, pd.Series, np.ndarray]): target data.\n",
    "            discrete_features: (Union[bool, np.ndarray, List]): discrete features.\n",
    "            target_discrete: (bool, default=True): target type.\n",
    "\n",
    "        Returns:\n",
    "            (np.ndarray): mutual information between features and target.\n",
    "        \"\"\"\n",
    "        X = self.check_X(X=X)\n",
    "        y = self.check_y(y=y)\n",
    "        self.discrete_features_ = self.check_discrete_features(\n",
    "            X=X, discrete_features=discrete_features\n",
    "        )\n",
    "        self.discrete_target_ = self.check_discrete_target(\n",
    "            target_discrete=target_discrete\n",
    "        )\n",
    "        return self.estimate_mi(X, y)\n",
    "\n",
    "    def estimate_mi(self, X: np.ndarray, y: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Estimate mutual information between features and target.\n",
    "\n",
    "        Args:\n",
    "            X: (np.ndarray): input data.\n",
    "            y: (np.ndarray): target data.\n",
    "\n",
    "        Returns:\n",
    "            (np.ndarray): mutual information between features and target.\n",
    "        \"\"\"\n",
    "        X, y = self.prepare_data(X, y)\n",
    "        return np.array(\n",
    "            [\n",
    "                self.calculate_mi(X[:, i], y, self.discrete_features_[i])\n",
    "                for i in range(X.shape[1])\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def prepare_data(\n",
    "        self, X: np.ndarray, y: np.ndarray\n",
    "    ) -> typing.Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"Prepare data for mutual information calculation.\n",
    "\n",
    "        Args:\n",
    "            X: (np.ndarray): input data.\n",
    "            y: (np.ndarray): target data.\n",
    "\n",
    "        Returns:\n",
    "            (np.ndarray, np.ndarray): prepared input and target data.\n",
    "        \"\"\"\n",
    "        discrete_mask = self.discrete_features_.copy()\n",
    "        continous_mask = ~discrete_mask\n",
    "        X = X.astype(np.float64)\n",
    "        X[:, continous_mask] = X[:, continous_mask] / np.std(\n",
    "            X[:, continous_mask], axis=0\n",
    "        )\n",
    "        # Add small noise to continuous features\n",
    "        means = np.maximum(1, np.mean(np.abs(X[:, continous_mask]), axis=0))\n",
    "        X[:, continous_mask] += (\n",
    "            1e-10\n",
    "            * means\n",
    "            * np.random.standard_normal(size=(X.shape[0], np.sum(continous_mask)))\n",
    "        )\n",
    "        y = y.astype(np.float64)\n",
    "        if self.discrete_target_ is False:\n",
    "            y = y / np.std(y)\n",
    "            # Add small noise to continuous features\n",
    "            y += (\n",
    "                1e-10\n",
    "                * np.maximum(1, np.mean(np.abs(y)))\n",
    "                * np.random.standard_normal(size=(X.shape[0],))\n",
    "            )\n",
    "        return X, y\n",
    "\n",
    "    def calculate_mi(\n",
    "        self, x: np.ndarray, y: np.ndarray, discrete_feature: bool\n",
    "    ) -> float:\n",
    "        \"\"\"Choose the right mutual information calculation method.\n",
    "\n",
    "        Args:\n",
    "            x: (np.ndarray): feature data.\n",
    "            y: (np.ndarray): target data.\n",
    "            discrete_feature: (bool): feature type.\n",
    "\n",
    "        Returns:\n",
    "            (float): mutual information between feature and target.\n",
    "        \"\"\"\n",
    "        if discrete_feature and self.discrete_target_:\n",
    "            return self.mutual_information_dd(x, y)\n",
    "        elif discrete_feature and not self.discrete_target_:\n",
    "            return self.mutual_information_cd(y, x)\n",
    "        elif not discrete_feature and self.discrete_target_:\n",
    "            return self.mutual_information_cd(x, y)\n",
    "        else:\n",
    "            return self.mutual_information_cc(x, y)\n",
    "\n",
    "    def mutual_information_dd(self, x: np.ndarray, y: np.ndarray) -> float:\n",
    "        \"\"\"Calculate mutual information between discrete feature and discrete target.\n",
    "\n",
    "        Args:\n",
    "            x: (np.ndarray): feature data.\n",
    "            y: (np.ndarray): target data.\n",
    "\n",
    "        Returns:\n",
    "            (float): mutual information between discrete feature and target.\n",
    "        \"\"\"\n",
    "        crosstab = np.array(pd.crosstab(x, y, margins=True))\n",
    "        crosstab = crosstab / crosstab[-1, -1]\n",
    "        mi = 0\n",
    "        for i in range(crosstab.shape[0] - 1):\n",
    "            for j in range(crosstab.shape[1] - 1):\n",
    "                if crosstab[i, j] != 0:\n",
    "                    mi += crosstab[i, j] * np.log(\n",
    "                        crosstab[i, j] / (crosstab[i, -1] * crosstab[-1, j])\n",
    "                    )\n",
    "        return mi\n",
    "\n",
    "    def mutual_information_cd(\n",
    "        self, continous: np.ndarray, discrete: np.ndarray\n",
    "    ) -> float:\n",
    "        \"\"\"Calculate mutual information between continuous feature and dicrete target.\n",
    "\n",
    "        Args:\n",
    "            continous: (np.ndarray): continuous feature data.\n",
    "            discrete: (np.ndarray): target data.\n",
    "\n",
    "        Returns:\n",
    "            (float): mutual information between continuous feature and target.\n",
    "        \"\"\"\n",
    "        continous = continous.reshape(-1, 1)\n",
    "        N = continous.shape[0]\n",
    "        N_x = np.empty(N)\n",
    "        radius = np.empty(N)\n",
    "        k_all = np.empty(N)\n",
    "        nearest_neighbors = NearestNeighbors()\n",
    "        for label in np.unique(discrete):\n",
    "            mask = discrete == label\n",
    "            count = np.sum(mask)\n",
    "            if count > 1:\n",
    "                k = min(self.n_neighbors_, count - 1)\n",
    "                k_all[mask] = k\n",
    "                nearest_neighbors.set_params(n_neighbors=k)\n",
    "                nearest_neighbors.fit(continous[mask].reshape(-1, 1))\n",
    "                r = nearest_neighbors.kneighbors()[0]\n",
    "                radius[mask] = np.nextafter(r[:, -1], 0)\n",
    "            N_x[mask] = count\n",
    "        mask = N_x > 1\n",
    "        N_x = N_x[mask]\n",
    "        k_all = k_all[mask]\n",
    "        continous = continous[mask].reshape(-1, 1)\n",
    "        radius = radius[mask]\n",
    "        kd = KDTree(continous, metric=\"chebyshev\")\n",
    "        m_all = np.array(\n",
    "            kd.query_radius(continous, radius, count_only=True, return_distance=False)\n",
    "        )\n",
    "        mi = (\n",
    "            digamma(N)\n",
    "            - np.mean(digamma(N_x))\n",
    "            + np.mean(digamma(k_all))\n",
    "            - np.mean(digamma(m_all))\n",
    "        )\n",
    "        return max(0, mi)\n",
    "\n",
    "    def mutual_information_cc(self, x: np.ndarray, y: np.ndarray) -> float:\n",
    "        \"\"\"Calculate mutual information between continuous feature and continuous target.\n",
    "\n",
    "        Args:\n",
    "            x: (np.ndarray): feature data.\n",
    "            y: (np.ndarray): target data.\n",
    "\n",
    "        Returns:\n",
    "            (float): mutual information between continuous feature and target.\n",
    "        \"\"\"\n",
    "        N = x.shape[0]\n",
    "        x = x.reshape(-1, 1)\n",
    "        y = y.reshape(-1, 1)\n",
    "        xy = np.hstack((x, y))\n",
    "        nn = NearestNeighbors(metric=\"chebyshev\", n_neighbors=self.n_neighbors_)\n",
    "        nn.fit(xy)\n",
    "        radius = nn.kneighbors()[0]\n",
    "        radius = np.nextafter(radius[:, -1], 0)\n",
    "        # fig = go.Figure()\n",
    "        # fig.add_trace(go.Scatter(x=x.squeeze(), y=y.squeeze(), mode='markers', marker=dict(color='blue'), marker_size=10))\n",
    "        # for i in range(x.shape[0]):\n",
    "        #     fig.add_shape(type=\"circle\", xref=\"x\", yref=\"y\", x0=x[i][0]-radius[i]-0.1, y0=y[i][0]-radius[i]-0.1, x1=x[i][0]+radius[i]+0.1, y1=y[i][0]+radius[i]+0.1, opacity=0.2, line=dict(color=\"black\", width=2), fillcolor=\"white\")\n",
    "        # fig.update_layout(template=\"simple_white\", width=600, height=600, title_text=\"<b>Nearest neighbors<b>\", title_x=0.5, yaxis_title=\"y\", xaxis_title=\"x\", font=dict(family=\"Times New Roman\",size=16,color=\"Black\"))\n",
    "        # fig.show(\"png\")\n",
    "        # fig = go.Figure()\n",
    "        # fig.add_trace(go.Scatter(x=x.squeeze(), y=[0 for i in range(0, x.shape[0])], mode=\"markers\", marker=dict(color=px.colors.qualitative.Plotly), marker_size=15, showlegend=False))\n",
    "        # fig.add_trace(go.Scatter(x=[x[i][0]-radius[i] for i in range(0, x.shape[0])], y=[0 for i in range(0, len(x))], mode=\"markers\", marker_symbol=\"arrow-up\", marker=dict(color=px.colors.qualitative.Plotly), marker_size=15, showlegend=False))\n",
    "        # fig.add_trace(go.Scatter(x=[x[i][0]+radius[i] for i in range(0, x.shape[0])], y=[0 for i in range(0, len(x))], mode=\"markers\", marker_symbol=\"arrow-up\", marker=dict(color=px.colors.qualitative.Plotly), marker_size=15, showlegend=False))\n",
    "        # fig.update_xaxes(showgrid=False)\n",
    "        # fig.update_yaxes(showgrid=False, zeroline=True, zerolinecolor='black', zerolinewidth=1, showticklabels=False)\n",
    "        # fig.update_layout(plot_bgcolor='white', height=400, title_text=\"<b>X distances<b>\", title_x=0.5, xaxis_title=\"x\", font=dict(family=\"Times New Roman\",size=16,color=\"Black\"))\n",
    "        # fig.show(\"png\")\n",
    "        kd = KDTree(x, metric=\"chebyshev\")\n",
    "        N_x = kd.query_radius(x, radius, count_only=True, return_distance=False)\n",
    "        kd = KDTree(y, metric=\"chebyshev\")\n",
    "        N_y = kd.query_radius(y, radius, count_only=True, return_distance=False)\n",
    "        mi = (\n",
    "            digamma(N)\n",
    "            - np.mean(digamma(N_x))\n",
    "            + digamma(self.n_neighbors_)\n",
    "            - np.mean(digamma(N_y))\n",
    "        )\n",
    "        return max(0, mi)\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    roc_auc_score,\n",
    "    mean_squared_error,\n",
    "    mean_absolute_error,\n",
    ")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import typing\n",
    "\n",
    "\n",
    "class RFECVMutualInformation(MutualInformation):\n",
    "    \"\"\"This class is a feature selection technique that uses Recursive Feature Elimination with Cross-Validation and Mutual Information.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        algorithm: typing.Any,\n",
    "        metric: str,\n",
    "        cv: KFold,\n",
    "        discrete_features: typing.List[bool],\n",
    "        target_discrete: bool,\n",
    "    ):\n",
    "        \"\"\"This method initializes the class.\n",
    "\n",
    "        Args:\n",
    "            algorithm (typing.Any): algorithm that will be used for feature selection.\n",
    "            metric (str): metric that will be used for evaluation.\n",
    "            cv (KFold): cross-validation technique that will be used.\n",
    "            discrete_features (typing.List[bool]): list of booleans that indicates whether the feature is discrete or not.\n",
    "            target_discrete (bool): boolean that indicates whether the target is discrete or not.\n",
    "        \"\"\"\n",
    "        self.algorithm = algorithm\n",
    "        metrics = {\n",
    "            \"accuracy\": [lambda y, y_pred: accuracy_score(y, y_pred), \"preds\"],\n",
    "            \"roc_auc\": [lambda y, y_pred: roc_auc_score(y, y_pred), \"probs\"],\n",
    "            \"neg_mse\": [lambda y, y_pred: -mean_squared_error(y, y_pred), \"preds\"],\n",
    "            \"neg_rmse\": [\n",
    "                lambda y, y_pred: -mean_squared_error(y, y_pred) ** 0.5,\n",
    "                \"preds\",\n",
    "            ],\n",
    "            \"neg_mae\": [lambda y, y_pred: -mean_absolute_error(y, y_pred), \"preds\"],\n",
    "        }\n",
    "        if metric not in metrics:\n",
    "            raise ValueError(\"Unsupported metric: {}\".format(metric))\n",
    "        self.metric = metric\n",
    "        self.eval_metric = metrics[metric][0]\n",
    "        self.metric_type = metrics[metric][1]\n",
    "        self.cv = cv\n",
    "        self.mutual_information = MutualInformation(n_neighbors=3, random_state=17)\n",
    "        self.discrete_features_ = discrete_features\n",
    "        self.discrete_target_ = target_discrete\n",
    "\n",
    "    def check_X(\n",
    "        self, X: typing.Union[pd.DataFrame, pd.Series, np.ndarray]\n",
    "    ) -> np.ndarray:\n",
    "        \"\"\"Check if X is pandas DataFrame, pandas Series or numpy array and convert it to numpy array.\n",
    "\n",
    "        Args:\n",
    "            X: (Union[pd.DataFrame, pd.Series, np.ndarray]): input data.\n",
    "\n",
    "        Returns:\n",
    "            X: (np.ndarray): converted input data.\n",
    "        \"\"\"\n",
    "        if (\n",
    "            not isinstance(X, pd.DataFrame)\n",
    "            and not isinstance(X, pd.Series)\n",
    "            and not isinstance(X, np.ndarray)\n",
    "        ):\n",
    "            raise TypeError(\n",
    "                \"Wrong type of X. It should be pandas DataFrame, pandas Series, numpy array.\"\n",
    "            )\n",
    "        X = np.array(X)\n",
    "        if X.ndim == 1:\n",
    "            X = X[None, :]\n",
    "        return X\n",
    "\n",
    "    def check_y(\n",
    "        self, y: typing.Union[pd.DataFrame, pd.Series, np.ndarray]\n",
    "    ) -> np.ndarray:\n",
    "        \"\"\"Check if y is pandas DataFrame, pandas Series or numpy array and convert it to numpy array.\n",
    "\n",
    "        Args:\n",
    "            y: (Union[pd.DataFrame, pd.Series, np.ndarray]): target data.\n",
    "\n",
    "        Returns:\n",
    "            y: (np.ndarray): converted target data.\n",
    "        \"\"\"\n",
    "        if (\n",
    "            not isinstance(y, pd.DataFrame)\n",
    "            and not isinstance(y, pd.Series)\n",
    "            and not isinstance(y, np.ndarray)\n",
    "        ):\n",
    "            raise TypeError(\n",
    "                \"Wrong type of y. It should be pandas DataFrame, pandas Series, numpy array.\"\n",
    "            )\n",
    "        y = np.array(y)\n",
    "        if y.ndim != 1:\n",
    "            y = y.squeeze()\n",
    "        return y\n",
    "\n",
    "    def check_for_object_columns(self, X: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Check if X contains object columns and convert it to numeric data.\n",
    "\n",
    "        Args:\n",
    "            X: (np.ndarray): input data.\n",
    "\n",
    "        Returns:\n",
    "            X: (np.ndarray): converted input data.\n",
    "        \"\"\"\n",
    "        X = pd.DataFrame(X)\n",
    "        if X.select_dtypes(include=np.number).shape[1] != X.shape[1]:\n",
    "            raise TypeError(\n",
    "                \"Your data contains object or string columns. Numeric data is obligated.\"\n",
    "            )\n",
    "        return np.array(X)\n",
    "\n",
    "    def fit(\n",
    "        self,\n",
    "        X: typing.Union[pd.DataFrame, pd.Series, np.ndarray],\n",
    "        y: typing.Union[pd.DataFrame, pd.Series, np.ndarray],\n",
    "        verbose: bool = False,\n",
    "    ) -> None:\n",
    "        \"\"\"Fit the Recursive Feature Elimination with Cross-Validation and Mutual Information to the data.\n",
    "\n",
    "        Args:\n",
    "            X (Union[pd.DataFrame, pd.Series, np.ndarray]): input data.\n",
    "            y (Union[pd.DataFrame, pd.Series, np.ndarray]): target data.\n",
    "            verbose (bool): boolean that indicates whether the information about the process will be printed out.\n",
    "        \"\"\"\n",
    "        X = self.check_X(X)\n",
    "        X = self.check_for_object_columns(X)\n",
    "        y = self.check_y(y)\n",
    "        self.mi_ = list(\n",
    "            self.mutual_information.fit(\n",
    "                X,\n",
    "                y,\n",
    "                discrete_features=self.discrete_features_,\n",
    "                target_discrete=self.discrete_target_,\n",
    "            )\n",
    "        )\n",
    "        self.indices_of_best_, self.support_ = self.perform_rfecv(X, y, verbose)\n",
    "\n",
    "    def perform_rfecv(\n",
    "        self, X: np.ndarray, y: np.ndarray, verbose: bool\n",
    "    ) -> typing.Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"Perform the Recursive Feature Elimination with Cross-Validation.\n",
    "\n",
    "        Args:\n",
    "            X (np.ndarray): input data.\n",
    "            y (np.ndarray): target data.\n",
    "            verbose (bool): boolean that indicates whether the information about the process will be printed out.\n",
    "\n",
    "        Returns:\n",
    "            best_features (np.ndarray): indices of the best features.\n",
    "            support_ (np.ndarray): boolean mask of the best features.\n",
    "        \"\"\"\n",
    "        original_features = [i for i in range(X.shape[-1])]\n",
    "        features = original_features.copy()\n",
    "        best_score = -np.inf\n",
    "        worst = None\n",
    "        while len(features) > 1:\n",
    "            if worst is not None:\n",
    "                features.remove(original_features[worst])\n",
    "            X_copy = X[:, features]\n",
    "            score = self.perform_cv(X_copy, y)\n",
    "            if score > best_score:\n",
    "                if verbose == True:\n",
    "                    print(\n",
    "                        \"After removing the worst feature: {}, score improved, because: {}>{}\".format(\n",
    "                            worst, score, best_score\n",
    "                        )\n",
    "                    )\n",
    "                best_score = score\n",
    "                best_features = np.setdiff1d(features, [worst])\n",
    "            worst = features[np.argmin([self.mi_[i] for i in features])]\n",
    "        support_ = np.array(\n",
    "            [True if i in best_features else False for i in range(0, X.shape[1])]\n",
    "        ).astype(bool)\n",
    "        return best_features, support_\n",
    "\n",
    "    def perform_cv(self, X: np.ndarray, y: np.ndarray) -> float:\n",
    "        \"\"\"This method performs cross-validation.\n",
    "\n",
    "        Args:\n",
    "            X: (np.ndarray): input data.\n",
    "            y: (np.ndarray): target data.\n",
    "\n",
    "        Returns:\n",
    "            float: cross-validation score.\n",
    "        \"\"\"\n",
    "        scores = []\n",
    "        for train_index, test_index in self.cv.split(X):\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "            self.algorithm.fit(X_train, y_train)\n",
    "            if self.metric_type == \"preds\":\n",
    "                y_pred = self.algorithm.predict(X_test)\n",
    "            else:\n",
    "                y_pred = self.algorithm.predict_proba(X_test)[:, 1]\n",
    "            scores.append(self.eval_metric(y_test, y_pred))\n",
    "        return np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8f8fd512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After removing the worst feature: None, score improved, because: -0.1928102065020521>-inf\n",
      "Indices of best features: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30]\n",
      "Support: [ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True]\n"
     ]
    }
   ],
   "source": [
    "discrete_features = [\"series\", \"Fiction\", \"Nonfiction\", \"Literary\", \"Fantasy\", \"Crime\", \"Social\", \"Children\", \"Romans\", \"Realism\"]\n",
    "model = XGBRegressor(max_depth=4, subsample=1, colsample_bytree=0.5, colsample_bylevel=0.4, reg_lambda=8, gamma=0, random_state=SEED, n_jobs=-1)\n",
    "rfecv_mi = RFECVMutualInformation(algorithm=model, metric=\"neg_rmse\", discrete_features=discrete_features, target_discrete=False, cv=KFold(n_splits=5, shuffle=True))\n",
    "rfecv_mi.fit(train_data[features], train_data[target], verbose=True)\n",
    "print(\"Indices of best features: {}\".format(rfecv_mi.indices_of_best_))\n",
    "print(\"Support: {}\".format(rfecv_mi.support_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf74e03",
   "metadata": {},
   "source": [
    "Wyniki sugerują, że model osiąga najlepsze rezultaty przy pełnym zbiorze zmiennych."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c728e00",
   "metadata": {},
   "source": [
    "## Zapisanie modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f7355cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 0.14659\n",
      "Test RMSE: 0.1983\n"
     ]
    }
   ],
   "source": [
    "test_indices = test_data.index\n",
    "#Ewaluacja modelu\n",
    "model = XGBRegressor(max_depth=4, subsample=1, colsample_bytree=0.5, colsample_bylevel=0.4, reg_lambda=8, gamma=0, random_state=SEED, n_jobs=-1)\n",
    "train_results, test_results, y_test_pred = evaluation(train_data_interactions[features_interactions], train_data_interactions[target], test_data_interactions[features_interactions], test_data_interactions[target], model)\n",
    "print(\"Train RMSE: {}\".format(round(train_results, 5)))\n",
    "print(\"Test RMSE: {}\".format(round(test_results, 5)))\n",
    "\n",
    "#Zapisanie modelu\n",
    "model_XGB = {\n",
    "    \"name\": \"XGB\",\n",
    "    \"trainResults\": train_results,\n",
    "    \"testResults\": test_results,\n",
    "    \"predictions\": y_test_pred,\n",
    "    \"indices\": test_indices,\n",
    "}\n",
    "with open(\"../data/model_XGB.p\", \"wb\") as fp:\n",
    "    pickle.dump(model_XGB, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96867c0",
   "metadata": {},
   "source": [
    "## Podsumowanie"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ec4b58",
   "metadata": {},
   "source": [
    "$\\text{Najlepsze wyniki walidacji krzyżowej uzyskano dla modelu bazującego na podstawowych danych}$<p>\n",
    "$\\text{Optymalizacja hiperparametrów oraz regularyzacja pozwoliły na poprawę wyników.}$<p>\n",
    "$\\text{Wyniki na zbiorze treningowym (RMSE): 0.14659}$<p>\n",
    "$\\text{Wyniki na zbiorze testowym (RMSE): 0.1983}$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
