{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import bibliotek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import *\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from  sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, QuantileTransformer\n",
    "import optuna\n",
    "import typing\n",
    "import plotly.graph_objs as go\n",
    "import itertools\n",
    "import warnings\n",
    "from scipy.special import digamma\n",
    "from sklearn.neighbors import NearestNeighbors, KDTree\n",
    "warnings.filterwarnings('ignore')\n",
    "SEED = 17"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ładowanie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pages</th>\n",
       "      <th>stars</th>\n",
       "      <th>reviews</th>\n",
       "      <th>series</th>\n",
       "      <th>mix</th>\n",
       "      <th>character</th>\n",
       "      <th>plot</th>\n",
       "      <th>funny</th>\n",
       "      <th>lighthearted</th>\n",
       "      <th>emotional</th>\n",
       "      <th>...</th>\n",
       "      <th>author_stars</th>\n",
       "      <th>Fiction</th>\n",
       "      <th>Nonfiction</th>\n",
       "      <th>Literary</th>\n",
       "      <th>Fantasy</th>\n",
       "      <th>Crime</th>\n",
       "      <th>Social</th>\n",
       "      <th>Children</th>\n",
       "      <th>Romans</th>\n",
       "      <th>Realism</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>273</td>\n",
       "      <td>4.00</td>\n",
       "      <td>2017</td>\n",
       "      <td>0</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.91</td>\n",
       "      <td>...</td>\n",
       "      <td>4.305000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>302</td>\n",
       "      <td>3.78</td>\n",
       "      <td>7330</td>\n",
       "      <td>0</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.18</td>\n",
       "      <td>...</td>\n",
       "      <td>3.670000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>400</td>\n",
       "      <td>4.15</td>\n",
       "      <td>16761</td>\n",
       "      <td>0</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.88</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>459</td>\n",
       "      <td>4.16</td>\n",
       "      <td>2128</td>\n",
       "      <td>1</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>160</td>\n",
       "      <td>3.65</td>\n",
       "      <td>6634</td>\n",
       "      <td>1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>4.115000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6925</th>\n",
       "      <td>432</td>\n",
       "      <td>4.15</td>\n",
       "      <td>30643</td>\n",
       "      <td>0</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.40</td>\n",
       "      <td>...</td>\n",
       "      <td>3.856667</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6926</th>\n",
       "      <td>352</td>\n",
       "      <td>3.62</td>\n",
       "      <td>1058</td>\n",
       "      <td>0</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6927</th>\n",
       "      <td>535</td>\n",
       "      <td>3.88</td>\n",
       "      <td>30975</td>\n",
       "      <td>1</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.31</td>\n",
       "      <td>...</td>\n",
       "      <td>3.870000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6928</th>\n",
       "      <td>472</td>\n",
       "      <td>3.88</td>\n",
       "      <td>5914</td>\n",
       "      <td>1</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.36</td>\n",
       "      <td>...</td>\n",
       "      <td>3.660000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6929</th>\n",
       "      <td>350</td>\n",
       "      <td>4.27</td>\n",
       "      <td>67909</td>\n",
       "      <td>0</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.78</td>\n",
       "      <td>...</td>\n",
       "      <td>4.315833</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6930 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pages  stars  reviews  series   mix  character  plot  funny  \\\n",
       "0       273   4.00     2017       0  0.44       0.51  0.02   0.27   \n",
       "1       302   3.78     7330       0  0.39       0.42  0.17   0.03   \n",
       "2       400   4.15    16761       0  0.51       0.39  0.08   0.02   \n",
       "3       459   4.16     2128       1  0.48       0.10  0.40   0.04   \n",
       "4       160   3.65     6634       1  0.28       0.16  0.54   0.92   \n",
       "...     ...    ...      ...     ...   ...        ...   ...    ...   \n",
       "6925    432   4.15    30643       0  0.48       0.05  0.46   0.00   \n",
       "6926    352   3.62     1058       0  0.55       0.13  0.30   0.15   \n",
       "6927    535   3.88    30975       1  0.45       0.08  0.45   0.14   \n",
       "6928    472   3.88     5914       1  0.64       0.12  0.22   0.07   \n",
       "6929    350   4.27    67909       0  0.37       0.56  0.05   0.74   \n",
       "\n",
       "      lighthearted  emotional  ...  author_stars  Fiction  Nonfiction  \\\n",
       "0             0.37       0.91  ...      4.305000        1           1   \n",
       "1             0.01       0.18  ...      3.670000        1           0   \n",
       "2             0.01       0.88  ...      0.000000        1           0   \n",
       "3             0.02       0.07  ...      0.000000        1           0   \n",
       "4             0.73       0.00  ...      4.115000        1           0   \n",
       "...            ...        ...  ...           ...      ...         ...   \n",
       "6925          0.00       0.40  ...      3.856667        1           0   \n",
       "6926          0.10       0.25  ...      3.700000        1           0   \n",
       "6927          0.19       0.31  ...      3.870000        1           0   \n",
       "6928          0.00       0.36  ...      3.660000        1           0   \n",
       "6929          0.28       0.78  ...      4.315833        1           0   \n",
       "\n",
       "      Literary  Fantasy  Crime  Social  Children  Romans  Realism  \n",
       "0            0        0      0       1         0       1        1  \n",
       "1            0        0      1       0         0       0        0  \n",
       "2            1        0      0       0         0       0        0  \n",
       "3            0        1      0       0         0       0        0  \n",
       "4            0        1      0       0         0       0        0  \n",
       "...        ...      ...    ...     ...       ...     ...      ...  \n",
       "6925         0        1      1       0         0       0        0  \n",
       "6926         0        1      0       1         0       0        0  \n",
       "6927         0        1      0       0         1       0        0  \n",
       "6928         0        1      0       0         1       0        0  \n",
       "6929         1        0      1       0         0       0        1  \n",
       "\n",
       "[6930 rows x 32 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv(\"../data/data_eda.csv\")\n",
    "data=data.drop(columns=['Unnamed: 0'])\n",
    "features=data.columns.tolist()\n",
    "features.remove('stars')\n",
    "target='stars'\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\text{Podział danych na zbiór treningowy i testowy}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_cv(X: pd.DataFrame, y: pd.Series, algorithm: typing.Any, cv: typing.Any = KFold(n_splits=5, shuffle=True, random_state=SEED), metric: typing.Any = mean_squared_error) -> typing.List[float]:\n",
    "    \"\"\"\n",
    "    Perform cross-validation and return list of scores\n",
    "    \n",
    "    Args:\n",
    "        X (pd.DataFrame): input data\n",
    "        y (pd.Series): target data\n",
    "        algorithm (typing.Any): algorithm to use for training and prediction\n",
    "        cv (typing.Any): cross-validation strategy\n",
    "        metric (typing.Any): metric to use for evaluation\n",
    "    \n",
    "    Returns:\n",
    "        typing.List[float]: list of scores in order: train_scores, validation_scores\n",
    "    \"\"\"\n",
    "    train_scores = []\n",
    "    validation_scores = []\n",
    "    for train_idx, val_idx in cv.split(X, y):\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "        algorithm.fit(X_train, y_train)\n",
    "        y_train_pred = algorithm.predict(X_train)\n",
    "        y_val_pred = algorithm.predict(X_val)\n",
    "        train_scores.append(metric(y_train, y_train_pred, squared=False))\n",
    "        validation_scores.append(metric(y_val, y_val_pred, squared=False))\n",
    "    return np.mean(train_scores), np.mean(validation_scores)\n",
    "\n",
    "def test_evaluation(X_train: pd.DataFrame, y_train: pd.Series, X_test: pd.DataFrame, y_test: pd.Series, algorithm: typing.Any, metric: typing.Any = mean_squared_error) -> float:\n",
    "    \"\"\"\n",
    "    Train the algorithm on the train data and evaluate on the test data\n",
    "    \n",
    "    Args:\n",
    "        X_train (pd.DataFrame): input train data\n",
    "        y_train (pd.Series): target train data\n",
    "        X_test (pd.DataFrame): input test data\n",
    "        y_test (pd.Series): target test data\n",
    "        algorithm (typing.Any): algorithm to use for training and prediction\n",
    "        metric (typing.Any): metric to use for evaluation\n",
    "    \n",
    "    Returns:\n",
    "        float: test score\n",
    "    \"\"\"\n",
    "    algorithm.fit(X_train, y_train)\n",
    "    y_test_pred = algorithm.predict(X_test)\n",
    "    return metric(y_test, y_test_pred, squared=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Średni błąd RMSE na zbiorze treningowym: 2.16058\n",
      "Średni błąd RMSE na zbiorze walidacyjnym: 2.06503\n",
      "Błąd RMSE na zbiorze testowym: 1.87393\n"
     ]
    }
   ],
   "source": [
    "model = MLPRegressor(random_state=SEED)\n",
    "train_scores, validation_scores = perform_cv(train_data[features], train_data[target], model)\n",
    "test_score = test_evaluation(train_data[features], train_data[target], test_data[features], test_data[target], model)\n",
    "print(\"Średni błąd RMSE na zbiorze treningowym: {:.5f}\".format(train_scores))\n",
    "print(\"Średni błąd RMSE na zbiorze walidacyjnym: {:.5f}\".format(validation_scores))\n",
    "print(\"Błąd RMSE na zbiorze testowym: {:.5f}\".format(test_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\text{Wyniki dla modelu bazowego wyglądają bardzo słabo w porównaniu do pozostałych algorytmów.}$<p>\n",
    "$\\text{Warto jednak zaznaczyć, że w przypadku sieci neuronowych, podobnie jak w KNN, należy znormalizować dane, ponieważ algorytmy te są wrażliwe na skalę danych.}$<p>\n",
    "$\\text{W celu normalizacji danych przetestujemy kilka różnych narzędzi.}$<p>\n",
    "$\\text{Transformacja zostanie przeprowadzona jedynie na zmiennych ciągłych.}$<p>\n",
    "$\\text{Ponieważ informacje na temat rozkładu zmiennych powinny być znane tylko dla danych treningowych, to zmodyfikujemy funkcje ewaluacyjne.}$<p>\n",
    "$\\text{Aby była możliwość porównania wyników z tymi uzyskanymi dla pozostałych algorytmów, przed porównaniem predykcji z wartościami prawdziwymi, dokonamy odwrotnej transformacji, w celu uzyskania pierwotnej skali danych.}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_cv_scaling(X: pd.DataFrame, y: pd.Series, algorithm: typing.Any, cv: typing.Any = KFold(n_splits=5, shuffle=True, random_state=SEED), metric: typing.Any = mean_squared_error, scaler: typing.Any = StandardScaler(), features_to_scale: typing.List[str] = None, target_to_scale: bool = False) -> typing.List[float]:\n",
    "    \"\"\"\n",
    "    Perform cross-validation and return list of scores\n",
    "    \n",
    "    Args:\n",
    "        X (pd.DataFrame): input data\n",
    "        y (pd.Series): target data\n",
    "        algorithm (typing.Any): algorithm to use for training and prediction\n",
    "        cv (typing.Any): cross-validation strategy\n",
    "        metric (typing.Any): metric to use for evaluation\n",
    "        scaler (typing.Any): scaler to use for scaling\n",
    "        features_to_scale (typing.List[str]): list of features to scale\n",
    "        target_to_scale (bool): whether to scale target data\n",
    "    \n",
    "    Returns:\n",
    "        typing.List[float]: list of scores in order: train_scores, validation_scores\n",
    "    \"\"\"\n",
    "    train_scores = []\n",
    "    validation_scores = []\n",
    "    for train_idx, val_idx in cv.split(X, y):\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "        X_train[features_to_scale] = scaler.fit_transform(X_train[features_to_scale])\n",
    "        X_val[features_to_scale] = scaler.transform(X_val[features_to_scale])\n",
    "        if target_to_scale:\n",
    "            y_train = scaler.fit_transform(y_train.values.reshape(-1, 1)).ravel()\n",
    "            y_val = scaler.transform(y_val.values.reshape(-1, 1)).ravel()    \n",
    "        algorithm.fit(X_train, y_train)\n",
    "        y_train_pred = algorithm.predict(X_train)\n",
    "        y_val_pred = algorithm.predict(X_val)\n",
    "        if(target_to_scale):\n",
    "            y_train = scaler.inverse_transform(y_train.reshape(-1, 1)).ravel()\n",
    "            y_val = scaler.inverse_transform(y_val.reshape(-1, 1)).ravel()\n",
    "            y_train_pred = scaler.inverse_transform(y_train_pred.reshape(-1, 1)).ravel()\n",
    "            y_val_pred = scaler.inverse_transform(y_val_pred.reshape(-1, 1)).ravel()\n",
    "        train_scores.append(metric(y_train, y_train_pred, squared=False))\n",
    "        validation_scores.append(metric(y_val, y_val_pred, squared=False))\n",
    "    return np.mean(train_scores), np.mean(validation_scores)\n",
    "\n",
    "def test_evaluation_scaling(X_train: pd.DataFrame, y_train: pd.Series, X_test: pd.DataFrame, y_test: pd.Series, algorithm: typing.Any, metric: typing.Any = mean_squared_error, scaler: typing.Any = StandardScaler(), features_to_scale: typing.List[str] = None, target_to_scale: bool = False) -> float:\n",
    "    \"\"\"\n",
    "    Train the algorithm on the train data and evaluate on the test data\n",
    "    \n",
    "    Args:\n",
    "        X_train (pd.DataFrame): input train data\n",
    "        y_train (pd.Series): target train data\n",
    "        X_test (pd.DataFrame): input test data\n",
    "        y_test (pd.Series): target test data\n",
    "        algorithm (typing.Any): algorithm to use for training and prediction\n",
    "        metric (typing.Any): metric to use for evaluation.\n",
    "        scaler (typing.Any): scaler to use for scaling\n",
    "        features_to_scale (typing.List[str]): list of features to scale\n",
    "        target_to_scale (bool): whether to scale target data\n",
    "    \n",
    "    Returns:\n",
    "        float: test score\n",
    "    \"\"\"\n",
    "    X_train[features_to_scale] = scaler.fit_transform(X_train[features_to_scale])\n",
    "    X_test[features_to_scale] = scaler.transform(X_test[features_to_scale])\n",
    "    if target_to_scale:\n",
    "        y_train = scaler.fit_transform(y_train.values.reshape(-1, 1)).ravel()\n",
    "        y_test = scaler.transform(y_test.values.reshape(-1, 1)).ravel()\n",
    "    algorithm.fit(X_train, y_train)\n",
    "    y_test_pred = algorithm.predict(X_test)\n",
    "    if target_to_scale:\n",
    "        y_test = scaler.inverse_transform(y_test.reshape(-1, 1)).ravel()\n",
    "        y_test_pred = scaler.inverse_transform(y_test_pred.reshape(-1, 1)).ravel()\n",
    "    return metric(y_test, y_test_pred, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Średni błąd RMSE na zbiorze treningowym z użyciem skaler: StandardScaler wynosi: 0.13254\n",
      "Średni błąd RMSE na zbiorze walidacyjnym z użyciem skaler: StandardScaler wynosi: 0.20105\n",
      "\n",
      "Średni błąd RMSE na zbiorze treningowym z użyciem skaler: MinMaxScaler wynosi: 0.20128\n",
      "Średni błąd RMSE na zbiorze walidacyjnym z użyciem skaler: MinMaxScaler wynosi: 0.21464\n",
      "\n",
      "Średni błąd RMSE na zbiorze treningowym z użyciem skaler: RobustScaler wynosi: 0.13630\n",
      "Średni błąd RMSE na zbiorze walidacyjnym z użyciem skaler: RobustScaler wynosi: 0.19931\n",
      "\n",
      "Średni błąd RMSE na zbiorze treningowym z użyciem skaler: QuantileTransformer wynosi: 0.19140\n",
      "Średni błąd RMSE na zbiorze walidacyjnym z użyciem skaler: QuantileTransformer wynosi: 0.23032\n",
      "\n"
     ]
    }
   ],
   "source": [
    "continous_features = [\"pages\", \"reviews\", \"mix\", \"character\", \"plot\", \"funny\", \"lighthearted\", \"emotional\", \"hopeful\", \"inspiring\", \"relaxing\", \"tense\", \"sad\", \"reflective\", \"adventurous\", \"challenging\", \"informative\", \"mysterious\", \"dark\", \"author_count\", \"author_stars\"]\n",
    "scalers = [StandardScaler(), MinMaxScaler(), RobustScaler(), QuantileTransformer()]\n",
    "scalers_names = [\"StandardScaler\", \"MinMaxScaler\", \"RobustScaler\", \"QuantileTransformer\"]\n",
    "for scaler, scaler_name in zip(scalers, scalers_names):\n",
    "    train_scores, validation_scores = perform_cv_scaling(train_data[features], train_data[target], model, scaler=scaler, features_to_scale=continous_features, target_to_scale=True)\n",
    "    print(\"Średni błąd RMSE na zbiorze treningowym z użyciem skaler: {} wynosi: {:.5f}\".format(scaler_name, train_scores))\n",
    "    print(\"Średni błąd RMSE na zbiorze walidacyjnym z użyciem skaler: {} wynosi: {:.5f}\".format(scaler_name, validation_scores))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\text{Wyniki walidacji krzyżowej sugerują wykorzystanie narzędzia RobustScaler do transformacji zmiennych ciągłych.}$<p>\n",
    "$\\text{Zaletą RobustScaler jest zwiększona odporność na obserwacje odstające, co jest istotne w przypadku niektórych zmiennych ciągłych występujących w zbiorze danych (np.: author\\_count, reviews, czy pages).}$<p>\n",
    "$\\text{Sprawdźmy wyniki na zbiorze testowym po dokonaniu standaryzacji.}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Średni błąd RMSE na zbiorze treningowym: 0.13630\n",
      "Średni błąd RMSE na zbiorze walidacyjnym: 0.19931\n",
      "Błąd RMSE na zbiorze testowym: 0.20221\n"
     ]
    }
   ],
   "source": [
    "model = MLPRegressor(random_state=SEED)\n",
    "scaler = RobustScaler()\n",
    "train_scores, validation_scores = perform_cv_scaling(train_data[features], train_data[target], model, scaler=scaler, features_to_scale=continous_features, target_to_scale=True)\n",
    "test_score = test_evaluation_scaling(train_data[features], train_data[target], test_data[features], test_data[target], model, scaler=scaler, features_to_scale=continous_features, target_to_scale=True)\n",
    "print(\"Średni błąd RMSE na zbiorze treningowym: {:.5f}\".format(train_scores))\n",
    "print(\"Średni błąd RMSE na zbiorze walidacyjnym: {:.5f}\".format(validation_scores))\n",
    "print(\"Błąd RMSE na zbiorze testowym: {:.5f}\".format(test_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\text{Wyniki uległy znacznej poprawie, natomiast warto odnotować, że sieć została przetrenowana.}$<p>\n",
    "$\\text{W kolejnych etapach będziemy starali się dokonać pewnej regularyzacji w celu możliwego zredukoania overfittingu.}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optymalizacja"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hidden_layer_sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\text{W przypadku sieci neuronowych, jednym z najważniejszych parametrów jest liczba warstw ukrytych oraz liczba neuronów w każdej z warstw.}$<p>\n",
    "$\\text{Zbyt mała liczba neuronów może prowadzić do underfittingu, natomiast zbyt duża do overfittingu oraz długiego czasu uczenia.}$<p>\n",
    "$\\text{Oczywiście dokładne znalezienie optymalnego rozwiązania jest niemal niemożliwe, dlatego spróbujemy zaledwie z kilkoma różnymi wartościami tego parametru.}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden layer sizes: 50; RMSE train: 0.15853; RMSE validation: 0.20207\n",
      "Hidden layer sizes: 100; RMSE train: 0.13630; RMSE validation: 0.19931\n",
      "Hidden layer sizes: 150; RMSE train: 0.12169; RMSE validation: 0.20307\n",
      "Hidden layer sizes: (50, 100); RMSE train: 0.09975; RMSE validation: 0.21803\n",
      "Hidden layer sizes: (50, 150); RMSE train: 0.08948; RMSE validation: 0.22231\n",
      "Hidden layer sizes: (100, 50); RMSE train: 0.08854; RMSE validation: 0.22334\n",
      "Hidden layer sizes: (100, 150); RMSE train: 0.06749; RMSE validation: 0.22186\n",
      "Hidden layer sizes: (150, 50); RMSE train: 0.07765; RMSE validation: 0.22214\n",
      "Hidden layer sizes: (150, 100); RMSE train: 0.06510; RMSE validation: 0.21836\n",
      "Hidden layer sizes: (50, 100, 150); RMSE train: 0.04911; RMSE validation: 0.23418\n",
      "Hidden layer sizes: (50, 150, 100); RMSE train: 0.04165; RMSE validation: 0.23364\n",
      "Hidden layer sizes: (100, 50, 150); RMSE train: 0.05390; RMSE validation: 0.23866\n",
      "Hidden layer sizes: (100, 150, 50); RMSE train: 0.04763; RMSE validation: 0.22964\n",
      "Hidden layer sizes: (150, 50, 100); RMSE train: 0.04809; RMSE validation: 0.22840\n",
      "Hidden layer sizes: (150, 100, 50); RMSE train: 0.04718; RMSE validation: 0.22874\n"
     ]
    }
   ],
   "source": [
    "hidden_layer_sizes = [50,100,150] + list(itertools.permutations([50,100,150],2)) + list(itertools.permutations([50,100,150],3))\n",
    "for hidden_layer_size in hidden_layer_sizes:\n",
    "    model = MLPRegressor(hidden_layer_sizes=hidden_layer_size, random_state=SEED)\n",
    "    train_scores, validation_scores = perform_cv_scaling(train_data[features], train_data[target], model, scaler=scaler, features_to_scale=continous_features, target_to_scale=True)\n",
    "    print(\"Hidden layer sizes: {}; RMSE train: {:.5f}; RMSE validation: {:.5f}\".format(hidden_layer_size, train_scores, validation_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\text{Widzimy, że wraz ze zwiększaniem liczby neuronów oraz warstw, wyniki na zbiorze trenigowym ulegają poprawie.}$<p>\n",
    "$\\text{Niestety, powoduje to również zwiększenie overfittingu.}$<p>\n",
    "$\\text{Wygląda na to, że optymalna będzie zaledwie jedna warstwa w sieci.}$<p>\n",
    "$\\text{Na dalszym etapie, podczas tuningowania całej sieci, testować będziemy wyniki dla wartości w okolicach 100 neuronów w pojedynczej warstwie.}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\text{Kolejnym ważnym parametrem jest funkcja aktywacji.}$<p>\n",
    "$\\text{Odpowiada ona za to, jaka transformacja zostanie zastosowana na danych wychodzących z warstwy ukrytej.}$<p>\n",
    "$\\text{Dla sieci neuronowych dostępne są różne funkcje aktywacji, poniżej przetestujemy następujące: identity, logistic, tanh, relu.}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation: identity; RMSE train: 0.22218; RMSE validation: 0.22367\n",
      "Activation: logistic; RMSE train: 0.19598; RMSE validation: 0.20402\n",
      "Activation: tanh; RMSE train: 0.15694; RMSE validation: 0.19697\n",
      "Activation: relu; RMSE train: 0.13630; RMSE validation: 0.19931\n"
     ]
    }
   ],
   "source": [
    "activations = ['identity', 'logistic', 'tanh', 'relu']\n",
    "for activation in activations:\n",
    "    model = MLPRegressor(hidden_layer_sizes=100, activation=activation, random_state=SEED)\n",
    "    train_scores, validation_scores = perform_cv_scaling(train_data[features], train_data[target], model, scaler=scaler, features_to_scale=continous_features, target_to_scale=True)\n",
    "    print(\"Activation: {}; RMSE train: {:.5f}; RMSE validation: {:.5f}\".format(activation, train_scores, validation_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\text{Najlepsze wyniki na zbiorze walidacyjnym uzyskano w przypadku funkcji aktywacji tanh.}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## solver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\text{Parametr solver odpowiada za algorytm optymalizacji wag - za to jak będą one aktualizowane w trakcie uczenia.}$<p>\n",
    "$\\text{Podobnie jak w przypadku funkcji aktywacji, dostępne są różne algorytmy, poniżej przetestujemy następujące: lbfgs, sgd, adam.}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solver: lbfgs; RMSE train: 0.15194; RMSE validation: 0.20313\n",
      "Solver: sgd; RMSE train: 0.20379; RMSE validation: 0.20946\n",
      "Solver: adam; RMSE train: 0.15694; RMSE validation: 0.19697\n"
     ]
    }
   ],
   "source": [
    "solvers = ['lbfgs', 'sgd', 'adam']\n",
    "for solver in solvers:\n",
    "    model = MLPRegressor(hidden_layer_sizes=100, activation='tanh', solver=solver, random_state=SEED)\n",
    "    train_scores, validation_scores = perform_cv_scaling(train_data[features], train_data[target], model, scaler=scaler, features_to_scale=continous_features, target_to_scale=True)\n",
    "    print(\"Solver: {}; RMSE train: {:.5f}; RMSE validation: {:.5f}\".format(solver, train_scores, validation_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\text{Zarówno rezultaty na zbiorze treningowym, jak i walidacyjnym są najlepsze dla solvera adam.}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\text{Parametr alpha odpowiada za regularyzację sieci.}$<p>\n",
    "$\\text{alpha służy do ograniczenia rozmiaru wag, co może pomóc w redukcji overfittingu.}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 1e-05; RMSE train: 0.15691; RMSE validation: 0.19698\n",
      "Alpha: 0.0001; RMSE train: 0.15694; RMSE validation: 0.19697\n",
      "Alpha: 0.001; RMSE train: 0.15720; RMSE validation: 0.19690\n",
      "Alpha: 0.01; RMSE train: 0.15915; RMSE validation: 0.19636\n",
      "Alpha: 0.1; RMSE train: 0.17174; RMSE validation: 0.19542\n",
      "Alpha: 1; RMSE train: 0.20312; RMSE validation: 0.20787\n",
      "Alpha: 10; RMSE train: 0.22935; RMSE validation: 0.22987\n",
      "Alpha: 100; RMSE train: 0.29388; RMSE validation: 0.29417\n",
      "Alpha: 1000; RMSE train: 0.30130; RMSE validation: 0.30147\n",
      "Alpha: 10000; RMSE train: 0.30130; RMSE validation: 0.30143\n"
     ]
    }
   ],
   "source": [
    "alphas = [10**i for i in range(-5, 5)]\n",
    "for alpha in alphas:\n",
    "    model = MLPRegressor(hidden_layer_sizes=100, activation='tanh', solver='adam', alpha=alpha, random_state=SEED)\n",
    "    train_scores, validation_scores = perform_cv_scaling(train_data[features], train_data[target], model, scaler=scaler, features_to_scale=continous_features, target_to_scale=True)\n",
    "    print(\"Alpha: {}; RMSE train: {:.5f}; RMSE validation: {:.5f}\".format(alpha, train_scores, validation_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\text{Wraz ze wzrostem wartości parametru alpha, wyniki na zbiorze trenigowym ulegają pogorszeniu.}$<p>\n",
    "$\\text{W przypadku zbioru walidacyjnego, najlepsze wyniki uzyskano dla wartości 0.01}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## learning_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\text{Parametr learning\\_rate odpowiada za to jak silnie aktualizowane są wagi w trakcie uczenia.}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 1e-05; RMSE train: 0.22565; RMSE validation: 0.22739\n",
      "Learning rate: 0.0001; RMSE train: 0.19920; RMSE validation: 0.20637\n",
      "Learning rate: 0.001; RMSE train: 0.15915; RMSE validation: 0.19636\n",
      "Learning rate: 0.01; RMSE train: 0.13676; RMSE validation: 0.21779\n",
      "Learning rate: 0.1; RMSE train: 0.22215; RMSE validation: 0.25893\n",
      "Learning rate: 1; RMSE train: 0.45501; RMSE validation: 0.46085\n"
     ]
    }
   ],
   "source": [
    "learning_rates = [10**i for i in range(-5, 1)]\n",
    "for learning_rate in learning_rates:\n",
    "    model = MLPRegressor(hidden_layer_sizes=100, activation='tanh', solver='adam', alpha=0.01, learning_rate_init=learning_rate, random_state=SEED)\n",
    "    train_scores, validation_scores = perform_cv_scaling(train_data[features], train_data[target], model, scaler=scaler, features_to_scale=continous_features, target_to_scale=True)\n",
    "    print(\"Learning rate: {}; RMSE train: {:.5f}; RMSE validation: {:.5f}\".format(learning_rate, train_scores, validation_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\text{Dla wartości domyślnej: 0.001, wyniki na zbiorze walidacyjnym są najlepsze.}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## max_iter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\text{Parametr max\\_iter odpowiada za maksymalną liczbę iteracji - czyli ile razy algorytm będzie uczył się na danych i optymalizował wagi.}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max iter: 100; RMSE train: 0.17769; RMSE validation: 0.19859\n",
      "Max iter: 200; RMSE train: 0.15915; RMSE validation: 0.19636\n",
      "Max iter: 300; RMSE train: 0.14982; RMSE validation: 0.19679\n",
      "Max iter: 400; RMSE train: 0.14903; RMSE validation: 0.19764\n",
      "Max iter: 500; RMSE train: 0.14903; RMSE validation: 0.19764\n",
      "Max iter: 600; RMSE train: 0.14903; RMSE validation: 0.19764\n",
      "Max iter: 700; RMSE train: 0.14903; RMSE validation: 0.19764\n",
      "Max iter: 800; RMSE train: 0.14903; RMSE validation: 0.19764\n",
      "Max iter: 900; RMSE train: 0.14903; RMSE validation: 0.19764\n",
      "Max iter: 1000; RMSE train: 0.14903; RMSE validation: 0.19764\n"
     ]
    }
   ],
   "source": [
    "max_iters = [i for i in range(100, 1001, 100)]\n",
    "for max_iter in max_iters:\n",
    "    model = MLPRegressor(hidden_layer_sizes=100, activation='tanh', solver='adam', alpha=0.01, learning_rate_init=0.001, max_iter=max_iter, random_state=SEED)\n",
    "    train_scores, validation_scores = perform_cv_scaling(train_data[features], train_data[target], model, scaler=scaler, features_to_scale=continous_features, target_to_scale=True)\n",
    "    print(\"Max iter: {}; RMSE train: {:.5f}; RMSE validation: {:.5f}\".format(max_iter, train_scores, validation_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\text{Od okolic 400 iteracji, model przestaje się uczyć, a wyniki na zbiorze walidacyjnym są stałe.}$<p>\n",
    "$\\text{Warto jednak zwrócić uwagę, że model zaczyna być przeuczony od około 200 iteracji.}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomSearchCV:\n",
    "    \"\"\"\n",
    "    This class is used to optimize the hyperparameters of the algorithm using Random Search.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        algorithm: typing.Any,\n",
    "        metric: str,\n",
    "        cv: typing.Any = KFold(n_splits=5, shuffle=True, random_state=17),\n",
    "        n_trials: int = 100,\n",
    "        seed: int = 17,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Initializes the RandomSearchCV class.\n",
    "\n",
    "        Args:\n",
    "            algorithm (typing.Any): algorithm to optimize.\n",
    "            metric (str): metric to use for optimization.\n",
    "            cv (typing.Any): cross-validation strategy.\n",
    "            n_trials (int): number of trials to perform.\n",
    "            seed (int): random seed.\n",
    "        \"\"\"\n",
    "        self.algorithm = algorithm\n",
    "        metrics = {\n",
    "            \"accuracy\": [lambda y, y_pred: accuracy_score(y, y_pred), \"preds\", \"maximize\"],\n",
    "            \"roc_auc\": [lambda y, y_pred: roc_auc_score(y, y_pred), \"probs\", \"maximize\"],\n",
    "            \"mse\": [lambda y, y_pred: mean_squared_error(y, y_pred), \"preds\", \"minimize\"],\n",
    "            \"rmse\": [\n",
    "                lambda y, y_pred: mean_squared_error(y, y_pred, squared=False),\n",
    "                \"preds\", \"minimize\"\n",
    "            ],\n",
    "            \"mae\": [lambda y, y_pred: mean_absolute_error(y, y_pred), \"preds\", \"minimize\"],\n",
    "        }\n",
    "        if metric not in metrics:\n",
    "            raise ValueError(\"Unsupported metric: {}\".format(metric))\n",
    "        self.eval_metric = metrics[metric][0]\n",
    "        self.metric_type = metrics[metric][1]\n",
    "        self.direction = metrics[metric][2]\n",
    "        self.cv = cv\n",
    "        self.n_trials = n_trials\n",
    "        self.seed = seed\n",
    "    \n",
    "    def check_X(\n",
    "        self, X: typing.Union[pd.DataFrame, pd.Series, np.ndarray]\n",
    "    ) -> np.ndarray:\n",
    "        \"\"\"Check if X is pandas DataFrame, pandas Series or numpy array and convert it to numpy array.\n",
    "\n",
    "        Args:\n",
    "            X: (Union[pd.DataFrame, pd.Series, np.ndarray]): input data.\n",
    "\n",
    "        Returns:\n",
    "            X: (np.ndarray): converted input data.\n",
    "        \"\"\"\n",
    "        if (\n",
    "            not isinstance(X, pd.DataFrame)\n",
    "            and not isinstance(X, pd.Series)\n",
    "            and not isinstance(X, np.ndarray)\n",
    "        ):\n",
    "            raise TypeError(\n",
    "                \"Wrong type of X. It should be pandas DataFrame, pandas Series, numpy array.\"\n",
    "            )\n",
    "        X = np.array(X)\n",
    "        if X.ndim == 1:\n",
    "            X = X[None, :]\n",
    "        return X\n",
    "\n",
    "    def check_y(\n",
    "        self, y: typing.Union[pd.DataFrame, pd.Series, np.ndarray]\n",
    "    ) -> np.ndarray:\n",
    "        \"\"\"Check if y is pandas DataFrame, pandas Series or numpy array and convert it to numpy array.\n",
    "\n",
    "        Args:\n",
    "            y: (Union[pd.DataFrame, pd.Series, np.ndarray]): target data.\n",
    "\n",
    "        Returns:\n",
    "            y: (np.ndarray): converted target data.\n",
    "        \"\"\"\n",
    "        if (\n",
    "            not isinstance(y, pd.DataFrame)\n",
    "            and not isinstance(y, pd.Series)\n",
    "            and not isinstance(y, np.ndarray)\n",
    "        ):\n",
    "            raise TypeError(\n",
    "                \"Wrong type of y. It should be pandas DataFrame, pandas Series, numpy array.\"\n",
    "            )\n",
    "        y = np.array(y)\n",
    "        if y.ndim != 1:\n",
    "            y = y.squeeze()\n",
    "        return y\n",
    "\n",
    "    def check_for_object_columns(self, X: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Check if X contains object columns and convert it to numeric data.\n",
    "\n",
    "        Args:\n",
    "            X: (np.ndarray): input data.\n",
    "\n",
    "        Returns:\n",
    "            X: (np.ndarray): converted input data.\n",
    "        \"\"\"\n",
    "        X = pd.DataFrame(X)\n",
    "        if X.select_dtypes(include=np.number).shape[1] != X.shape[1]:\n",
    "            raise TypeError(\n",
    "                \"Your data contains object or string columns. Numeric data is obligated.\"\n",
    "            )\n",
    "        return np.array(X)\n",
    "\n",
    "    def tune(\n",
    "        self,\n",
    "        X: pd.DataFrame,\n",
    "        y: pd.Series,\n",
    "        params_grid: typing.Dict[str, typing.Tuple[str, typing.List[typing.Any]]],\n",
    "        X_valid: pd.DataFrame = None,\n",
    "        y_valid: pd.Series = None,\n",
    "    ) -> typing.Dict[str, typing.Any]:\n",
    "        \"\"\"\n",
    "        This method tunes the algorithm hyperparameters.\n",
    "\n",
    "        Args:\n",
    "            X (pd.DataFrame): input data.\n",
    "            y (pd.Series): target data.\n",
    "            params_grid (typing.Dict[str, typing.Tuple[str, typing.List[typing.Any]]]): hyperparameters grid.\n",
    "            X_valid (pd.DataFrame): validation data (default is None).\n",
    "            y_valid (pd.Series): validation labels (default is None).\n",
    "\n",
    "        Returns:\n",
    "            typing.Dict[str, typing.Any]: best hyperparameters.\n",
    "        \"\"\"\n",
    "        self.params_grid = params_grid\n",
    "        study = self.create_study()\n",
    "        X = self.check_X(X)\n",
    "        X = self.check_for_object_columns(X)\n",
    "        y = self.check_y(y)\n",
    "        if X_valid is not None and y_valid is not None:\n",
    "            X_valid = self.check_X(X_valid)\n",
    "            y_valid = self.check_y(y_valid)\n",
    "            X_valid = self.check_for_object_columns(X_valid)\n",
    "            study.optimize(\n",
    "                lambda trial: self.objective(trial, X, y, X_valid, y_valid),\n",
    "                n_trials=self.n_trials,\n",
    "            )\n",
    "        else:\n",
    "            study.optimize(\n",
    "                lambda trial: self.objective_cv(trial, X, y),\n",
    "                n_trials=self.n_trials,\n",
    "            )\n",
    "        return study.best_params\n",
    "    \n",
    "    def create_study(self,) -> optuna.study.Study:\n",
    "        \"\"\"This method creates an optuna study object.\n",
    "\n",
    "        Returns:\n",
    "            optuna.study.Study: optuna study object.\n",
    "        \"\"\"\n",
    "        sampler = optuna.samplers.TPESampler(seed=self.seed)\n",
    "        return optuna.create_study(direction=self.direction, sampler=sampler)\n",
    "    \n",
    "    def objective(self, trial: optuna.Trial, X_train: np.ndarray, y_train: np.ndarray, X_valid: np.ndarray, y_valid: np.ndarray) -> float:\n",
    "        \"\"\"\n",
    "        This method defines the objective function for optimization when validation data is provided.\n",
    "\n",
    "        Args:\n",
    "            trial (optuna.Trial): trial object.\n",
    "            X_train (np.ndarray): input data.\n",
    "            y_train (np.ndarray): target data.\n",
    "            X_valid (np.ndarray): validation data.\n",
    "            y_valid (np.ndarray): validation labels.\n",
    "        \n",
    "        Returns:\n",
    "            float: Validation score.\n",
    "        \"\"\"\n",
    "        params = {param_name: self.get_param(trial, param_name, param_values) for param_name, param_values in self.params_grid.items()}\n",
    "        self.algorithm = self.algorithm.set_params(**params)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_valid_pred = model.predict(X_valid)\n",
    "        return self.eval_metric(y_valid, y_valid_pred)\n",
    "    \n",
    "    def objective_cv(self, trial: optuna.Trial, X: np.ndarray, y: np.ndarray) -> float:\n",
    "        \"\"\"\n",
    "        This method defines the objective function for optimization when validation data is not provided.\n",
    "\n",
    "        Args:\n",
    "            trial (optuna.Trial): trial object.\n",
    "            X (np.ndarray): input data.\n",
    "            y (np.ndarray): target data.\n",
    "        \n",
    "        Returns:\n",
    "            float: Cross-validation score.\n",
    "        \"\"\"\n",
    "        params = {param_name: self.get_param(trial, param_name, param_values) for param_name, param_values in self.params_grid.items()}\n",
    "        self.algorithm = self.algorithm.set_params(**params)\n",
    "        return self.perform_cv(X, y)\n",
    "\n",
    "    \n",
    "    def get_param(self, trial: optuna.Trial, param_name: str, param_values: typing.Tuple[str, typing.List[typing.Any]]) -> typing.Any:\n",
    "        \"\"\"\n",
    "        This method converts the parameter values to the optuna parameter suggestion.\n",
    "\n",
    "        Args:\n",
    "            trial (optuna.Trial): trial object.\n",
    "            param_name (str): parameter name.\n",
    "            param_values (typing.Tuple[str, typing.List[typing.Any]]): parameter values.\n",
    "\n",
    "        Returns:\n",
    "            typing.Any: parameter suggestion.\n",
    "        \"\"\"\n",
    "        param_type, param_value = param_values\n",
    "        if param_type == \"int\":\n",
    "            return trial.suggest_int(param_name, low=param_value[0], high=param_value[1])\n",
    "        elif param_type == \"float\":\n",
    "            return trial.suggest_float(param_name, low=param_value[0], high=param_value[1])\n",
    "        elif param_type == \"categorical\":\n",
    "            return trial.suggest_categorical(param_name, param_value)\n",
    "        elif param_type == \"constant\":\n",
    "            return trial.suggest_categorical(param_name, [param_value])\n",
    "\n",
    "    def perform_cv(self, X: np.ndarray, y: np.ndarray) -> float:\n",
    "        \"\"\"This method performs cross-validation.\n",
    "\n",
    "        Args:\n",
    "            X: (np.ndarray): input data.\n",
    "            y: (np.ndarray): target data.\n",
    "\n",
    "        Returns:\n",
    "            float: cross-validation score.\n",
    "        \"\"\"\n",
    "        valid_scores = []\n",
    "        for train_idx, valid_idx in self.cv.split(X):\n",
    "            X_train_cv, X_valid_cv = X[train_idx], X[valid_idx]\n",
    "            y_train_cv, y_valid_cv = y[train_idx], y[valid_idx]\n",
    "            self.algorithm.fit(X_train_cv, y_train_cv)\n",
    "            if self.metric_type == \"preds\":\n",
    "                y_valid_pred = self.algorithm.predict(X_valid_cv)\n",
    "            else:\n",
    "                y_valid_pred = self.algorithm.predict_proba(X_valid_cv)[:, 1]\n",
    "            valid_scores.append(self.eval_metric(y_valid_cv, y_valid_pred))\n",
    "        return np.mean(valid_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-02 13:35:40,741] A new study created in memory with name: no-name-9ed01e7b-a9cd-4015-9a9a-a0690f3e2996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-02 13:35:50,061] Trial 0 finished with value: 0.48971971643022466 and parameters: {'hidden_layer_sizes': 79, 'activation': 'tanh', 'solver': 'adam', 'alpha': 0.32988509327904847, 'learning_rate_init': 0.0033688440321963616, 'max_iter': 265, 'random_state': 17}. Best is trial 0 with value: 0.48971971643022466.\n",
      "[I 2024-05-02 13:36:09,875] Trial 1 finished with value: 0.47838451048494984 and parameters: {'hidden_layer_sizes': 53, 'activation': 'relu', 'solver': 'adam', 'alpha': 0.43925881044327497, 'learning_rate_init': 0.0007303714952920416, 'max_iter': 281, 'random_state': 17}. Best is trial 1 with value: 0.47838451048494984.\n",
      "[I 2024-05-02 13:36:20,991] Trial 2 finished with value: 0.4865709381022877 and parameters: {'hidden_layer_sizes': 105, 'activation': 'tanh', 'solver': 'adam', 'alpha': 0.28294690813654877, 'learning_rate_init': 0.0022822134622116196, 'max_iter': 308, 'random_state': 17}. Best is trial 1 with value: 0.47838451048494984.\n",
      "[I 2024-05-02 13:36:38,022] Trial 3 finished with value: 0.4746035004114579 and parameters: {'hidden_layer_sizes': 92, 'activation': 'relu', 'solver': 'adam', 'alpha': 0.14969709047954857, 'learning_rate_init': 0.001394482424901544, 'max_iter': 317, 'random_state': 17}. Best is trial 3 with value: 0.4746035004114579.\n",
      "[I 2024-05-02 13:36:50,927] Trial 4 finished with value: 0.4830983095845253 and parameters: {'hidden_layer_sizes': 107, 'activation': 'relu', 'solver': 'adam', 'alpha': 0.06364377111514286, 'learning_rate_init': 0.00250248229754031, 'max_iter': 328, 'random_state': 17}. Best is trial 3 with value: 0.4746035004114579.\n",
      "[I 2024-05-02 13:37:00,130] Trial 5 finished with value: 0.4779413942488563 and parameters: {'hidden_layer_sizes': 130, 'activation': 'relu', 'solver': 'adam', 'alpha': 0.37307049874137777, 'learning_rate_init': 0.004494813583485366, 'max_iter': 176, 'random_state': 17}. Best is trial 3 with value: 0.4746035004114579.\n",
      "[I 2024-05-02 13:37:11,324] Trial 6 finished with value: 0.48395750586951775 and parameters: {'hidden_layer_sizes': 128, 'activation': 'tanh', 'solver': 'adam', 'alpha': 0.22143973612318024, 'learning_rate_init': 0.0028428577858009936, 'max_iter': 249, 'random_state': 17}. Best is trial 3 with value: 0.4746035004114579.\n",
      "[I 2024-05-02 13:37:23,565] Trial 7 finished with value: 0.49373896438959425 and parameters: {'hidden_layer_sizes': 63, 'activation': 'tanh', 'solver': 'adam', 'alpha': 0.4773972434506775, 'learning_rate_init': 0.0013884969988115388, 'max_iter': 166, 'random_state': 17}. Best is trial 3 with value: 0.4746035004114579.\n",
      "[I 2024-05-02 13:37:33,035] Trial 8 finished with value: 0.4773021843892953 and parameters: {'hidden_layer_sizes': 139, 'activation': 'relu', 'solver': 'adam', 'alpha': 0.45847449276282987, 'learning_rate_init': 0.0017321593681300293, 'max_iter': 197, 'random_state': 17}. Best is trial 3 with value: 0.4746035004114579.\n",
      "[I 2024-05-02 13:37:40,995] Trial 9 finished with value: 0.49095334001477775 and parameters: {'hidden_layer_sizes': 81, 'activation': 'tanh', 'solver': 'adam', 'alpha': 0.3479839576376705, 'learning_rate_init': 0.004032876610687683, 'max_iter': 221, 'random_state': 17}. Best is trial 3 with value: 0.4746035004114579.\n",
      "[I 2024-05-02 13:38:05,075] Trial 10 finished with value: 0.5037148388991758 and parameters: {'hidden_layer_sizes': 89, 'activation': 'relu', 'solver': 'sgd', 'alpha': 0.1528329174621159, 'learning_rate_init': 0.0006638809896344954, 'max_iter': 350, 'random_state': 17}. Best is trial 3 with value: 0.4746035004114579.\n",
      "[I 2024-05-02 13:38:27,131] Trial 11 finished with value: 0.4918234372094427 and parameters: {'hidden_layer_sizes': 140, 'activation': 'relu', 'solver': 'sgd', 'alpha': 0.19034210126417825, 'learning_rate_init': 0.0016964870875842948, 'max_iter': 211, 'random_state': 17}. Best is trial 3 with value: 0.4746035004114579.\n",
      "[I 2024-05-02 13:38:47,163] Trial 12 finished with value: 0.4973205978976001 and parameters: {'hidden_layer_sizes': 117, 'activation': 'relu', 'solver': 'sgd', 'alpha': 0.49406090073874637, 'learning_rate_init': 0.0017087261021014701, 'max_iter': 210, 'random_state': 17}. Best is trial 3 with value: 0.4746035004114579.\n",
      "[I 2024-05-02 13:39:06,705] Trial 13 finished with value: 0.4736707025446177 and parameters: {'hidden_layer_sizes': 148, 'activation': 'relu', 'solver': 'adam', 'alpha': 0.11766534074826607, 'learning_rate_init': 0.0012449492411036732, 'max_iter': 296, 'random_state': 17}. Best is trial 13 with value: 0.4736707025446177.\n",
      "[I 2024-05-02 13:39:34,255] Trial 14 finished with value: 0.49583466065622306 and parameters: {'hidden_layer_sizes': 150, 'activation': 'relu', 'solver': 'sgd', 'alpha': 0.10629122662990871, 'learning_rate_init': 0.0011127721008692098, 'max_iter': 291, 'random_state': 17}. Best is trial 13 with value: 0.4736707025446177.\n",
      "[I 2024-05-02 13:40:03,313] Trial 15 finished with value: 0.4802205207386786 and parameters: {'hidden_layer_sizes': 93, 'activation': 'relu', 'solver': 'adam', 'alpha': 0.006417700515867403, 'learning_rate_init': 0.0005195044328789577, 'max_iter': 315, 'random_state': 17}. Best is trial 13 with value: 0.4736707025446177.\n",
      "[I 2024-05-02 13:40:20,018] Trial 16 finished with value: 0.46923330677777486 and parameters: {'hidden_layer_sizes': 113, 'activation': 'relu', 'solver': 'adam', 'alpha': 0.15729943558162535, 'learning_rate_init': 0.0011992598745496593, 'max_iter': 337, 'random_state': 17}. Best is trial 16 with value: 0.46923330677777486.\n",
      "[I 2024-05-02 13:40:32,939] Trial 17 finished with value: 0.475733513395315 and parameters: {'hidden_layer_sizes': 119, 'activation': 'relu', 'solver': 'adam', 'alpha': 0.2487852777194514, 'learning_rate_init': 0.0021211006321254474, 'max_iter': 349, 'random_state': 17}. Best is trial 16 with value: 0.46923330677777486.\n",
      "[I 2024-05-02 13:40:58,560] Trial 18 finished with value: 0.501590829742935 and parameters: {'hidden_layer_sizes': 147, 'activation': 'relu', 'solver': 'sgd', 'alpha': 0.10083379911574464, 'learning_rate_init': 0.0010944974172415562, 'max_iter': 250, 'random_state': 17}. Best is trial 16 with value: 0.46923330677777486.\n",
      "[I 2024-05-02 13:41:09,499] Trial 19 finished with value: 0.4781552509802956 and parameters: {'hidden_layer_sizes': 118, 'activation': 'relu', 'solver': 'adam', 'alpha': 0.20272372963843824, 'learning_rate_init': 0.0027940526657063095, 'max_iter': 290, 'random_state': 17}. Best is trial 16 with value: 0.46923330677777486.\n",
      "[I 2024-05-02 13:41:20,902] Trial 20 finished with value: 0.4712976041493425 and parameters: {'hidden_layer_sizes': 131, 'activation': 'relu', 'solver': 'adam', 'alpha': 0.2740133616850457, 'learning_rate_init': 0.002059188606871966, 'max_iter': 323, 'random_state': 17}. Best is trial 16 with value: 0.46923330677777486.\n",
      "[I 2024-05-02 13:41:33,145] Trial 21 finished with value: 0.46919478369577583 and parameters: {'hidden_layer_sizes': 131, 'activation': 'relu', 'solver': 'adam', 'alpha': 0.27871379369767196, 'learning_rate_init': 0.0019267397281344887, 'max_iter': 332, 'random_state': 17}. Best is trial 21 with value: 0.46919478369577583.\n",
      "[I 2024-05-02 13:41:46,469] Trial 22 finished with value: 0.47300739643778267 and parameters: {'hidden_layer_sizes': 129, 'activation': 'relu', 'solver': 'adam', 'alpha': 0.2765686131092155, 'learning_rate_init': 0.0020588513358455853, 'max_iter': 334, 'random_state': 17}. Best is trial 21 with value: 0.46919478369577583.\n",
      "[I 2024-05-02 13:41:56,585] Trial 23 finished with value: 0.4763215511572506 and parameters: {'hidden_layer_sizes': 111, 'activation': 'relu', 'solver': 'adam', 'alpha': 0.2799357124005446, 'learning_rate_init': 0.0019970371948430593, 'max_iter': 329, 'random_state': 17}. Best is trial 21 with value: 0.46919478369577583.\n",
      "[I 2024-05-02 13:42:04,413] Trial 24 finished with value: 0.47551439352498515 and parameters: {'hidden_layer_sizes': 138, 'activation': 'relu', 'solver': 'adam', 'alpha': 0.22396369832383436, 'learning_rate_init': 0.002386526609064251, 'max_iter': 337, 'random_state': 17}. Best is trial 21 with value: 0.46919478369577583.\n",
      "[I 2024-05-02 13:42:16,444] Trial 25 finished with value: 0.47019006700124477 and parameters: {'hidden_layer_sizes': 123, 'activation': 'relu', 'solver': 'adam', 'alpha': 0.3075824946913978, 'learning_rate_init': 0.0017382026838673, 'max_iter': 266, 'random_state': 17}. Best is trial 21 with value: 0.46919478369577583.\n",
      "[I 2024-05-02 13:42:41,056] Trial 26 finished with value: 0.5107932974055946 and parameters: {'hidden_layer_sizes': 100, 'activation': 'tanh', 'solver': 'sgd', 'alpha': 0.31437675596713405, 'learning_rate_init': 0.0009126450487626425, 'max_iter': 270, 'random_state': 17}. Best is trial 21 with value: 0.46919478369577583.\n",
      "[I 2024-05-02 13:42:54,953] Trial 27 finished with value: 0.46998877275586315 and parameters: {'hidden_layer_sizes': 121, 'activation': 'relu', 'solver': 'adam', 'alpha': 0.3786487557460367, 'learning_rate_init': 0.0015411435201072674, 'max_iter': 234, 'random_state': 17}. Best is trial 21 with value: 0.46919478369577583.\n",
      "[I 2024-05-02 13:43:09,708] Trial 28 finished with value: 0.4740144252888272 and parameters: {'hidden_layer_sizes': 111, 'activation': 'relu', 'solver': 'adam', 'alpha': 0.39237675664486654, 'learning_rate_init': 0.0013558203198637219, 'max_iter': 230, 'random_state': 17}. Best is trial 21 with value: 0.46919478369577583.\n",
      "[I 2024-05-02 13:43:21,739] Trial 29 finished with value: 0.49120619088120404 and parameters: {'hidden_layer_sizes': 101, 'activation': 'tanh', 'solver': 'adam', 'alpha': 0.3450559397961077, 'learning_rate_init': 0.0031193926091145673, 'max_iter': 246, 'random_state': 17}. Best is trial 21 with value: 0.46919478369577583.\n",
      "[I 2024-05-02 13:43:40,005] Trial 30 finished with value: 0.46819210181649584 and parameters: {'hidden_layer_sizes': 123, 'activation': 'relu', 'solver': 'adam', 'alpha': 0.4121634855102475, 'learning_rate_init': 0.0009681555312184396, 'max_iter': 189, 'random_state': 17}. Best is trial 30 with value: 0.46819210181649584.\n",
      "[I 2024-05-02 13:43:56,892] Trial 31 finished with value: 0.4719242906920485 and parameters: {'hidden_layer_sizes': 124, 'activation': 'relu', 'solver': 'adam', 'alpha': 0.4242301462218591, 'learning_rate_init': 0.0009022136845598777, 'max_iter': 157, 'random_state': 17}. Best is trial 30 with value: 0.46819210181649584.\n",
      "[I 2024-05-02 13:44:15,187] Trial 32 finished with value: 0.4730545616594732 and parameters: {'hidden_layer_sizes': 113, 'activation': 'relu', 'solver': 'adam', 'alpha': 0.4215128920173691, 'learning_rate_init': 0.0008489340697605523, 'max_iter': 200, 'random_state': 17}. Best is trial 30 with value: 0.46819210181649584.\n",
      "[I 2024-05-02 13:44:26,137] Trial 33 finished with value: 0.4720224184940621 and parameters: {'hidden_layer_sizes': 136, 'activation': 'relu', 'solver': 'adam', 'alpha': 0.37861162735265413, 'learning_rate_init': 0.0014736925766390516, 'max_iter': 184, 'random_state': 17}. Best is trial 30 with value: 0.46819210181649584.\n",
      "[I 2024-05-02 13:44:41,542] Trial 34 finished with value: 0.470957015407361 and parameters: {'hidden_layer_sizes': 122, 'activation': 'relu', 'solver': 'adam', 'alpha': 0.4064872884843848, 'learning_rate_init': 0.001001661791103241, 'max_iter': 230, 'random_state': 17}. Best is trial 30 with value: 0.46819210181649584.\n",
      "[I 2024-05-02 13:45:04,534] Trial 35 finished with value: 0.47347067732361686 and parameters: {'hidden_layer_sizes': 134, 'activation': 'relu', 'solver': 'adam', 'alpha': 0.44442747641649066, 'learning_rate_init': 0.0005359740948510867, 'max_iter': 305, 'random_state': 17}. Best is trial 30 with value: 0.46819210181649584.\n",
      "[I 2024-05-02 13:45:18,545] Trial 36 finished with value: 0.47504580279645675 and parameters: {'hidden_layer_sizes': 102, 'activation': 'relu', 'solver': 'adam', 'alpha': 0.3344566429884684, 'learning_rate_init': 0.001508839433379778, 'max_iter': 276, 'random_state': 17}. Best is trial 30 with value: 0.46819210181649584.\n",
      "[I 2024-05-02 13:45:33,826] Trial 37 finished with value: 0.48944563558929827 and parameters: {'hidden_layer_sizes': 108, 'activation': 'tanh', 'solver': 'adam', 'alpha': 0.36462224610669436, 'learning_rate_init': 0.0011429727808116475, 'max_iter': 189, 'random_state': 17}. Best is trial 30 with value: 0.46819210181649584.\n",
      "[I 2024-05-02 13:45:50,269] Trial 38 finished with value: 0.47379563499530325 and parameters: {'hidden_layer_sizes': 51, 'activation': 'relu', 'solver': 'adam', 'alpha': 0.39196465892889965, 'learning_rate_init': 0.0007820368093296206, 'max_iter': 259, 'random_state': 17}. Best is trial 30 with value: 0.46819210181649584.\n",
      "[I 2024-05-02 13:45:59,991] Trial 39 finished with value: 0.47773420749606704 and parameters: {'hidden_layer_sizes': 125, 'activation': 'relu', 'solver': 'adam', 'alpha': 0.3079074578302125, 'learning_rate_init': 0.0024254838315835667, 'max_iter': 237, 'random_state': 17}. Best is trial 30 with value: 0.46819210181649584.\n",
      "[I 2024-05-02 13:46:11,373] Trial 40 finished with value: 0.48769972457845023 and parameters: {'hidden_layer_sizes': 65, 'activation': 'tanh', 'solver': 'adam', 'alpha': 0.352829549812128, 'learning_rate_init': 0.0012710647240125087, 'max_iter': 150, 'random_state': 17}. Best is trial 30 with value: 0.46819210181649584.\n",
      "[I 2024-05-02 13:46:21,456] Trial 41 finished with value: 0.47494651196943777 and parameters: {'hidden_layer_sizes': 114, 'activation': 'relu', 'solver': 'adam', 'alpha': 0.3051096572927471, 'learning_rate_init': 0.0018758965310543324, 'max_iter': 309, 'random_state': 17}. Best is trial 30 with value: 0.46819210181649584.\n",
      "[I 2024-05-02 13:46:33,058] Trial 42 finished with value: 0.4696973458290527 and parameters: {'hidden_layer_sizes': 122, 'activation': 'relu', 'solver': 'adam', 'alpha': 0.32973968722292063, 'learning_rate_init': 0.0015620570218379689, 'max_iter': 168, 'random_state': 17}. Best is trial 30 with value: 0.46819210181649584.\n",
      "[I 2024-05-02 13:46:43,003] Trial 43 finished with value: 0.4691971490587162 and parameters: {'hidden_layer_sizes': 143, 'activation': 'relu', 'solver': 'adam', 'alpha': 0.36699403950675114, 'learning_rate_init': 0.0016657008987036126, 'max_iter': 170, 'random_state': 17}. Best is trial 30 with value: 0.46819210181649584.\n",
      "[I 2024-05-02 13:46:54,458] Trial 44 finished with value: 0.468471472142702 and parameters: {'hidden_layer_sizes': 143, 'activation': 'relu', 'solver': 'adam', 'alpha': 0.31963153876990147, 'learning_rate_init': 0.0015948524867890432, 'max_iter': 172, 'random_state': 17}. Best is trial 30 with value: 0.46819210181649584.\n",
      "[I 2024-05-02 13:47:06,994] Trial 45 finished with value: 0.4743628007140675 and parameters: {'hidden_layer_sizes': 141, 'activation': 'relu', 'solver': 'adam', 'alpha': 0.4652434772516696, 'learning_rate_init': 0.0012758604011309993, 'max_iter': 170, 'random_state': 17}. Best is trial 30 with value: 0.46819210181649584.\n",
      "[I 2024-05-02 13:47:27,239] Trial 46 finished with value: 0.4931432184999892 and parameters: {'hidden_layer_sizes': 143, 'activation': 'relu', 'solver': 'sgd', 'alpha': 0.36260205989187877, 'learning_rate_init': 0.002255244601516598, 'max_iter': 185, 'random_state': 17}. Best is trial 30 with value: 0.46819210181649584.\n",
      "[I 2024-05-02 13:47:38,678] Trial 47 finished with value: 0.4727883896670573 and parameters: {'hidden_layer_sizes': 133, 'activation': 'relu', 'solver': 'adam', 'alpha': 0.24926499358352014, 'learning_rate_init': 0.001855274529159687, 'max_iter': 160, 'random_state': 17}. Best is trial 30 with value: 0.46819210181649584.\n",
      "[I 2024-05-02 13:47:55,250] Trial 48 finished with value: 0.49067395493746535 and parameters: {'hidden_layer_sizes': 144, 'activation': 'tanh', 'solver': 'adam', 'alpha': 0.3284321211405915, 'learning_rate_init': 0.0010449767632530066, 'max_iter': 174, 'random_state': 17}. Best is trial 30 with value: 0.46819210181649584.\n",
      "[I 2024-05-02 13:48:16,657] Trial 49 finished with value: 0.5090280763013356 and parameters: {'hidden_layer_sizes': 128, 'activation': 'relu', 'solver': 'sgd', 'alpha': 0.29095994247181317, 'learning_rate_init': 0.0006905639287121362, 'max_iter': 205, 'random_state': 17}. Best is trial 30 with value: 0.46819210181649584.\n",
      "[I 2024-05-02 13:48:26,368] Trial 50 finished with value: 0.47562248919552247 and parameters: {'hidden_layer_sizes': 147, 'activation': 'relu', 'solver': 'adam', 'alpha': 0.4472371875824041, 'learning_rate_init': 0.0025985138364333182, 'max_iter': 216, 'random_state': 17}. Best is trial 30 with value: 0.46819210181649584.\n",
      "[I 2024-05-02 13:48:37,842] Trial 51 finished with value: 0.4720739717649008 and parameters: {'hidden_layer_sizes': 126, 'activation': 'relu', 'solver': 'adam', 'alpha': 0.3441309081258042, 'learning_rate_init': 0.0016297410620138646, 'max_iter': 178, 'random_state': 17}. Best is trial 30 with value: 0.46819210181649584.\n",
      "[I 2024-05-02 13:48:50,371] Trial 52 finished with value: 0.47292948009588487 and parameters: {'hidden_layer_sizes': 136, 'activation': 'relu', 'solver': 'adam', 'alpha': 0.3345854750335611, 'learning_rate_init': 0.0014357555933248133, 'max_iter': 163, 'random_state': 17}. Best is trial 30 with value: 0.46819210181649584.\n",
      "[I 2024-05-02 13:49:03,956] Trial 53 finished with value: 0.46954111390847925 and parameters: {'hidden_layer_sizes': 132, 'activation': 'relu', 'solver': 'adam', 'alpha': 0.26041501921702964, 'learning_rate_init': 0.001809653008185974, 'max_iter': 150, 'random_state': 17}. Best is trial 30 with value: 0.46819210181649584.\n",
      "[I 2024-05-02 13:49:14,410] Trial 54 finished with value: 0.47265329871395023 and parameters: {'hidden_layer_sizes': 143, 'activation': 'relu', 'solver': 'adam', 'alpha': 0.23689605541870978, 'learning_rate_init': 0.0022076748266334706, 'max_iter': 154, 'random_state': 17}. Best is trial 30 with value: 0.46819210181649584.\n",
      "[I 2024-05-02 13:49:27,372] Trial 55 finished with value: 0.47186339473629585 and parameters: {'hidden_layer_sizes': 132, 'activation': 'relu', 'solver': 'adam', 'alpha': 0.26429197974141727, 'learning_rate_init': 0.001841903212416927, 'max_iter': 195, 'random_state': 17}. Best is trial 30 with value: 0.46819210181649584.\n",
      "[I 2024-05-02 13:49:42,871] Trial 56 finished with value: 0.47172017531244326 and parameters: {'hidden_layer_sizes': 117, 'activation': 'relu', 'solver': 'adam', 'alpha': 0.2613563794553354, 'learning_rate_init': 0.0012547487401949997, 'max_iter': 343, 'random_state': 17}. Best is trial 30 with value: 0.46819210181649584.\n",
      "[I 2024-05-02 13:49:58,214] Trial 57 finished with value: 0.4720544968727796 and parameters: {'hidden_layer_sizes': 129, 'activation': 'relu', 'solver': 'adam', 'alpha': 0.2054462007836433, 'learning_rate_init': 0.001942771620669842, 'max_iter': 175, 'random_state': 17}. Best is trial 30 with value: 0.46819210181649584.\n",
      "[I 2024-05-02 13:50:14,650] Trial 58 finished with value: 0.49898716029854545 and parameters: {'hidden_layer_sizes': 139, 'activation': 'relu', 'solver': 'sgd', 'alpha': 0.2872726957483762, 'learning_rate_init': 0.0017063440977035345, 'max_iter': 150, 'random_state': 17}. Best is trial 30 with value: 0.46819210181649584.\n",
      "[I 2024-05-02 13:50:26,250] Trial 59 finished with value: 0.4724963555824651 and parameters: {'hidden_layer_sizes': 150, 'activation': 'relu', 'solver': 'adam', 'alpha': 0.23659828549670373, 'learning_rate_init': 0.0021427707624770945, 'max_iter': 323, 'random_state': 17}. Best is trial 30 with value: 0.46819210181649584.\n",
      "[I 2024-05-02 13:50:43,738] Trial 60 finished with value: 0.48304078414845353 and parameters: {'hidden_layer_sizes': 136, 'activation': 'tanh', 'solver': 'adam', 'alpha': 0.1616537596854798, 'learning_rate_init': 0.001130229950604746, 'max_iter': 163, 'random_state': 17}. Best is trial 30 with value: 0.46819210181649584.\n",
      "[I 2024-05-02 13:50:56,363] Trial 61 finished with value: 0.4738589306880467 and parameters: {'hidden_layer_sizes': 119, 'activation': 'relu', 'solver': 'adam', 'alpha': 0.3161714969616738, 'learning_rate_init': 0.0016054969042191035, 'max_iter': 166, 'random_state': 17}. Best is trial 30 with value: 0.46819210181649584.\n",
      "[I 2024-05-02 13:51:13,084] Trial 62 finished with value: 0.46745733529339023 and parameters: {'hidden_layer_sizes': 128, 'activation': 'relu', 'solver': 'adam', 'alpha': 0.2928504907398234, 'learning_rate_init': 0.0013911875532228446, 'max_iter': 179, 'random_state': 17}. Best is trial 62 with value: 0.46745733529339023.\n",
      "[I 2024-05-02 13:51:28,601] Trial 63 finished with value: 0.47009418684488774 and parameters: {'hidden_layer_sizes': 127, 'activation': 'relu', 'solver': 'adam', 'alpha': 0.29730105973985865, 'learning_rate_init': 0.001375523668608483, 'max_iter': 180, 'random_state': 17}. Best is trial 62 with value: 0.46745733529339023.\n",
      "[I 2024-05-02 13:51:39,710] Trial 64 finished with value: 0.46774393680554366 and parameters: {'hidden_layer_sizes': 146, 'activation': 'relu', 'solver': 'adam', 'alpha': 0.28215392584251037, 'learning_rate_init': 0.001784010467295247, 'max_iter': 191, 'random_state': 17}. Best is trial 62 with value: 0.46745733529339023.\n",
      "[I 2024-05-02 13:51:50,642] Trial 65 finished with value: 0.468146526930503 and parameters: {'hidden_layer_sizes': 146, 'activation': 'relu', 'solver': 'adam', 'alpha': 0.27687927095554293, 'learning_rate_init': 0.0019858635416131138, 'max_iter': 190, 'random_state': 17}. Best is trial 62 with value: 0.46745733529339023.\n",
      "[I 2024-05-02 13:52:01,873] Trial 66 finished with value: 0.4690933096905825 and parameters: {'hidden_layer_sizes': 146, 'activation': 'relu', 'solver': 'adam', 'alpha': 0.29288411724283936, 'learning_rate_init': 0.002023791586433258, 'max_iter': 189, 'random_state': 17}. Best is trial 62 with value: 0.46745733529339023.\n",
      "[I 2024-05-02 13:52:13,653] Trial 67 finished with value: 0.4679013666977171 and parameters: {'hidden_layer_sizes': 146, 'activation': 'relu', 'solver': 'adam', 'alpha': 0.2801333001284284, 'learning_rate_init': 0.002004397475795607, 'max_iter': 193, 'random_state': 17}. Best is trial 62 with value: 0.46745733529339023.\n",
      "[I 2024-05-02 13:52:25,011] Trial 68 finished with value: 0.4681856403082688 and parameters: {'hidden_layer_sizes': 146, 'activation': 'relu', 'solver': 'adam', 'alpha': 0.2907240606858351, 'learning_rate_init': 0.0020554302944967707, 'max_iter': 193, 'random_state': 17}. Best is trial 62 with value: 0.46745733529339023.\n",
      "[I 2024-05-02 13:52:46,773] Trial 69 finished with value: 0.49170843444139906 and parameters: {'hidden_layer_sizes': 150, 'activation': 'relu', 'solver': 'sgd', 'alpha': 0.2759891624391789, 'learning_rate_init': 0.0021643799293040557, 'max_iter': 197, 'random_state': 17}. Best is trial 62 with value: 0.46745733529339023.\n",
      "[I 2024-05-02 13:52:57,002] Trial 70 finished with value: 0.4758965710001514 and parameters: {'hidden_layer_sizes': 140, 'activation': 'relu', 'solver': 'adam', 'alpha': 0.3197548795465555, 'learning_rate_init': 0.002584972835463468, 'max_iter': 221, 'random_state': 17}. Best is trial 62 with value: 0.46745733529339023.\n",
      "[I 2024-05-02 13:53:09,325] Trial 71 finished with value: 0.46800706300969547 and parameters: {'hidden_layer_sizes': 146, 'activation': 'relu', 'solver': 'adam', 'alpha': 0.2915713369370877, 'learning_rate_init': 0.002016151032922943, 'max_iter': 193, 'random_state': 17}. Best is trial 62 with value: 0.46745733529339023.\n",
      "[I 2024-05-02 13:53:21,034] Trial 72 finished with value: 0.468588943935785 and parameters: {'hidden_layer_sizes': 146, 'activation': 'relu', 'solver': 'adam', 'alpha': 0.29496189773194414, 'learning_rate_init': 0.0023215303765777265, 'max_iter': 193, 'random_state': 17}. Best is trial 62 with value: 0.46745733529339023.\n",
      "[I 2024-05-02 13:53:32,568] Trial 73 finished with value: 0.4704238557183863 and parameters: {'hidden_layer_sizes': 150, 'activation': 'relu', 'solver': 'adam', 'alpha': 0.2662531527196512, 'learning_rate_init': 0.002027443454092945, 'max_iter': 203, 'random_state': 17}. Best is trial 62 with value: 0.46745733529339023.\n",
      "[I 2024-05-02 13:53:44,015] Trial 74 finished with value: 0.46903924409640824 and parameters: {'hidden_layer_sizes': 145, 'activation': 'relu', 'solver': 'adam', 'alpha': 0.27756733534389705, 'learning_rate_init': 0.001767623430035129, 'max_iter': 210, 'random_state': 17}. Best is trial 62 with value: 0.46745733529339023.\n",
      "[I 2024-05-02 13:53:55,641] Trial 75 finished with value: 0.4698232650202582 and parameters: {'hidden_layer_sizes': 141, 'activation': 'relu', 'solver': 'adam', 'alpha': 0.30986271619400746, 'learning_rate_init': 0.0019188264979506666, 'max_iter': 182, 'random_state': 17}. Best is trial 62 with value: 0.46745733529339023.\n",
      "[I 2024-05-02 13:54:06,658] Trial 76 finished with value: 0.4678107443886952 and parameters: {'hidden_layer_sizes': 137, 'activation': 'relu', 'solver': 'adam', 'alpha': 0.24964135870153503, 'learning_rate_init': 0.002289907414402049, 'max_iter': 190, 'random_state': 17}. Best is trial 62 with value: 0.46745733529339023.\n",
      "[I 2024-05-02 13:54:16,933] Trial 77 finished with value: 0.4779074160153118 and parameters: {'hidden_layer_sizes': 138, 'activation': 'relu', 'solver': 'adam', 'alpha': 0.24786966439621047, 'learning_rate_init': 0.0023281350718459526, 'max_iter': 189, 'random_state': 17}. Best is trial 62 with value: 0.46745733529339023.\n",
      "[I 2024-05-02 13:54:28,967] Trial 78 finished with value: 0.48252769946276663 and parameters: {'hidden_layer_sizes': 135, 'activation': 'tanh', 'solver': 'adam', 'alpha': 0.22401287647044843, 'learning_rate_init': 0.0021229582009229257, 'max_iter': 206, 'random_state': 17}. Best is trial 62 with value: 0.46745733529339023.\n",
      "[I 2024-05-02 13:54:39,464] Trial 79 finished with value: 0.4754419913751945 and parameters: {'hidden_layer_sizes': 148, 'activation': 'relu', 'solver': 'adam', 'alpha': 0.28261513896356166, 'learning_rate_init': 0.0024953233289245775, 'max_iter': 219, 'random_state': 17}. Best is trial 62 with value: 0.46745733529339023.\n",
      "[I 2024-05-02 13:54:49,099] Trial 80 finished with value: 0.47386423501845076 and parameters: {'hidden_layer_sizes': 140, 'activation': 'relu', 'solver': 'adam', 'alpha': 0.24955765427836715, 'learning_rate_init': 0.0022748361039816745, 'max_iter': 213, 'random_state': 17}. Best is trial 62 with value: 0.46745733529339023.\n",
      "[I 2024-05-02 13:55:01,940] Trial 81 finished with value: 0.4659013624537218 and parameters: {'hidden_layer_sizes': 143, 'activation': 'relu', 'solver': 'adam', 'alpha': 0.27081178344047946, 'learning_rate_init': 0.0019615393918952393, 'max_iter': 192, 'random_state': 17}. Best is trial 81 with value: 0.4659013624537218.\n",
      "[I 2024-05-02 13:55:15,178] Trial 82 finished with value: 0.46663931499222067 and parameters: {'hidden_layer_sizes': 148, 'activation': 'relu', 'solver': 'adam', 'alpha': 0.3014679499605711, 'learning_rate_init': 0.0020411100398848546, 'max_iter': 201, 'random_state': 17}. Best is trial 81 with value: 0.4659013624537218.\n",
      "[I 2024-05-02 13:55:26,549] Trial 83 finished with value: 0.4704707226112289 and parameters: {'hidden_layer_sizes': 147, 'activation': 'relu', 'solver': 'adam', 'alpha': 0.29737280225310053, 'learning_rate_init': 0.0020240412550647778, 'max_iter': 199, 'random_state': 17}. Best is trial 81 with value: 0.4659013624537218.\n",
      "[I 2024-05-02 13:55:35,594] Trial 84 finished with value: 0.47350683939092547 and parameters: {'hidden_layer_sizes': 138, 'activation': 'relu', 'solver': 'adam', 'alpha': 0.27024853162263823, 'learning_rate_init': 0.0022006154840976126, 'max_iter': 182, 'random_state': 17}. Best is trial 81 with value: 0.4659013624537218.\n",
      "[I 2024-05-02 13:55:48,981] Trial 85 finished with value: 0.47321970091951837 and parameters: {'hidden_layer_sizes': 96, 'activation': 'relu', 'solver': 'adam', 'alpha': 0.28540387517973315, 'learning_rate_init': 0.0019534258654042916, 'max_iter': 203, 'random_state': 17}. Best is trial 81 with value: 0.4659013624537218.\n",
      "[I 2024-05-02 13:56:01,313] Trial 86 finished with value: 0.4703184554976116 and parameters: {'hidden_layer_sizes': 142, 'activation': 'relu', 'solver': 'adam', 'alpha': 0.3026770402327547, 'learning_rate_init': 0.0017406223924978186, 'max_iter': 192, 'random_state': 17}. Best is trial 81 with value: 0.4659013624537218.\n",
      "[I 2024-05-02 13:56:12,432] Trial 87 finished with value: 0.4663140456801071 and parameters: {'hidden_layer_sizes': 145, 'activation': 'relu', 'solver': 'adam', 'alpha': 0.2708969201109124, 'learning_rate_init': 0.0020988773689177348, 'max_iter': 186, 'random_state': 17}. Best is trial 81 with value: 0.4659013624537218.\n",
      "[I 2024-05-02 13:56:28,762] Trial 88 finished with value: 0.4944765526001021 and parameters: {'hidden_layer_sizes': 78, 'activation': 'relu', 'solver': 'sgd', 'alpha': 0.25835282810895094, 'learning_rate_init': 0.002424071844834766, 'max_iter': 184, 'random_state': 17}. Best is trial 81 with value: 0.4659013624537218.\n",
      "[I 2024-05-02 13:56:42,002] Trial 89 finished with value: 0.4660175644020453 and parameters: {'hidden_layer_sizes': 148, 'activation': 'relu', 'solver': 'adam', 'alpha': 0.2729813321345955, 'learning_rate_init': 0.0018771314711008914, 'max_iter': 208, 'random_state': 17}. Best is trial 81 with value: 0.4659013624537218.\n",
      "[I 2024-05-02 13:56:58,545] Trial 90 finished with value: 0.48542070473711413 and parameters: {'hidden_layer_sizes': 149, 'activation': 'tanh', 'solver': 'adam', 'alpha': 0.23628485954821232, 'learning_rate_init': 0.001797629291017763, 'max_iter': 207, 'random_state': 17}. Best is trial 81 with value: 0.4659013624537218.\n",
      "[I 2024-05-02 13:57:11,331] Trial 91 finished with value: 0.47247424571282115 and parameters: {'hidden_layer_sizes': 144, 'activation': 'relu', 'solver': 'adam', 'alpha': 0.2661559415002764, 'learning_rate_init': 0.001876156514330551, 'max_iter': 200, 'random_state': 17}. Best is trial 81 with value: 0.4659013624537218.\n",
      "[I 2024-05-02 13:57:21,758] Trial 92 finished with value: 0.4692109682668534 and parameters: {'hidden_layer_sizes': 145, 'activation': 'relu', 'solver': 'adam', 'alpha': 0.2785790708776307, 'learning_rate_init': 0.0021219350415036054, 'max_iter': 177, 'random_state': 17}. Best is trial 81 with value: 0.4659013624537218.\n",
      "[I 2024-05-02 13:57:37,893] Trial 93 finished with value: 0.4676884342388967 and parameters: {'hidden_layer_sizes': 137, 'activation': 'relu', 'solver': 'adam', 'alpha': 0.2540499173532697, 'learning_rate_init': 0.0015296877436483346, 'max_iter': 212, 'random_state': 17}. Best is trial 81 with value: 0.4659013624537218.\n",
      "[I 2024-05-02 13:57:50,289] Trial 94 finished with value: 0.4694927721378496 and parameters: {'hidden_layer_sizes': 137, 'activation': 'relu', 'solver': 'adam', 'alpha': 0.2582119848441485, 'learning_rate_init': 0.0015148823290409975, 'max_iter': 222, 'random_state': 17}. Best is trial 81 with value: 0.4659013624537218.\n",
      "[I 2024-05-02 13:58:03,438] Trial 95 finished with value: 0.47097122513231504 and parameters: {'hidden_layer_sizes': 134, 'activation': 'relu', 'solver': 'adam', 'alpha': 0.3045824429545184, 'learning_rate_init': 0.0016990637550180934, 'max_iter': 213, 'random_state': 17}. Best is trial 81 with value: 0.4659013624537218.\n",
      "[I 2024-05-02 13:58:16,734] Trial 96 finished with value: 0.47091054177114433 and parameters: {'hidden_layer_sizes': 142, 'activation': 'relu', 'solver': 'adam', 'alpha': 0.24815989710660957, 'learning_rate_init': 0.0014565225728098172, 'max_iter': 186, 'random_state': 17}. Best is trial 81 with value: 0.4659013624537218.\n",
      "[I 2024-05-02 13:58:30,176] Trial 97 finished with value: 0.4666375556781217 and parameters: {'hidden_layer_sizes': 148, 'activation': 'relu', 'solver': 'adam', 'alpha': 0.2715880792572277, 'learning_rate_init': 0.0016185607574681102, 'max_iter': 201, 'random_state': 17}. Best is trial 81 with value: 0.4659013624537218.\n",
      "[I 2024-05-02 13:58:41,756] Trial 98 finished with value: 0.46690288555656156 and parameters: {'hidden_layer_sizes': 140, 'activation': 'relu', 'solver': 'adam', 'alpha': 0.2707329197852816, 'learning_rate_init': 0.0016073311575892533, 'max_iter': 224, 'random_state': 17}. Best is trial 81 with value: 0.4659013624537218.\n",
      "[I 2024-05-02 13:58:52,514] Trial 99 finished with value: 0.46747812579735226 and parameters: {'hidden_layer_sizes': 140, 'activation': 'relu', 'solver': 'adam', 'alpha': 0.26900124649946044, 'learning_rate_init': 0.0015812379911371724, 'max_iter': 239, 'random_state': 17}. Best is trial 81 with value: 0.4659013624537218.\n"
     ]
    }
   ],
   "source": [
    "params_dict = {\n",
    "    \"hidden_layer_sizes\": (\"int\", [50, 150]),\n",
    "    \"activation\": (\"categorical\", [\"tanh\", \"relu\"]),\n",
    "    \"solver\": (\"categorical\", [\"sgd\", \"adam\"]),\n",
    "    \"alpha\": (\"float\", [0.005, 0.5]),\n",
    "    \"learning_rate_init\": (\"float\", [0.0005, 0.005]),\n",
    "    \"max_iter\": (\"int\", [150, 350]),\n",
    "    \"random_state\": (\"constant\", SEED),\n",
    "}\n",
    "CV = RandomSearchCV(\n",
    "    algorithm=MLPRegressor(random_state=SEED),\n",
    "    metric=\"rmse\",\n",
    "    cv=KFold(n_splits=5, shuffle=True, random_state=SEED),\n",
    "    n_trials=100,\n",
    "    seed=SEED,\n",
    ")\n",
    "train_data_scaled = train_data.copy()\n",
    "train_data_scaled[continous_features] = scaler.fit_transform(train_data_scaled[continous_features])\n",
    "train_data_scaled[target] = scaler.fit_transform(train_data_scaled[target].values.reshape(-1, 1)).ravel()\n",
    "best_params = CV.tune(train_data_scaled[features], train_data_scaled[target], params_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_f80c0_row0_col1, #T_f80c0_row1_col2, #T_f80c0_row1_col3 {\n",
       "  background-color: #fff5f0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f80c0_row0_col2, #T_f80c0_row0_col3, #T_f80c0_row1_col1 {\n",
       "  background-color: #67000d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_f80c0\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_f80c0_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_f80c0_level0_col1\" class=\"col_heading level0 col1\" >Train RMSE</th>\n",
       "      <th id=\"T_f80c0_level0_col2\" class=\"col_heading level0 col2\" >Validation RMSE</th>\n",
       "      <th id=\"T_f80c0_level0_col3\" class=\"col_heading level0 col3\" >Test RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_f80c0_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_f80c0_row0_col0\" class=\"data row0 col0\" >Base</td>\n",
       "      <td id=\"T_f80c0_row0_col1\" class=\"data row0 col1\" >0.136297</td>\n",
       "      <td id=\"T_f80c0_row0_col2\" class=\"data row0 col2\" >0.199309</td>\n",
       "      <td id=\"T_f80c0_row0_col3\" class=\"data row0 col3\" >0.202214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f80c0_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_f80c0_row1_col0\" class=\"data row1 col0\" >Tuning</td>\n",
       "      <td id=\"T_f80c0_row1_col1\" class=\"data row1 col1\" >0.157285</td>\n",
       "      <td id=\"T_f80c0_row1_col2\" class=\"data row1 col2\" >0.192559</td>\n",
       "      <td id=\"T_f80c0_row1_col3\" class=\"data row1 col3\" >0.196598</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1c9102cfcd0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model bazowy\n",
    "model = MLPRegressor(random_state=SEED)\n",
    "base_train_scores, base_validation_scores = perform_cv_scaling(train_data[features], train_data[target], model, scaler=scaler, features_to_scale=continous_features, target_to_scale=True)\n",
    "base_test_score = test_evaluation_scaling(train_data[features], train_data[target], test_data[features], test_data[target], model, scaler=scaler, features_to_scale=continous_features, target_to_scale=True)\n",
    "#Tuning\n",
    "model = MLPRegressor(**best_params)\n",
    "tuning_train_scores, tuning_validation_scores = perform_cv_scaling(train_data[features], train_data[target], model, scaler=scaler, features_to_scale=continous_features, target_to_scale=True)\n",
    "tuning_test_score = test_evaluation_scaling(train_data[features], train_data[target], test_data[features], test_data[target], model, scaler=scaler, features_to_scale=continous_features, target_to_scale=True)\n",
    "results = pd.DataFrame({\n",
    "    \"Model\": [\"Base\", \"Tuning\"],\n",
    "    \"Train RMSE\": [base_train_scores, tuning_train_scores],\n",
    "    \"Validation RMSE\": [base_validation_scores, tuning_validation_scores],\n",
    "    \"Test RMSE\": [base_test_score, tuning_test_score]\n",
    "})\n",
    "results.style.background_gradient(cmap='Reds', axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\text{Optymalizacja hiperparametrów modelu pozwoliła na uzyskanie lepszych wyników na zbiorze walidacyjnym oraz testowym.}$<p>\n",
    "$\\text{Co prawda rezultaty są nieco gorsze niż dla Ensemblingu, ale różnica nie jest duża (Sieć neuronowa: 0.196598; Ensembling: 0.196046).}$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
