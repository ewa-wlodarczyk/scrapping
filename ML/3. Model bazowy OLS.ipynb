{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a92b3f1",
   "metadata": {},
   "source": [
    "# Import bibliotek i danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57d73554",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor \n",
    "import statsmodels.api as sm\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import *\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy import stats\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pickle\n",
    "import typing\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "SEED = 17"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e762285a",
   "metadata": {},
   "source": [
    "# Ładowanie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "474174bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pages</th>\n",
       "      <th>stars</th>\n",
       "      <th>reviews</th>\n",
       "      <th>series</th>\n",
       "      <th>mix</th>\n",
       "      <th>character</th>\n",
       "      <th>plot</th>\n",
       "      <th>funny</th>\n",
       "      <th>lighthearted</th>\n",
       "      <th>emotional</th>\n",
       "      <th>...</th>\n",
       "      <th>author_stars</th>\n",
       "      <th>Fiction</th>\n",
       "      <th>Nonfiction</th>\n",
       "      <th>Literary</th>\n",
       "      <th>Fantasy</th>\n",
       "      <th>Crime</th>\n",
       "      <th>Social</th>\n",
       "      <th>Children</th>\n",
       "      <th>Romans</th>\n",
       "      <th>Realism</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>273</td>\n",
       "      <td>4.00</td>\n",
       "      <td>2017</td>\n",
       "      <td>0</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.91</td>\n",
       "      <td>...</td>\n",
       "      <td>4.305000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>302</td>\n",
       "      <td>3.78</td>\n",
       "      <td>7330</td>\n",
       "      <td>0</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.18</td>\n",
       "      <td>...</td>\n",
       "      <td>3.670000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>400</td>\n",
       "      <td>4.15</td>\n",
       "      <td>16761</td>\n",
       "      <td>0</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.88</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>459</td>\n",
       "      <td>4.16</td>\n",
       "      <td>2128</td>\n",
       "      <td>1</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>160</td>\n",
       "      <td>3.65</td>\n",
       "      <td>6634</td>\n",
       "      <td>1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>4.115000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6925</th>\n",
       "      <td>432</td>\n",
       "      <td>4.15</td>\n",
       "      <td>30643</td>\n",
       "      <td>0</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.40</td>\n",
       "      <td>...</td>\n",
       "      <td>3.856667</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6926</th>\n",
       "      <td>352</td>\n",
       "      <td>3.62</td>\n",
       "      <td>1058</td>\n",
       "      <td>0</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6927</th>\n",
       "      <td>535</td>\n",
       "      <td>3.88</td>\n",
       "      <td>30975</td>\n",
       "      <td>1</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.31</td>\n",
       "      <td>...</td>\n",
       "      <td>3.870000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6928</th>\n",
       "      <td>472</td>\n",
       "      <td>3.88</td>\n",
       "      <td>5914</td>\n",
       "      <td>1</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.36</td>\n",
       "      <td>...</td>\n",
       "      <td>3.660000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6929</th>\n",
       "      <td>350</td>\n",
       "      <td>4.27</td>\n",
       "      <td>67909</td>\n",
       "      <td>0</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.78</td>\n",
       "      <td>...</td>\n",
       "      <td>4.315833</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6930 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pages  stars  reviews  series   mix  character  plot  funny  \\\n",
       "0       273   4.00     2017       0  0.44       0.51  0.02   0.27   \n",
       "1       302   3.78     7330       0  0.39       0.42  0.17   0.03   \n",
       "2       400   4.15    16761       0  0.51       0.39  0.08   0.02   \n",
       "3       459   4.16     2128       1  0.48       0.10  0.40   0.04   \n",
       "4       160   3.65     6634       1  0.28       0.16  0.54   0.92   \n",
       "...     ...    ...      ...     ...   ...        ...   ...    ...   \n",
       "6925    432   4.15    30643       0  0.48       0.05  0.46   0.00   \n",
       "6926    352   3.62     1058       0  0.55       0.13  0.30   0.15   \n",
       "6927    535   3.88    30975       1  0.45       0.08  0.45   0.14   \n",
       "6928    472   3.88     5914       1  0.64       0.12  0.22   0.07   \n",
       "6929    350   4.27    67909       0  0.37       0.56  0.05   0.74   \n",
       "\n",
       "      lighthearted  emotional  ...  author_stars  Fiction  Nonfiction  \\\n",
       "0             0.37       0.91  ...      4.305000        1           1   \n",
       "1             0.01       0.18  ...      3.670000        1           0   \n",
       "2             0.01       0.88  ...      0.000000        1           0   \n",
       "3             0.02       0.07  ...      0.000000        1           0   \n",
       "4             0.73       0.00  ...      4.115000        1           0   \n",
       "...            ...        ...  ...           ...      ...         ...   \n",
       "6925          0.00       0.40  ...      3.856667        1           0   \n",
       "6926          0.10       0.25  ...      3.700000        1           0   \n",
       "6927          0.19       0.31  ...      3.870000        1           0   \n",
       "6928          0.00       0.36  ...      3.660000        1           0   \n",
       "6929          0.28       0.78  ...      4.315833        1           0   \n",
       "\n",
       "      Literary  Fantasy  Crime  Social  Children  Romans  Realism  \n",
       "0            0        0      0       1         0       1        1  \n",
       "1            0        0      1       0         0       0        0  \n",
       "2            1        0      0       0         0       0        0  \n",
       "3            0        1      0       0         0       0        0  \n",
       "4            0        1      0       0         0       0        0  \n",
       "...        ...      ...    ...     ...       ...     ...      ...  \n",
       "6925         0        1      1       0         0       0        0  \n",
       "6926         0        1      0       1         0       0        0  \n",
       "6927         0        1      0       0         1       0        0  \n",
       "6928         0        1      0       0         1       0        0  \n",
       "6929         1        0      1       0         0       0        1  \n",
       "\n",
       "[6930 rows x 32 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv(\"../data/data_eda.csv\")\n",
    "data=data.drop(columns=['Unnamed: 0'])\n",
    "features=data.columns.tolist()\n",
    "features.remove('stars')\n",
    "target='stars'\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ebb9e8",
   "metadata": {},
   "source": [
    "$\\text{Podział danych na zbiór treningowy i testowy}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f42e0721",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1686cb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_cv(X: pd.DataFrame, y: pd.Series, algorithm: typing.Any, cv: typing.Any = KFold(n_splits=5, shuffle=True, random_state=SEED), metric: typing.Any = mean_squared_error) -> typing.List[float]:\n",
    "    \"\"\"\n",
    "    Perform cross-validation and return list of scores\n",
    "    \n",
    "    Args:\n",
    "        X (pd.DataFrame): input data\n",
    "        y (pd.Series): target data\n",
    "        algorithm (typing.Any): algorithm to use for training and prediction\n",
    "        cv (typing.Any): cross-validation strategy\n",
    "        metric (typing.Any): metric to use for evaluation\n",
    "    \n",
    "    Returns:\n",
    "        typing.List[float]: list of scores in order: train_scores, validation_scores\n",
    "    \"\"\"\n",
    "    train_scores = []\n",
    "    validation_scores = []\n",
    "    for train_idx, val_idx in cv.split(X, y):\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "        algorithm.fit(X_train, y_train)\n",
    "        y_train_pred = algorithm.predict(X_train)\n",
    "        y_val_pred = algorithm.predict(X_val)\n",
    "        train_scores.append(metric(y_train, y_train_pred, squared=False))\n",
    "        validation_scores.append(metric(y_val, y_val_pred, squared=False))\n",
    "    return np.mean(train_scores), np.mean(validation_scores)\n",
    "\n",
    "def evaluation(X_train: pd.DataFrame, y_train: pd.Series, X_test: pd.DataFrame, y_test: pd.Series, algorithm: typing.Any, metric: typing.Any = mean_squared_error) -> typing.Tuple[float, float, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Train the algorithm on the train data and evaluate on the train and test data\n",
    "    \n",
    "    Args:\n",
    "        X_train (pd.DataFrame): input train data\n",
    "        y_train (pd.Series): target train data\n",
    "        X_test (pd.DataFrame): input test data\n",
    "        y_test (pd.Series): target test data\n",
    "        algorithm (typing.Any): algorithm to use for training and prediction\n",
    "        metric (typing.Any): metric to use for evaluation\n",
    "    \n",
    "    Returns:\n",
    "        typing.Tuple[float, float, np.ndarray]: train_score, test_score, predictions on test data\n",
    "    \"\"\"\n",
    "    algorithm.fit(X_train, y_train)\n",
    "    y_train_pred = algorithm.predict(X_train)\n",
    "    y_test_pred = algorithm.predict(X_test)\n",
    "    train_results = metric(y_train, y_train_pred, squared=False)\n",
    "    test_results = metric(y_test, y_test_pred, squared=False)\n",
    "    return train_results, test_results, y_test_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85554d4",
   "metadata": {},
   "source": [
    "### Najbardziej podstawowy model (bez feature engineeringu):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "edf8e210",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>stars</td>      <th>  R-squared:         </th> <td>   0.464</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.461</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   153.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 11 May 2024</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>19:38:29</td>     <th>  Log-Likelihood:    </th> <td>  512.46</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  5544</td>      <th>  AIC:               </th> <td>  -960.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  5512</td>      <th>  BIC:               </th> <td>  -749.1</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    31</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>    <td>    3.0217</td> <td>    0.036</td> <td>   84.278</td> <td> 0.000</td> <td>    2.951</td> <td>    3.092</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pages</th>        <td> -2.24e-05</td> <td> 2.22e-05</td> <td>   -1.008</td> <td> 0.314</td> <td> -6.6e-05</td> <td> 2.12e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>reviews</th>      <td> 1.023e-06</td> <td> 1.23e-07</td> <td>    8.348</td> <td> 0.000</td> <td> 7.83e-07</td> <td> 1.26e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>series</th>       <td>    0.0708</td> <td>    0.008</td> <td>    8.948</td> <td> 0.000</td> <td>    0.055</td> <td>    0.086</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mix</th>          <td>    0.0731</td> <td>    0.033</td> <td>    2.238</td> <td> 0.025</td> <td>    0.009</td> <td>    0.137</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>character</th>    <td>   -0.0894</td> <td>    0.027</td> <td>   -3.357</td> <td> 0.001</td> <td>   -0.142</td> <td>   -0.037</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>plot</th>         <td>   -0.1755</td> <td>    0.038</td> <td>   -4.609</td> <td> 0.000</td> <td>   -0.250</td> <td>   -0.101</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>funny</th>        <td>    0.4076</td> <td>    0.021</td> <td>   19.274</td> <td> 0.000</td> <td>    0.366</td> <td>    0.449</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lighthearted</th> <td>   -0.0356</td> <td>    0.036</td> <td>   -0.987</td> <td> 0.324</td> <td>   -0.106</td> <td>    0.035</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>emotional</th>    <td>    0.3759</td> <td>    0.028</td> <td>   13.635</td> <td> 0.000</td> <td>    0.322</td> <td>    0.430</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>hopeful</th>      <td>    0.2907</td> <td>    0.039</td> <td>    7.535</td> <td> 0.000</td> <td>    0.215</td> <td>    0.366</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>inspiring</th>    <td>    0.2729</td> <td>    0.036</td> <td>    7.544</td> <td> 0.000</td> <td>    0.202</td> <td>    0.344</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>relaxing</th>     <td>    0.7907</td> <td>    0.075</td> <td>   10.521</td> <td> 0.000</td> <td>    0.643</td> <td>    0.938</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tense</th>        <td>    0.2778</td> <td>    0.033</td> <td>    8.393</td> <td> 0.000</td> <td>    0.213</td> <td>    0.343</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sad</th>          <td>    0.2105</td> <td>    0.029</td> <td>    7.289</td> <td> 0.000</td> <td>    0.154</td> <td>    0.267</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>reflective</th>   <td>   -0.0111</td> <td>    0.028</td> <td>   -0.403</td> <td> 0.687</td> <td>   -0.065</td> <td>    0.043</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>adventurous</th>  <td>    0.1818</td> <td>    0.019</td> <td>    9.746</td> <td> 0.000</td> <td>    0.145</td> <td>    0.218</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>challenging</th>  <td>    0.4286</td> <td>    0.030</td> <td>   14.496</td> <td> 0.000</td> <td>    0.371</td> <td>    0.487</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>informative</th>  <td>    0.4146</td> <td>    0.025</td> <td>   16.538</td> <td> 0.000</td> <td>    0.365</td> <td>    0.464</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mysterious</th>   <td>    0.1753</td> <td>    0.020</td> <td>    8.930</td> <td> 0.000</td> <td>    0.137</td> <td>    0.214</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>dark</th>         <td>   -0.0036</td> <td>    0.022</td> <td>   -0.169</td> <td> 0.866</td> <td>   -0.046</td> <td>    0.039</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>author_count</th> <td>    0.0025</td> <td>    0.000</td> <td>    5.206</td> <td> 0.000</td> <td>    0.002</td> <td>    0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>author_stars</th> <td>    0.0187</td> <td>    0.002</td> <td>   10.596</td> <td> 0.000</td> <td>    0.015</td> <td>    0.022</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Fiction</th>      <td>    0.0786</td> <td>    0.032</td> <td>    2.461</td> <td> 0.014</td> <td>    0.016</td> <td>    0.141</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Nonfiction</th>   <td>    0.1668</td> <td>    0.017</td> <td>    9.681</td> <td> 0.000</td> <td>    0.133</td> <td>    0.201</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Literary</th>     <td>    0.0280</td> <td>    0.008</td> <td>    3.437</td> <td> 0.001</td> <td>    0.012</td> <td>    0.044</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Fantasy</th>      <td>    0.0242</td> <td>    0.010</td> <td>    2.364</td> <td> 0.018</td> <td>    0.004</td> <td>    0.044</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Crime</th>        <td>    0.0053</td> <td>    0.012</td> <td>    0.436</td> <td> 0.663</td> <td>   -0.018</td> <td>    0.029</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Social</th>       <td>    0.0530</td> <td>    0.009</td> <td>    6.132</td> <td> 0.000</td> <td>    0.036</td> <td>    0.070</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Children</th>     <td>   -0.0269</td> <td>    0.009</td> <td>   -3.148</td> <td> 0.002</td> <td>   -0.044</td> <td>   -0.010</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Romans</th>       <td>   -0.0634</td> <td>    0.010</td> <td>   -6.224</td> <td> 0.000</td> <td>   -0.083</td> <td>   -0.043</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Realism</th>      <td>   -0.0499</td> <td>    0.009</td> <td>   -5.621</td> <td> 0.000</td> <td>   -0.067</td> <td>   -0.033</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>206.478</td> <th>  Durbin-Watson:     </th> <td>   2.014</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 306.045</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.360</td>  <th>  Prob(JB):          </th> <td>3.49e-67</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.898</td>  <th>  Cond. No.          </th> <td>7.68e+05</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 7.68e+05. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &      stars       & \\textbf{  R-squared:         } &     0.464   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.461   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     153.9   \\\\\n",
       "\\textbf{Date:}             & Sat, 11 May 2024 & \\textbf{  Prob (F-statistic):} &     0.00    \\\\\n",
       "\\textbf{Time:}             &     19:38:29     & \\textbf{  Log-Likelihood:    } &    512.46   \\\\\n",
       "\\textbf{No. Observations:} &        5544      & \\textbf{  AIC:               } &    -960.9   \\\\\n",
       "\\textbf{Df Residuals:}     &        5512      & \\textbf{  BIC:               } &    -749.1   \\\\\n",
       "\\textbf{Df Model:}         &          31      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                       & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept}     &       3.0217  &        0.036     &    84.278  &         0.000        &        2.951    &        3.092     \\\\\n",
       "\\textbf{pages}         &    -2.24e-05  &     2.22e-05     &    -1.008  &         0.314        &     -6.6e-05    &     2.12e-05     \\\\\n",
       "\\textbf{reviews}       &    1.023e-06  &     1.23e-07     &     8.348  &         0.000        &     7.83e-07    &     1.26e-06     \\\\\n",
       "\\textbf{series}        &       0.0708  &        0.008     &     8.948  &         0.000        &        0.055    &        0.086     \\\\\n",
       "\\textbf{mix}           &       0.0731  &        0.033     &     2.238  &         0.025        &        0.009    &        0.137     \\\\\n",
       "\\textbf{character}     &      -0.0894  &        0.027     &    -3.357  &         0.001        &       -0.142    &       -0.037     \\\\\n",
       "\\textbf{plot}          &      -0.1755  &        0.038     &    -4.609  &         0.000        &       -0.250    &       -0.101     \\\\\n",
       "\\textbf{funny}         &       0.4076  &        0.021     &    19.274  &         0.000        &        0.366    &        0.449     \\\\\n",
       "\\textbf{lighthearted}  &      -0.0356  &        0.036     &    -0.987  &         0.324        &       -0.106    &        0.035     \\\\\n",
       "\\textbf{emotional}     &       0.3759  &        0.028     &    13.635  &         0.000        &        0.322    &        0.430     \\\\\n",
       "\\textbf{hopeful}       &       0.2907  &        0.039     &     7.535  &         0.000        &        0.215    &        0.366     \\\\\n",
       "\\textbf{inspiring}     &       0.2729  &        0.036     &     7.544  &         0.000        &        0.202    &        0.344     \\\\\n",
       "\\textbf{relaxing}      &       0.7907  &        0.075     &    10.521  &         0.000        &        0.643    &        0.938     \\\\\n",
       "\\textbf{tense}         &       0.2778  &        0.033     &     8.393  &         0.000        &        0.213    &        0.343     \\\\\n",
       "\\textbf{sad}           &       0.2105  &        0.029     &     7.289  &         0.000        &        0.154    &        0.267     \\\\\n",
       "\\textbf{reflective}    &      -0.0111  &        0.028     &    -0.403  &         0.687        &       -0.065    &        0.043     \\\\\n",
       "\\textbf{adventurous}   &       0.1818  &        0.019     &     9.746  &         0.000        &        0.145    &        0.218     \\\\\n",
       "\\textbf{challenging}   &       0.4286  &        0.030     &    14.496  &         0.000        &        0.371    &        0.487     \\\\\n",
       "\\textbf{informative}   &       0.4146  &        0.025     &    16.538  &         0.000        &        0.365    &        0.464     \\\\\n",
       "\\textbf{mysterious}    &       0.1753  &        0.020     &     8.930  &         0.000        &        0.137    &        0.214     \\\\\n",
       "\\textbf{dark}          &      -0.0036  &        0.022     &    -0.169  &         0.866        &       -0.046    &        0.039     \\\\\n",
       "\\textbf{author\\_count} &       0.0025  &        0.000     &     5.206  &         0.000        &        0.002    &        0.003     \\\\\n",
       "\\textbf{author\\_stars} &       0.0187  &        0.002     &    10.596  &         0.000        &        0.015    &        0.022     \\\\\n",
       "\\textbf{Fiction}       &       0.0786  &        0.032     &     2.461  &         0.014        &        0.016    &        0.141     \\\\\n",
       "\\textbf{Nonfiction}    &       0.1668  &        0.017     &     9.681  &         0.000        &        0.133    &        0.201     \\\\\n",
       "\\textbf{Literary}      &       0.0280  &        0.008     &     3.437  &         0.001        &        0.012    &        0.044     \\\\\n",
       "\\textbf{Fantasy}       &       0.0242  &        0.010     &     2.364  &         0.018        &        0.004    &        0.044     \\\\\n",
       "\\textbf{Crime}         &       0.0053  &        0.012     &     0.436  &         0.663        &       -0.018    &        0.029     \\\\\n",
       "\\textbf{Social}        &       0.0530  &        0.009     &     6.132  &         0.000        &        0.036    &        0.070     \\\\\n",
       "\\textbf{Children}      &      -0.0269  &        0.009     &    -3.148  &         0.002        &       -0.044    &       -0.010     \\\\\n",
       "\\textbf{Romans}        &      -0.0634  &        0.010     &    -6.224  &         0.000        &       -0.083    &       -0.043     \\\\\n",
       "\\textbf{Realism}       &      -0.0499  &        0.009     &    -5.621  &         0.000        &       -0.067    &       -0.033     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 206.478 & \\textbf{  Durbin-Watson:     } &    2.014  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } &  306.045  \\\\\n",
       "\\textbf{Skew:}          &  -0.360 & \\textbf{  Prob(JB):          } & 3.49e-67  \\\\\n",
       "\\textbf{Kurtosis:}      &   3.898 & \\textbf{  Cond. No.          } & 7.68e+05  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 7.68e+05. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  stars   R-squared:                       0.464\n",
       "Model:                            OLS   Adj. R-squared:                  0.461\n",
       "Method:                 Least Squares   F-statistic:                     153.9\n",
       "Date:                Sat, 11 May 2024   Prob (F-statistic):               0.00\n",
       "Time:                        19:38:29   Log-Likelihood:                 512.46\n",
       "No. Observations:                5544   AIC:                            -960.9\n",
       "Df Residuals:                    5512   BIC:                            -749.1\n",
       "Df Model:                          31                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "================================================================================\n",
       "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------\n",
       "Intercept        3.0217      0.036     84.278      0.000       2.951       3.092\n",
       "pages         -2.24e-05   2.22e-05     -1.008      0.314    -6.6e-05    2.12e-05\n",
       "reviews       1.023e-06   1.23e-07      8.348      0.000    7.83e-07    1.26e-06\n",
       "series           0.0708      0.008      8.948      0.000       0.055       0.086\n",
       "mix              0.0731      0.033      2.238      0.025       0.009       0.137\n",
       "character       -0.0894      0.027     -3.357      0.001      -0.142      -0.037\n",
       "plot            -0.1755      0.038     -4.609      0.000      -0.250      -0.101\n",
       "funny            0.4076      0.021     19.274      0.000       0.366       0.449\n",
       "lighthearted    -0.0356      0.036     -0.987      0.324      -0.106       0.035\n",
       "emotional        0.3759      0.028     13.635      0.000       0.322       0.430\n",
       "hopeful          0.2907      0.039      7.535      0.000       0.215       0.366\n",
       "inspiring        0.2729      0.036      7.544      0.000       0.202       0.344\n",
       "relaxing         0.7907      0.075     10.521      0.000       0.643       0.938\n",
       "tense            0.2778      0.033      8.393      0.000       0.213       0.343\n",
       "sad              0.2105      0.029      7.289      0.000       0.154       0.267\n",
       "reflective      -0.0111      0.028     -0.403      0.687      -0.065       0.043\n",
       "adventurous      0.1818      0.019      9.746      0.000       0.145       0.218\n",
       "challenging      0.4286      0.030     14.496      0.000       0.371       0.487\n",
       "informative      0.4146      0.025     16.538      0.000       0.365       0.464\n",
       "mysterious       0.1753      0.020      8.930      0.000       0.137       0.214\n",
       "dark            -0.0036      0.022     -0.169      0.866      -0.046       0.039\n",
       "author_count     0.0025      0.000      5.206      0.000       0.002       0.003\n",
       "author_stars     0.0187      0.002     10.596      0.000       0.015       0.022\n",
       "Fiction          0.0786      0.032      2.461      0.014       0.016       0.141\n",
       "Nonfiction       0.1668      0.017      9.681      0.000       0.133       0.201\n",
       "Literary         0.0280      0.008      3.437      0.001       0.012       0.044\n",
       "Fantasy          0.0242      0.010      2.364      0.018       0.004       0.044\n",
       "Crime            0.0053      0.012      0.436      0.663      -0.018       0.029\n",
       "Social           0.0530      0.009      6.132      0.000       0.036       0.070\n",
       "Children        -0.0269      0.009     -3.148      0.002      -0.044      -0.010\n",
       "Romans          -0.0634      0.010     -6.224      0.000      -0.083      -0.043\n",
       "Realism         -0.0499      0.009     -5.621      0.000      -0.067      -0.033\n",
       "==============================================================================\n",
       "Omnibus:                      206.478   Durbin-Watson:                   2.014\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              306.045\n",
       "Skew:                          -0.360   Prob(JB):                     3.49e-67\n",
       "Kurtosis:                       3.898   Cond. No.                     7.68e+05\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 7.68e+05. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wzor = 'stars~' + '+'.join(features)\n",
    "mod = smf.ols(formula = wzor, data = train_data)\n",
    "res = mod.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ccc2d90a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 0.2204369364743511\n",
      "Validation RMSE: 0.2220773168372384\n"
     ]
    }
   ],
   "source": [
    "model = LinearRegression(fit_intercept=True)\n",
    "train_scores, validation_scores = perform_cv(train_data[features], train_data[target], model)\n",
    "print(\"Train RMSE:\", train_scores)\n",
    "print(\"Validation RMSE:\", validation_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b902236e",
   "metadata": {},
   "source": [
    "## Model z interakcjami"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86f9e797",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>stars</td>      <th>  R-squared:         </th> <td>   0.509</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.503</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   90.01</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 11 May 2024</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>19:38:29</td>     <th>  Log-Likelihood:    </th> <td>  753.11</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  5544</td>      <th>  AIC:               </th> <td>  -1378.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  5480</td>      <th>  BIC:               </th> <td>  -954.5</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    63</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "             <td></td>                <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>               <td>    3.0548</td> <td>    0.056</td> <td>   54.741</td> <td> 0.000</td> <td>    2.945</td> <td>    3.164</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>index_0</th>                 <td>-1.187e-05</td> <td> 1.46e-06</td> <td>   -8.137</td> <td> 0.000</td> <td>-1.47e-05</td> <td>-9.01e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pages</th>                   <td>-1.542e-05</td> <td> 2.17e-05</td> <td>   -0.710</td> <td> 0.478</td> <td> -5.8e-05</td> <td> 2.71e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>reviews</th>                 <td> 7.376e-07</td> <td>  1.2e-07</td> <td>    6.162</td> <td> 0.000</td> <td> 5.03e-07</td> <td> 9.72e-07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>series</th>                  <td>    0.0021</td> <td>    0.022</td> <td>    0.094</td> <td> 0.925</td> <td>   -0.042</td> <td>    0.046</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mix</th>                     <td>    0.0449</td> <td>    0.022</td> <td>    2.018</td> <td> 0.044</td> <td>    0.001</td> <td>    0.088</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>character</th>               <td>   -0.0488</td> <td>    0.013</td> <td>   -3.774</td> <td> 0.000</td> <td>   -0.074</td> <td>   -0.023</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>plot</th>                    <td>   -0.0608</td> <td>    0.020</td> <td>   -3.112</td> <td> 0.002</td> <td>   -0.099</td> <td>   -0.023</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>funny</th>                   <td>    0.4203</td> <td>    0.021</td> <td>   19.939</td> <td> 0.000</td> <td>    0.379</td> <td>    0.462</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lighthearted</th>            <td>   -0.0195</td> <td>    0.036</td> <td>   -0.536</td> <td> 0.592</td> <td>   -0.091</td> <td>    0.052</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>emotional</th>               <td>    0.4435</td> <td>    0.060</td> <td>    7.430</td> <td> 0.000</td> <td>    0.327</td> <td>    0.561</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>hopeful</th>                 <td>    0.0860</td> <td>    0.124</td> <td>    0.695</td> <td> 0.487</td> <td>   -0.157</td> <td>    0.329</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>inspiring</th>               <td>    0.3943</td> <td>    0.060</td> <td>    6.617</td> <td> 0.000</td> <td>    0.277</td> <td>    0.511</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>relaxing</th>                <td>    0.8472</td> <td>    0.074</td> <td>   11.487</td> <td> 0.000</td> <td>    0.703</td> <td>    0.992</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tense</th>                   <td>    0.0362</td> <td>    0.130</td> <td>    0.278</td> <td> 0.781</td> <td>   -0.219</td> <td>    0.291</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sad</th>                     <td>    0.2220</td> <td>    0.076</td> <td>    2.927</td> <td> 0.003</td> <td>    0.073</td> <td>    0.371</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>reflective</th>              <td>   -0.2326</td> <td>    0.059</td> <td>   -3.929</td> <td> 0.000</td> <td>   -0.349</td> <td>   -0.117</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>adventurous</th>             <td>   -0.0065</td> <td>    0.065</td> <td>   -0.100</td> <td> 0.921</td> <td>   -0.135</td> <td>    0.121</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>challenging</th>             <td>    1.6755</td> <td>    0.146</td> <td>   11.473</td> <td> 0.000</td> <td>    1.389</td> <td>    1.962</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>informative</th>             <td>    0.3665</td> <td>    0.028</td> <td>   12.879</td> <td> 0.000</td> <td>    0.311</td> <td>    0.422</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mysterious</th>              <td>    0.4816</td> <td>    0.126</td> <td>    3.837</td> <td> 0.000</td> <td>    0.236</td> <td>    0.728</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>dark</th>                    <td>   -0.1860</td> <td>    0.068</td> <td>   -2.748</td> <td> 0.006</td> <td>   -0.319</td> <td>   -0.053</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>author_count</th>            <td>    0.0022</td> <td>    0.000</td> <td>    4.612</td> <td> 0.000</td> <td>    0.001</td> <td>    0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>author_stars</th>            <td>   -0.0013</td> <td>    0.009</td> <td>   -0.139</td> <td> 0.889</td> <td>   -0.020</td> <td>    0.017</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Fiction</th>                 <td>    0.0179</td> <td>    0.057</td> <td>    0.314</td> <td> 0.753</td> <td>   -0.094</td> <td>    0.130</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Nonfiction</th>              <td>    0.2561</td> <td>    0.037</td> <td>    6.917</td> <td> 0.000</td> <td>    0.184</td> <td>    0.329</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Literary</th>                <td>    0.0920</td> <td>    0.023</td> <td>    4.026</td> <td> 0.000</td> <td>    0.047</td> <td>    0.137</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Fantasy</th>                 <td>   -0.0153</td> <td>    0.025</td> <td>   -0.614</td> <td> 0.539</td> <td>   -0.064</td> <td>    0.034</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Crime</th>                   <td>   -0.0124</td> <td>    0.027</td> <td>   -0.465</td> <td> 0.642</td> <td>   -0.065</td> <td>    0.040</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Social</th>                  <td>    0.0065</td> <td>    0.013</td> <td>    0.509</td> <td> 0.611</td> <td>   -0.019</td> <td>    0.032</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Children</th>                <td>   -0.0324</td> <td>    0.008</td> <td>   -3.833</td> <td> 0.000</td> <td>   -0.049</td> <td>   -0.016</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Romans</th>                  <td>   -0.0380</td> <td>    0.015</td> <td>   -2.464</td> <td> 0.014</td> <td>   -0.068</td> <td>   -0.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Realism</th>                 <td>   -0.0389</td> <td>    0.009</td> <td>   -4.368</td> <td> 0.000</td> <td>   -0.056</td> <td>   -0.021</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Crime_mix</th>               <td>    0.0467</td> <td>    0.055</td> <td>    0.843</td> <td> 0.399</td> <td>   -0.062</td> <td>    0.155</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Fantasy_adventurous</th>     <td>    0.1019</td> <td>    0.030</td> <td>    3.422</td> <td> 0.001</td> <td>    0.044</td> <td>    0.160</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Fantasy_author_stars</th>    <td>   -0.0037</td> <td>    0.004</td> <td>   -0.958</td> <td> 0.338</td> <td>   -0.011</td> <td>    0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Fantasy_inspiring</th>       <td>    0.0067</td> <td>    0.058</td> <td>    0.116</td> <td> 0.907</td> <td>   -0.106</td> <td>    0.120</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Fantasy_mix</th>             <td>    0.0092</td> <td>    0.052</td> <td>    0.176</td> <td> 0.860</td> <td>   -0.093</td> <td>    0.111</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Fiction_adventurous</th>     <td>    0.1279</td> <td>    0.070</td> <td>    1.838</td> <td> 0.066</td> <td>   -0.008</td> <td>    0.264</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Fiction_author_stars</th>    <td>    0.0116</td> <td>    0.009</td> <td>    1.243</td> <td> 0.214</td> <td>   -0.007</td> <td>    0.030</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Fiction_challenging</th>     <td>   -1.3974</td> <td>    0.147</td> <td>   -9.530</td> <td> 0.000</td> <td>   -1.685</td> <td>   -1.110</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Fiction_character</th>       <td>   -0.0488</td> <td>    0.013</td> <td>   -3.774</td> <td> 0.000</td> <td>   -0.074</td> <td>   -0.023</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Fiction_dark</th>            <td>    0.2525</td> <td>    0.071</td> <td>    3.564</td> <td> 0.000</td> <td>    0.114</td> <td>    0.391</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Fiction_emotional</th>       <td>   -0.0421</td> <td>    0.066</td> <td>   -0.635</td> <td> 0.526</td> <td>   -0.172</td> <td>    0.088</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Fiction_hopeful</th>         <td>    0.1984</td> <td>    0.129</td> <td>    1.535</td> <td> 0.125</td> <td>   -0.055</td> <td>    0.452</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Fiction_inspiring</th>       <td>    0.1621</td> <td>    0.078</td> <td>    2.085</td> <td> 0.037</td> <td>    0.010</td> <td>    0.315</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Fiction_mix</th>             <td>    0.0449</td> <td>    0.022</td> <td>    2.018</td> <td> 0.044</td> <td>    0.001</td> <td>    0.088</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Fiction_mysterious</th>      <td>   -0.3130</td> <td>    0.126</td> <td>   -2.492</td> <td> 0.013</td> <td>   -0.559</td> <td>   -0.067</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Fiction_plot</th>            <td>   -0.0608</td> <td>    0.020</td> <td>   -3.112</td> <td> 0.002</td> <td>   -0.099</td> <td>   -0.023</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Fiction_reflective</th>      <td>    0.2839</td> <td>    0.064</td> <td>    4.464</td> <td> 0.000</td> <td>    0.159</td> <td>    0.409</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Fiction_sad</th>             <td>   -0.0636</td> <td>    0.081</td> <td>   -0.786</td> <td> 0.432</td> <td>   -0.222</td> <td>    0.095</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Fiction_tense</th>           <td>    0.3074</td> <td>    0.134</td> <td>    2.299</td> <td> 0.022</td> <td>    0.045</td> <td>    0.570</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Literary_author_stars</th>   <td>    0.0064</td> <td>    0.004</td> <td>    1.811</td> <td> 0.070</td> <td>   -0.001</td> <td>    0.013</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Literary_emotional</th>      <td>    0.0094</td> <td>    0.039</td> <td>    0.242</td> <td> 0.809</td> <td>   -0.067</td> <td>    0.085</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Literary_inspiring</th>      <td>   -0.1487</td> <td>    0.048</td> <td>   -3.101</td> <td> 0.002</td> <td>   -0.243</td> <td>   -0.055</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Literary_mix</th>            <td>   -0.2250</td> <td>    0.040</td> <td>   -5.658</td> <td> 0.000</td> <td>   -0.303</td> <td>   -0.147</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Literary_mysterious</th>     <td>    0.0328</td> <td>    0.028</td> <td>    1.177</td> <td> 0.239</td> <td>   -0.022</td> <td>    0.087</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Literary_sad</th>            <td>    0.0996</td> <td>    0.045</td> <td>    2.216</td> <td> 0.027</td> <td>    0.012</td> <td>    0.188</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Nonfiction_author_stars</th> <td>    0.0091</td> <td>    0.008</td> <td>    1.110</td> <td> 0.267</td> <td>   -0.007</td> <td>    0.025</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Nonfiction_challenging</th>  <td>   -0.7165</td> <td>    0.134</td> <td>   -5.360</td> <td> 0.000</td> <td>   -0.979</td> <td>   -0.454</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Nonfiction_hopeful</th>      <td>   -0.0812</td> <td>    0.095</td> <td>   -0.852</td> <td> 0.394</td> <td>   -0.268</td> <td>    0.106</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Romans_author_stars</th>     <td>   -0.0034</td> <td>    0.004</td> <td>   -0.814</td> <td> 0.416</td> <td>   -0.012</td> <td>    0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Social_author_stars</th>     <td>    0.0115</td> <td>    0.004</td> <td>    2.892</td> <td> 0.004</td> <td>    0.004</td> <td>    0.019</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>series_adventurous</th>      <td>    0.0146</td> <td>    0.027</td> <td>    0.542</td> <td> 0.588</td> <td>   -0.038</td> <td>    0.067</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>series_author_stars</th>     <td>    0.0155</td> <td>    0.004</td> <td>    4.138</td> <td> 0.000</td> <td>    0.008</td> <td>    0.023</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>series_emotional</th>        <td>   -0.1160</td> <td>    0.027</td> <td>   -4.223</td> <td> 0.000</td> <td>   -0.170</td> <td>   -0.062</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>series_mix</th>              <td>    0.1821</td> <td>    0.044</td> <td>    4.126</td> <td> 0.000</td> <td>    0.096</td> <td>    0.269</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>201.113</td> <th>  Durbin-Watson:     </th> <td>   2.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 319.413</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.332</td>  <th>  Prob(JB):          </th> <td>4.37e-70</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.971</td>  <th>  Cond. No.          </th> <td>1.16e+16</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 3.36e-20. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}            &      stars       & \\textbf{  R-squared:         } &     0.509   \\\\\n",
       "\\textbf{Model:}                    &       OLS        & \\textbf{  Adj. R-squared:    } &     0.503   \\\\\n",
       "\\textbf{Method:}                   &  Least Squares   & \\textbf{  F-statistic:       } &     90.01   \\\\\n",
       "\\textbf{Date:}                     & Sat, 11 May 2024 & \\textbf{  Prob (F-statistic):} &     0.00    \\\\\n",
       "\\textbf{Time:}                     &     19:38:29     & \\textbf{  Log-Likelihood:    } &    753.11   \\\\\n",
       "\\textbf{No. Observations:}         &        5544      & \\textbf{  AIC:               } &    -1378.   \\\\\n",
       "\\textbf{Df Residuals:}             &        5480      & \\textbf{  BIC:               } &    -954.5   \\\\\n",
       "\\textbf{Df Model:}                 &          63      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}          &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                                   & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept}                 &       3.0548  &        0.056     &    54.741  &         0.000        &        2.945    &        3.164     \\\\\n",
       "\\textbf{index\\_0}                  &   -1.187e-05  &     1.46e-06     &    -8.137  &         0.000        &    -1.47e-05    &    -9.01e-06     \\\\\n",
       "\\textbf{pages}                     &   -1.542e-05  &     2.17e-05     &    -0.710  &         0.478        &     -5.8e-05    &     2.71e-05     \\\\\n",
       "\\textbf{reviews}                   &    7.376e-07  &      1.2e-07     &     6.162  &         0.000        &     5.03e-07    &     9.72e-07     \\\\\n",
       "\\textbf{series}                    &       0.0021  &        0.022     &     0.094  &         0.925        &       -0.042    &        0.046     \\\\\n",
       "\\textbf{mix}                       &       0.0449  &        0.022     &     2.018  &         0.044        &        0.001    &        0.088     \\\\\n",
       "\\textbf{character}                 &      -0.0488  &        0.013     &    -3.774  &         0.000        &       -0.074    &       -0.023     \\\\\n",
       "\\textbf{plot}                      &      -0.0608  &        0.020     &    -3.112  &         0.002        &       -0.099    &       -0.023     \\\\\n",
       "\\textbf{funny}                     &       0.4203  &        0.021     &    19.939  &         0.000        &        0.379    &        0.462     \\\\\n",
       "\\textbf{lighthearted}              &      -0.0195  &        0.036     &    -0.536  &         0.592        &       -0.091    &        0.052     \\\\\n",
       "\\textbf{emotional}                 &       0.4435  &        0.060     &     7.430  &         0.000        &        0.327    &        0.561     \\\\\n",
       "\\textbf{hopeful}                   &       0.0860  &        0.124     &     0.695  &         0.487        &       -0.157    &        0.329     \\\\\n",
       "\\textbf{inspiring}                 &       0.3943  &        0.060     &     6.617  &         0.000        &        0.277    &        0.511     \\\\\n",
       "\\textbf{relaxing}                  &       0.8472  &        0.074     &    11.487  &         0.000        &        0.703    &        0.992     \\\\\n",
       "\\textbf{tense}                     &       0.0362  &        0.130     &     0.278  &         0.781        &       -0.219    &        0.291     \\\\\n",
       "\\textbf{sad}                       &       0.2220  &        0.076     &     2.927  &         0.003        &        0.073    &        0.371     \\\\\n",
       "\\textbf{reflective}                &      -0.2326  &        0.059     &    -3.929  &         0.000        &       -0.349    &       -0.117     \\\\\n",
       "\\textbf{adventurous}               &      -0.0065  &        0.065     &    -0.100  &         0.921        &       -0.135    &        0.121     \\\\\n",
       "\\textbf{challenging}               &       1.6755  &        0.146     &    11.473  &         0.000        &        1.389    &        1.962     \\\\\n",
       "\\textbf{informative}               &       0.3665  &        0.028     &    12.879  &         0.000        &        0.311    &        0.422     \\\\\n",
       "\\textbf{mysterious}                &       0.4816  &        0.126     &     3.837  &         0.000        &        0.236    &        0.728     \\\\\n",
       "\\textbf{dark}                      &      -0.1860  &        0.068     &    -2.748  &         0.006        &       -0.319    &       -0.053     \\\\\n",
       "\\textbf{author\\_count}             &       0.0022  &        0.000     &     4.612  &         0.000        &        0.001    &        0.003     \\\\\n",
       "\\textbf{author\\_stars}             &      -0.0013  &        0.009     &    -0.139  &         0.889        &       -0.020    &        0.017     \\\\\n",
       "\\textbf{Fiction}                   &       0.0179  &        0.057     &     0.314  &         0.753        &       -0.094    &        0.130     \\\\\n",
       "\\textbf{Nonfiction}                &       0.2561  &        0.037     &     6.917  &         0.000        &        0.184    &        0.329     \\\\\n",
       "\\textbf{Literary}                  &       0.0920  &        0.023     &     4.026  &         0.000        &        0.047    &        0.137     \\\\\n",
       "\\textbf{Fantasy}                   &      -0.0153  &        0.025     &    -0.614  &         0.539        &       -0.064    &        0.034     \\\\\n",
       "\\textbf{Crime}                     &      -0.0124  &        0.027     &    -0.465  &         0.642        &       -0.065    &        0.040     \\\\\n",
       "\\textbf{Social}                    &       0.0065  &        0.013     &     0.509  &         0.611        &       -0.019    &        0.032     \\\\\n",
       "\\textbf{Children}                  &      -0.0324  &        0.008     &    -3.833  &         0.000        &       -0.049    &       -0.016     \\\\\n",
       "\\textbf{Romans}                    &      -0.0380  &        0.015     &    -2.464  &         0.014        &       -0.068    &       -0.008     \\\\\n",
       "\\textbf{Realism}                   &      -0.0389  &        0.009     &    -4.368  &         0.000        &       -0.056    &       -0.021     \\\\\n",
       "\\textbf{Crime\\_mix}                &       0.0467  &        0.055     &     0.843  &         0.399        &       -0.062    &        0.155     \\\\\n",
       "\\textbf{Fantasy\\_adventurous}      &       0.1019  &        0.030     &     3.422  &         0.001        &        0.044    &        0.160     \\\\\n",
       "\\textbf{Fantasy\\_author\\_stars}    &      -0.0037  &        0.004     &    -0.958  &         0.338        &       -0.011    &        0.004     \\\\\n",
       "\\textbf{Fantasy\\_inspiring}        &       0.0067  &        0.058     &     0.116  &         0.907        &       -0.106    &        0.120     \\\\\n",
       "\\textbf{Fantasy\\_mix}              &       0.0092  &        0.052     &     0.176  &         0.860        &       -0.093    &        0.111     \\\\\n",
       "\\textbf{Fiction\\_adventurous}      &       0.1279  &        0.070     &     1.838  &         0.066        &       -0.008    &        0.264     \\\\\n",
       "\\textbf{Fiction\\_author\\_stars}    &       0.0116  &        0.009     &     1.243  &         0.214        &       -0.007    &        0.030     \\\\\n",
       "\\textbf{Fiction\\_challenging}      &      -1.3974  &        0.147     &    -9.530  &         0.000        &       -1.685    &       -1.110     \\\\\n",
       "\\textbf{Fiction\\_character}        &      -0.0488  &        0.013     &    -3.774  &         0.000        &       -0.074    &       -0.023     \\\\\n",
       "\\textbf{Fiction\\_dark}             &       0.2525  &        0.071     &     3.564  &         0.000        &        0.114    &        0.391     \\\\\n",
       "\\textbf{Fiction\\_emotional}        &      -0.0421  &        0.066     &    -0.635  &         0.526        &       -0.172    &        0.088     \\\\\n",
       "\\textbf{Fiction\\_hopeful}          &       0.1984  &        0.129     &     1.535  &         0.125        &       -0.055    &        0.452     \\\\\n",
       "\\textbf{Fiction\\_inspiring}        &       0.1621  &        0.078     &     2.085  &         0.037        &        0.010    &        0.315     \\\\\n",
       "\\textbf{Fiction\\_mix}              &       0.0449  &        0.022     &     2.018  &         0.044        &        0.001    &        0.088     \\\\\n",
       "\\textbf{Fiction\\_mysterious}       &      -0.3130  &        0.126     &    -2.492  &         0.013        &       -0.559    &       -0.067     \\\\\n",
       "\\textbf{Fiction\\_plot}             &      -0.0608  &        0.020     &    -3.112  &         0.002        &       -0.099    &       -0.023     \\\\\n",
       "\\textbf{Fiction\\_reflective}       &       0.2839  &        0.064     &     4.464  &         0.000        &        0.159    &        0.409     \\\\\n",
       "\\textbf{Fiction\\_sad}              &      -0.0636  &        0.081     &    -0.786  &         0.432        &       -0.222    &        0.095     \\\\\n",
       "\\textbf{Fiction\\_tense}            &       0.3074  &        0.134     &     2.299  &         0.022        &        0.045    &        0.570     \\\\\n",
       "\\textbf{Literary\\_author\\_stars}   &       0.0064  &        0.004     &     1.811  &         0.070        &       -0.001    &        0.013     \\\\\n",
       "\\textbf{Literary\\_emotional}       &       0.0094  &        0.039     &     0.242  &         0.809        &       -0.067    &        0.085     \\\\\n",
       "\\textbf{Literary\\_inspiring}       &      -0.1487  &        0.048     &    -3.101  &         0.002        &       -0.243    &       -0.055     \\\\\n",
       "\\textbf{Literary\\_mix}             &      -0.2250  &        0.040     &    -5.658  &         0.000        &       -0.303    &       -0.147     \\\\\n",
       "\\textbf{Literary\\_mysterious}      &       0.0328  &        0.028     &     1.177  &         0.239        &       -0.022    &        0.087     \\\\\n",
       "\\textbf{Literary\\_sad}             &       0.0996  &        0.045     &     2.216  &         0.027        &        0.012    &        0.188     \\\\\n",
       "\\textbf{Nonfiction\\_author\\_stars} &       0.0091  &        0.008     &     1.110  &         0.267        &       -0.007    &        0.025     \\\\\n",
       "\\textbf{Nonfiction\\_challenging}   &      -0.7165  &        0.134     &    -5.360  &         0.000        &       -0.979    &       -0.454     \\\\\n",
       "\\textbf{Nonfiction\\_hopeful}       &      -0.0812  &        0.095     &    -0.852  &         0.394        &       -0.268    &        0.106     \\\\\n",
       "\\textbf{Romans\\_author\\_stars}     &      -0.0034  &        0.004     &    -0.814  &         0.416        &       -0.012    &        0.005     \\\\\n",
       "\\textbf{Social\\_author\\_stars}     &       0.0115  &        0.004     &     2.892  &         0.004        &        0.004    &        0.019     \\\\\n",
       "\\textbf{series\\_adventurous}       &       0.0146  &        0.027     &     0.542  &         0.588        &       -0.038    &        0.067     \\\\\n",
       "\\textbf{series\\_author\\_stars}     &       0.0155  &        0.004     &     4.138  &         0.000        &        0.008    &        0.023     \\\\\n",
       "\\textbf{series\\_emotional}         &      -0.1160  &        0.027     &    -4.223  &         0.000        &       -0.170    &       -0.062     \\\\\n",
       "\\textbf{series\\_mix}               &       0.1821  &        0.044     &     4.126  &         0.000        &        0.096    &        0.269     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 201.113 & \\textbf{  Durbin-Watson:     } &    2.006  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } &  319.413  \\\\\n",
       "\\textbf{Skew:}          &  -0.332 & \\textbf{  Prob(JB):          } & 4.37e-70  \\\\\n",
       "\\textbf{Kurtosis:}      &   3.971 & \\textbf{  Cond. No.          } & 1.16e+16  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The smallest eigenvalue is 3.36e-20. This might indicate that there are \\newline\n",
       " strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  stars   R-squared:                       0.509\n",
       "Model:                            OLS   Adj. R-squared:                  0.503\n",
       "Method:                 Least Squares   F-statistic:                     90.01\n",
       "Date:                Sat, 11 May 2024   Prob (F-statistic):               0.00\n",
       "Time:                        19:38:29   Log-Likelihood:                 753.11\n",
       "No. Observations:                5544   AIC:                            -1378.\n",
       "Df Residuals:                    5480   BIC:                            -954.5\n",
       "Df Model:                          63                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "===========================================================================================\n",
       "                              coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------------------\n",
       "Intercept                   3.0548      0.056     54.741      0.000       2.945       3.164\n",
       "index_0                 -1.187e-05   1.46e-06     -8.137      0.000   -1.47e-05   -9.01e-06\n",
       "pages                   -1.542e-05   2.17e-05     -0.710      0.478    -5.8e-05    2.71e-05\n",
       "reviews                  7.376e-07    1.2e-07      6.162      0.000    5.03e-07    9.72e-07\n",
       "series                      0.0021      0.022      0.094      0.925      -0.042       0.046\n",
       "mix                         0.0449      0.022      2.018      0.044       0.001       0.088\n",
       "character                  -0.0488      0.013     -3.774      0.000      -0.074      -0.023\n",
       "plot                       -0.0608      0.020     -3.112      0.002      -0.099      -0.023\n",
       "funny                       0.4203      0.021     19.939      0.000       0.379       0.462\n",
       "lighthearted               -0.0195      0.036     -0.536      0.592      -0.091       0.052\n",
       "emotional                   0.4435      0.060      7.430      0.000       0.327       0.561\n",
       "hopeful                     0.0860      0.124      0.695      0.487      -0.157       0.329\n",
       "inspiring                   0.3943      0.060      6.617      0.000       0.277       0.511\n",
       "relaxing                    0.8472      0.074     11.487      0.000       0.703       0.992\n",
       "tense                       0.0362      0.130      0.278      0.781      -0.219       0.291\n",
       "sad                         0.2220      0.076      2.927      0.003       0.073       0.371\n",
       "reflective                 -0.2326      0.059     -3.929      0.000      -0.349      -0.117\n",
       "adventurous                -0.0065      0.065     -0.100      0.921      -0.135       0.121\n",
       "challenging                 1.6755      0.146     11.473      0.000       1.389       1.962\n",
       "informative                 0.3665      0.028     12.879      0.000       0.311       0.422\n",
       "mysterious                  0.4816      0.126      3.837      0.000       0.236       0.728\n",
       "dark                       -0.1860      0.068     -2.748      0.006      -0.319      -0.053\n",
       "author_count                0.0022      0.000      4.612      0.000       0.001       0.003\n",
       "author_stars               -0.0013      0.009     -0.139      0.889      -0.020       0.017\n",
       "Fiction                     0.0179      0.057      0.314      0.753      -0.094       0.130\n",
       "Nonfiction                  0.2561      0.037      6.917      0.000       0.184       0.329\n",
       "Literary                    0.0920      0.023      4.026      0.000       0.047       0.137\n",
       "Fantasy                    -0.0153      0.025     -0.614      0.539      -0.064       0.034\n",
       "Crime                      -0.0124      0.027     -0.465      0.642      -0.065       0.040\n",
       "Social                      0.0065      0.013      0.509      0.611      -0.019       0.032\n",
       "Children                   -0.0324      0.008     -3.833      0.000      -0.049      -0.016\n",
       "Romans                     -0.0380      0.015     -2.464      0.014      -0.068      -0.008\n",
       "Realism                    -0.0389      0.009     -4.368      0.000      -0.056      -0.021\n",
       "Crime_mix                   0.0467      0.055      0.843      0.399      -0.062       0.155\n",
       "Fantasy_adventurous         0.1019      0.030      3.422      0.001       0.044       0.160\n",
       "Fantasy_author_stars       -0.0037      0.004     -0.958      0.338      -0.011       0.004\n",
       "Fantasy_inspiring           0.0067      0.058      0.116      0.907      -0.106       0.120\n",
       "Fantasy_mix                 0.0092      0.052      0.176      0.860      -0.093       0.111\n",
       "Fiction_adventurous         0.1279      0.070      1.838      0.066      -0.008       0.264\n",
       "Fiction_author_stars        0.0116      0.009      1.243      0.214      -0.007       0.030\n",
       "Fiction_challenging        -1.3974      0.147     -9.530      0.000      -1.685      -1.110\n",
       "Fiction_character          -0.0488      0.013     -3.774      0.000      -0.074      -0.023\n",
       "Fiction_dark                0.2525      0.071      3.564      0.000       0.114       0.391\n",
       "Fiction_emotional          -0.0421      0.066     -0.635      0.526      -0.172       0.088\n",
       "Fiction_hopeful             0.1984      0.129      1.535      0.125      -0.055       0.452\n",
       "Fiction_inspiring           0.1621      0.078      2.085      0.037       0.010       0.315\n",
       "Fiction_mix                 0.0449      0.022      2.018      0.044       0.001       0.088\n",
       "Fiction_mysterious         -0.3130      0.126     -2.492      0.013      -0.559      -0.067\n",
       "Fiction_plot               -0.0608      0.020     -3.112      0.002      -0.099      -0.023\n",
       "Fiction_reflective          0.2839      0.064      4.464      0.000       0.159       0.409\n",
       "Fiction_sad                -0.0636      0.081     -0.786      0.432      -0.222       0.095\n",
       "Fiction_tense               0.3074      0.134      2.299      0.022       0.045       0.570\n",
       "Literary_author_stars       0.0064      0.004      1.811      0.070      -0.001       0.013\n",
       "Literary_emotional          0.0094      0.039      0.242      0.809      -0.067       0.085\n",
       "Literary_inspiring         -0.1487      0.048     -3.101      0.002      -0.243      -0.055\n",
       "Literary_mix               -0.2250      0.040     -5.658      0.000      -0.303      -0.147\n",
       "Literary_mysterious         0.0328      0.028      1.177      0.239      -0.022       0.087\n",
       "Literary_sad                0.0996      0.045      2.216      0.027       0.012       0.188\n",
       "Nonfiction_author_stars     0.0091      0.008      1.110      0.267      -0.007       0.025\n",
       "Nonfiction_challenging     -0.7165      0.134     -5.360      0.000      -0.979      -0.454\n",
       "Nonfiction_hopeful         -0.0812      0.095     -0.852      0.394      -0.268       0.106\n",
       "Romans_author_stars        -0.0034      0.004     -0.814      0.416      -0.012       0.005\n",
       "Social_author_stars         0.0115      0.004      2.892      0.004       0.004       0.019\n",
       "series_adventurous          0.0146      0.027      0.542      0.588      -0.038       0.067\n",
       "series_author_stars         0.0155      0.004      4.138      0.000       0.008       0.023\n",
       "series_emotional           -0.1160      0.027     -4.223      0.000      -0.170      -0.062\n",
       "series_mix                  0.1821      0.044      4.126      0.000       0.096       0.269\n",
       "==============================================================================\n",
       "Omnibus:                      201.113   Durbin-Watson:                   2.006\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              319.413\n",
       "Skew:                          -0.332   Prob(JB):                     4.37e-70\n",
       "Kurtosis:                       3.971   Cond. No.                     1.16e+16\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 3.36e-20. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_interactions=pd.read_csv(\"../data/data_add.csv\")\n",
    "data_interactions=data_interactions.drop(columns=['Unnamed: 0'])\n",
    "features_interactions=data_interactions.columns.tolist()\n",
    "features_interactions.remove('stars')\n",
    "train_data_interactions, test_data_interactions = train_test_split(data_interactions, test_size=0.2, random_state=SEED)\n",
    "wzor = 'stars~' + '+'.join(features_interactions)\n",
    "mod = smf.ols(formula = wzor, data = train_data_interactions)\n",
    "res = mod.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2355372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 0.21091275251763042\n",
      "Validation RMSE: 0.21410239828253755\n"
     ]
    }
   ],
   "source": [
    "model = LinearRegression(fit_intercept=True)\n",
    "train_scores, validation_scores = perform_cv(train_data_interactions[features_interactions], train_data_interactions[target], model)\n",
    "print(\"Train RMSE:\", train_scores)\n",
    "print(\"Validation RMSE:\", validation_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54369fb6",
   "metadata": {},
   "source": [
    "## Model z transformacjami zmiennych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7dd89e1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>stars</td>      <th>  R-squared:         </th> <td>   0.412</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.408</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   98.76</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 11 May 2024</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>19:38:29</td>     <th>  Log-Likelihood:    </th> <td>  254.48</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  5544</td>      <th>  AIC:               </th> <td>  -429.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  5504</td>      <th>  BIC:               </th> <td>  -164.1</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    39</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                  <td></td>                    <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                        <td>    2.5155</td> <td>    0.116</td> <td>   21.716</td> <td> 0.000</td> <td>    2.288</td> <td>    2.743</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Crime</th>                            <td>    0.0159</td> <td>    0.013</td> <td>    1.268</td> <td> 0.205</td> <td>   -0.009</td> <td>    0.040</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Romans</th>                           <td>   -0.1002</td> <td>    0.010</td> <td>  -10.071</td> <td> 0.000</td> <td>   -0.120</td> <td>   -0.081</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sad_mm</th>                           <td>    0.2819</td> <td>    0.025</td> <td>   11.277</td> <td> 0.000</td> <td>    0.233</td> <td>    0.331</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>reviews_boxcox</th>                   <td>   -0.3657</td> <td>    0.037</td> <td>   -9.832</td> <td> 0.000</td> <td>   -0.439</td> <td>   -0.293</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>reflective_boxcox</th>                <td>    0.0244</td> <td>    0.007</td> <td>    3.341</td> <td> 0.001</td> <td>    0.010</td> <td>    0.039</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mysterious_rs</th>                    <td>    0.0424</td> <td>    0.012</td> <td>    3.654</td> <td> 0.000</td> <td>    0.020</td> <td>    0.065</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>inspiring_log</th>                    <td>    0.0111</td> <td>    0.004</td> <td>    2.914</td> <td> 0.004</td> <td>    0.004</td> <td>    0.019</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>informative_boxcox</th>               <td>    0.0024</td> <td>    0.001</td> <td>    1.860</td> <td> 0.063</td> <td>   -0.000</td> <td>    0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>emotional_boxcox</th>                 <td>    0.0133</td> <td>    0.019</td> <td>    0.711</td> <td> 0.477</td> <td>   -0.023</td> <td>    0.050</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>challenging_mm</th>                   <td>    0.4429</td> <td>    0.111</td> <td>    3.990</td> <td> 0.000</td> <td>    0.225</td> <td>    0.661</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>author_stars</th>                     <td>    0.0034</td> <td>    0.003</td> <td>    1.087</td> <td> 0.277</td> <td>   -0.003</td> <td>    0.010</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Fantasy_author_stars</th>             <td>    0.0045</td> <td>    0.004</td> <td>    1.227</td> <td> 0.220</td> <td>   -0.003</td> <td>    0.012</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Fantasy_mix_qt</th>                   <td>    0.0178</td> <td>    0.020</td> <td>    0.870</td> <td> 0.385</td> <td>   -0.022</td> <td>    0.058</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Fiction_adventurous_qt</th>           <td>    0.1298</td> <td>    0.022</td> <td>    5.965</td> <td> 0.000</td> <td>    0.087</td> <td>    0.172</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Fiction_author_count_ss</th>          <td>    0.0201</td> <td>    0.004</td> <td>    5.543</td> <td> 0.000</td> <td>    0.013</td> <td>    0.027</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Fiction_challenging_mm</th>           <td>   -0.1187</td> <td>    0.109</td> <td>   -1.093</td> <td> 0.274</td> <td>   -0.331</td> <td>    0.094</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Fiction_character_ss</th>             <td>   -0.0519</td> <td>    0.006</td> <td>   -8.502</td> <td> 0.000</td> <td>   -0.064</td> <td>   -0.040</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Fiction_emotional_boxcox</th>         <td>   -0.1172</td> <td>    0.022</td> <td>   -5.223</td> <td> 0.000</td> <td>   -0.161</td> <td>   -0.073</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Fiction_hopeful_rs</th>               <td>    0.1084</td> <td>    0.009</td> <td>   12.319</td> <td> 0.000</td> <td>    0.091</td> <td>    0.126</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Fiction_mix_qt</th>                   <td>    0.1775</td> <td>    0.024</td> <td>    7.425</td> <td> 0.000</td> <td>    0.131</td> <td>    0.224</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Fiction_pages_qt</th>                 <td>   -0.0085</td> <td>    0.014</td> <td>   -0.593</td> <td> 0.553</td> <td>   -0.037</td> <td>    0.020</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Fiction_plot_qt</th>                  <td>   -0.3081</td> <td>    0.025</td> <td>  -12.095</td> <td> 0.000</td> <td>   -0.358</td> <td>   -0.258</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Literary_author_stars</th>            <td>    0.0063</td> <td>    0.003</td> <td>    1.880</td> <td> 0.060</td> <td>   -0.000</td> <td>    0.013</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Literary_emotional_boxcox</th>        <td>    0.0074</td> <td>    0.016</td> <td>    0.454</td> <td> 0.650</td> <td>   -0.025</td> <td>    0.039</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Literary_hopeful_rs</th>              <td>    0.0247</td> <td>    0.010</td> <td>    2.354</td> <td> 0.019</td> <td>    0.004</td> <td>    0.045</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Literary_inspiring_log</th>           <td>   -0.0084</td> <td>    0.005</td> <td>   -1.841</td> <td> 0.066</td> <td>   -0.017</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Literary_mysterious_rs</th>           <td>   -0.0188</td> <td>    0.014</td> <td>   -1.368</td> <td> 0.171</td> <td>   -0.046</td> <td>    0.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Nonfiction_author_count_ss</th>       <td>   -0.0730</td> <td>    0.014</td> <td>   -5.173</td> <td> 0.000</td> <td>   -0.101</td> <td>   -0.045</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Nonfiction_author_stars</th>          <td>    0.0217</td> <td>    0.004</td> <td>    4.940</td> <td> 0.000</td> <td>    0.013</td> <td>    0.030</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Nonfiction_challenging_mm</th>        <td>    0.2843</td> <td>    0.105</td> <td>    2.704</td> <td> 0.007</td> <td>    0.078</td> <td>    0.490</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Nonfiction_dark_ss</th>               <td>   -0.0433</td> <td>    0.011</td> <td>   -3.769</td> <td> 0.000</td> <td>   -0.066</td> <td>   -0.021</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Social_author_stars</th>              <td>    0.0114</td> <td>    0.003</td> <td>    3.370</td> <td> 0.001</td> <td>    0.005</td> <td>    0.018</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Social_challenging_mm</th>            <td>    0.0278</td> <td>    0.040</td> <td>    0.694</td> <td> 0.488</td> <td>   -0.051</td> <td>    0.106</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>series_author_stars</th>              <td>    0.0112</td> <td>    0.003</td> <td>    3.200</td> <td> 0.001</td> <td>    0.004</td> <td>    0.018</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>series_inspiring_log</th>             <td>    0.0031</td> <td>    0.005</td> <td>    0.660</td> <td> 0.509</td> <td>   -0.006</td> <td>    0.012</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>series_mix_qt</th>                    <td>    0.1165</td> <td>    0.022</td> <td>    5.323</td> <td> 0.000</td> <td>    0.074</td> <td>    0.159</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lighthearted_mm__relaxing_boxcox</th> <td>   -0.0041</td> <td>    0.002</td> <td>   -2.491</td> <td> 0.013</td> <td>   -0.007</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tense_rs_dark_ss</th>                 <td>    0.3414</td> <td>    0.129</td> <td>    2.649</td> <td> 0.008</td> <td>    0.089</td> <td>    0.594</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lighthearted_mm__funny_qt</th>        <td>    0.1127</td> <td>    0.010</td> <td>   10.747</td> <td> 0.000</td> <td>    0.092</td> <td>    0.133</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>116.895</td> <th>  Durbin-Watson:     </th> <td>   2.017</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 164.332</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.245</td>  <th>  Prob(JB):          </th> <td>2.07e-36</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.687</td>  <th>  Cond. No.          </th> <td>    402.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}                       &      stars       & \\textbf{  R-squared:         } &     0.412   \\\\\n",
       "\\textbf{Model:}                               &       OLS        & \\textbf{  Adj. R-squared:    } &     0.408   \\\\\n",
       "\\textbf{Method:}                              &  Least Squares   & \\textbf{  F-statistic:       } &     98.76   \\\\\n",
       "\\textbf{Date:}                                & Sat, 11 May 2024 & \\textbf{  Prob (F-statistic):} &     0.00    \\\\\n",
       "\\textbf{Time:}                                &     19:38:29     & \\textbf{  Log-Likelihood:    } &    254.48   \\\\\n",
       "\\textbf{No. Observations:}                    &        5544      & \\textbf{  AIC:               } &    -429.0   \\\\\n",
       "\\textbf{Df Residuals:}                        &        5504      & \\textbf{  BIC:               } &    -164.1   \\\\\n",
       "\\textbf{Df Model:}                            &          39      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}                     &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                                              & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept}                            &       2.5155  &        0.116     &    21.716  &         0.000        &        2.288    &        2.743     \\\\\n",
       "\\textbf{Crime}                                &       0.0159  &        0.013     &     1.268  &         0.205        &       -0.009    &        0.040     \\\\\n",
       "\\textbf{Romans}                               &      -0.1002  &        0.010     &   -10.071  &         0.000        &       -0.120    &       -0.081     \\\\\n",
       "\\textbf{sad\\_mm}                              &       0.2819  &        0.025     &    11.277  &         0.000        &        0.233    &        0.331     \\\\\n",
       "\\textbf{reviews\\_boxcox}                      &      -0.3657  &        0.037     &    -9.832  &         0.000        &       -0.439    &       -0.293     \\\\\n",
       "\\textbf{reflective\\_boxcox}                   &       0.0244  &        0.007     &     3.341  &         0.001        &        0.010    &        0.039     \\\\\n",
       "\\textbf{mysterious\\_rs}                       &       0.0424  &        0.012     &     3.654  &         0.000        &        0.020    &        0.065     \\\\\n",
       "\\textbf{inspiring\\_log}                       &       0.0111  &        0.004     &     2.914  &         0.004        &        0.004    &        0.019     \\\\\n",
       "\\textbf{informative\\_boxcox}                  &       0.0024  &        0.001     &     1.860  &         0.063        &       -0.000    &        0.005     \\\\\n",
       "\\textbf{emotional\\_boxcox}                    &       0.0133  &        0.019     &     0.711  &         0.477        &       -0.023    &        0.050     \\\\\n",
       "\\textbf{challenging\\_mm}                      &       0.4429  &        0.111     &     3.990  &         0.000        &        0.225    &        0.661     \\\\\n",
       "\\textbf{author\\_stars}                        &       0.0034  &        0.003     &     1.087  &         0.277        &       -0.003    &        0.010     \\\\\n",
       "\\textbf{Fantasy\\_author\\_stars}               &       0.0045  &        0.004     &     1.227  &         0.220        &       -0.003    &        0.012     \\\\\n",
       "\\textbf{Fantasy\\_mix\\_qt}                     &       0.0178  &        0.020     &     0.870  &         0.385        &       -0.022    &        0.058     \\\\\n",
       "\\textbf{Fiction\\_adventurous\\_qt}             &       0.1298  &        0.022     &     5.965  &         0.000        &        0.087    &        0.172     \\\\\n",
       "\\textbf{Fiction\\_author\\_count\\_ss}           &       0.0201  &        0.004     &     5.543  &         0.000        &        0.013    &        0.027     \\\\\n",
       "\\textbf{Fiction\\_challenging\\_mm}             &      -0.1187  &        0.109     &    -1.093  &         0.274        &       -0.331    &        0.094     \\\\\n",
       "\\textbf{Fiction\\_character\\_ss}               &      -0.0519  &        0.006     &    -8.502  &         0.000        &       -0.064    &       -0.040     \\\\\n",
       "\\textbf{Fiction\\_emotional\\_boxcox}           &      -0.1172  &        0.022     &    -5.223  &         0.000        &       -0.161    &       -0.073     \\\\\n",
       "\\textbf{Fiction\\_hopeful\\_rs}                 &       0.1084  &        0.009     &    12.319  &         0.000        &        0.091    &        0.126     \\\\\n",
       "\\textbf{Fiction\\_mix\\_qt}                     &       0.1775  &        0.024     &     7.425  &         0.000        &        0.131    &        0.224     \\\\\n",
       "\\textbf{Fiction\\_pages\\_qt}                   &      -0.0085  &        0.014     &    -0.593  &         0.553        &       -0.037    &        0.020     \\\\\n",
       "\\textbf{Fiction\\_plot\\_qt}                    &      -0.3081  &        0.025     &   -12.095  &         0.000        &       -0.358    &       -0.258     \\\\\n",
       "\\textbf{Literary\\_author\\_stars}              &       0.0063  &        0.003     &     1.880  &         0.060        &       -0.000    &        0.013     \\\\\n",
       "\\textbf{Literary\\_emotional\\_boxcox}          &       0.0074  &        0.016     &     0.454  &         0.650        &       -0.025    &        0.039     \\\\\n",
       "\\textbf{Literary\\_hopeful\\_rs}                &       0.0247  &        0.010     &     2.354  &         0.019        &        0.004    &        0.045     \\\\\n",
       "\\textbf{Literary\\_inspiring\\_log}             &      -0.0084  &        0.005     &    -1.841  &         0.066        &       -0.017    &        0.001     \\\\\n",
       "\\textbf{Literary\\_mysterious\\_rs}             &      -0.0188  &        0.014     &    -1.368  &         0.171        &       -0.046    &        0.008     \\\\\n",
       "\\textbf{Nonfiction\\_author\\_count\\_ss}        &      -0.0730  &        0.014     &    -5.173  &         0.000        &       -0.101    &       -0.045     \\\\\n",
       "\\textbf{Nonfiction\\_author\\_stars}            &       0.0217  &        0.004     &     4.940  &         0.000        &        0.013    &        0.030     \\\\\n",
       "\\textbf{Nonfiction\\_challenging\\_mm}          &       0.2843  &        0.105     &     2.704  &         0.007        &        0.078    &        0.490     \\\\\n",
       "\\textbf{Nonfiction\\_dark\\_ss}                 &      -0.0433  &        0.011     &    -3.769  &         0.000        &       -0.066    &       -0.021     \\\\\n",
       "\\textbf{Social\\_author\\_stars}                &       0.0114  &        0.003     &     3.370  &         0.001        &        0.005    &        0.018     \\\\\n",
       "\\textbf{Social\\_challenging\\_mm}              &       0.0278  &        0.040     &     0.694  &         0.488        &       -0.051    &        0.106     \\\\\n",
       "\\textbf{series\\_author\\_stars}                &       0.0112  &        0.003     &     3.200  &         0.001        &        0.004    &        0.018     \\\\\n",
       "\\textbf{series\\_inspiring\\_log}               &       0.0031  &        0.005     &     0.660  &         0.509        &       -0.006    &        0.012     \\\\\n",
       "\\textbf{series\\_mix\\_qt}                      &       0.1165  &        0.022     &     5.323  &         0.000        &        0.074    &        0.159     \\\\\n",
       "\\textbf{lighthearted\\_mm\\_\\_relaxing\\_boxcox} &      -0.0041  &        0.002     &    -2.491  &         0.013        &       -0.007    &       -0.001     \\\\\n",
       "\\textbf{tense\\_rs\\_dark\\_ss}                  &       0.3414  &        0.129     &     2.649  &         0.008        &        0.089    &        0.594     \\\\\n",
       "\\textbf{lighthearted\\_mm\\_\\_funny\\_qt}        &       0.1127  &        0.010     &    10.747  &         0.000        &        0.092    &        0.133     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 116.895 & \\textbf{  Durbin-Watson:     } &    2.017  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } &  164.332  \\\\\n",
       "\\textbf{Skew:}          &  -0.245 & \\textbf{  Prob(JB):          } & 2.07e-36  \\\\\n",
       "\\textbf{Kurtosis:}      &   3.687 & \\textbf{  Cond. No.          } &     402.  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  stars   R-squared:                       0.412\n",
       "Model:                            OLS   Adj. R-squared:                  0.408\n",
       "Method:                 Least Squares   F-statistic:                     98.76\n",
       "Date:                Sat, 11 May 2024   Prob (F-statistic):               0.00\n",
       "Time:                        19:38:29   Log-Likelihood:                 254.48\n",
       "No. Observations:                5544   AIC:                            -429.0\n",
       "Df Residuals:                    5504   BIC:                            -164.1\n",
       "Df Model:                          39                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "====================================================================================================\n",
       "                                       coef    std err          t      P>|t|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------------------------\n",
       "Intercept                            2.5155      0.116     21.716      0.000       2.288       2.743\n",
       "Crime                                0.0159      0.013      1.268      0.205      -0.009       0.040\n",
       "Romans                              -0.1002      0.010    -10.071      0.000      -0.120      -0.081\n",
       "sad_mm                               0.2819      0.025     11.277      0.000       0.233       0.331\n",
       "reviews_boxcox                      -0.3657      0.037     -9.832      0.000      -0.439      -0.293\n",
       "reflective_boxcox                    0.0244      0.007      3.341      0.001       0.010       0.039\n",
       "mysterious_rs                        0.0424      0.012      3.654      0.000       0.020       0.065\n",
       "inspiring_log                        0.0111      0.004      2.914      0.004       0.004       0.019\n",
       "informative_boxcox                   0.0024      0.001      1.860      0.063      -0.000       0.005\n",
       "emotional_boxcox                     0.0133      0.019      0.711      0.477      -0.023       0.050\n",
       "challenging_mm                       0.4429      0.111      3.990      0.000       0.225       0.661\n",
       "author_stars                         0.0034      0.003      1.087      0.277      -0.003       0.010\n",
       "Fantasy_author_stars                 0.0045      0.004      1.227      0.220      -0.003       0.012\n",
       "Fantasy_mix_qt                       0.0178      0.020      0.870      0.385      -0.022       0.058\n",
       "Fiction_adventurous_qt               0.1298      0.022      5.965      0.000       0.087       0.172\n",
       "Fiction_author_count_ss              0.0201      0.004      5.543      0.000       0.013       0.027\n",
       "Fiction_challenging_mm              -0.1187      0.109     -1.093      0.274      -0.331       0.094\n",
       "Fiction_character_ss                -0.0519      0.006     -8.502      0.000      -0.064      -0.040\n",
       "Fiction_emotional_boxcox            -0.1172      0.022     -5.223      0.000      -0.161      -0.073\n",
       "Fiction_hopeful_rs                   0.1084      0.009     12.319      0.000       0.091       0.126\n",
       "Fiction_mix_qt                       0.1775      0.024      7.425      0.000       0.131       0.224\n",
       "Fiction_pages_qt                    -0.0085      0.014     -0.593      0.553      -0.037       0.020\n",
       "Fiction_plot_qt                     -0.3081      0.025    -12.095      0.000      -0.358      -0.258\n",
       "Literary_author_stars                0.0063      0.003      1.880      0.060      -0.000       0.013\n",
       "Literary_emotional_boxcox            0.0074      0.016      0.454      0.650      -0.025       0.039\n",
       "Literary_hopeful_rs                  0.0247      0.010      2.354      0.019       0.004       0.045\n",
       "Literary_inspiring_log              -0.0084      0.005     -1.841      0.066      -0.017       0.001\n",
       "Literary_mysterious_rs              -0.0188      0.014     -1.368      0.171      -0.046       0.008\n",
       "Nonfiction_author_count_ss          -0.0730      0.014     -5.173      0.000      -0.101      -0.045\n",
       "Nonfiction_author_stars              0.0217      0.004      4.940      0.000       0.013       0.030\n",
       "Nonfiction_challenging_mm            0.2843      0.105      2.704      0.007       0.078       0.490\n",
       "Nonfiction_dark_ss                  -0.0433      0.011     -3.769      0.000      -0.066      -0.021\n",
       "Social_author_stars                  0.0114      0.003      3.370      0.001       0.005       0.018\n",
       "Social_challenging_mm                0.0278      0.040      0.694      0.488      -0.051       0.106\n",
       "series_author_stars                  0.0112      0.003      3.200      0.001       0.004       0.018\n",
       "series_inspiring_log                 0.0031      0.005      0.660      0.509      -0.006       0.012\n",
       "series_mix_qt                        0.1165      0.022      5.323      0.000       0.074       0.159\n",
       "lighthearted_mm__relaxing_boxcox    -0.0041      0.002     -2.491      0.013      -0.007      -0.001\n",
       "tense_rs_dark_ss                     0.3414      0.129      2.649      0.008       0.089       0.594\n",
       "lighthearted_mm__funny_qt            0.1127      0.010     10.747      0.000       0.092       0.133\n",
       "==============================================================================\n",
       "Omnibus:                      116.895   Durbin-Watson:                   2.017\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              164.332\n",
       "Skew:                          -0.245   Prob(JB):                     2.07e-36\n",
       "Kurtosis:                       3.687   Cond. No.                         402.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_transformations=pd.read_csv(\"../data/data_fe.csv\")\n",
    "data_transformations=data_transformations.drop(columns=['Unnamed: 0'])\n",
    "features_transformations=data_transformations.columns.tolist()\n",
    "features_transformations.remove('stars')\n",
    "train_data_transformations, test_data_transformations = train_test_split(data_transformations, test_size=0.2, random_state=SEED)\n",
    "wzor = 'stars~' + '+'.join(features_transformations)\n",
    "mod = smf.ols(formula = wzor, data = train_data_transformations)\n",
    "res = mod.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9791cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 0.23086218185156407\n",
      "Validation RMSE: 0.23336460790373134\n"
     ]
    }
   ],
   "source": [
    "model = LinearRegression(fit_intercept=True)\n",
    "train_scores, validation_scores = perform_cv(train_data_transformations[features_transformations], train_data_transformations[target], model)\n",
    "print(\"Train RMSE:\", train_scores)\n",
    "print(\"Validation RMSE:\", validation_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0044d9",
   "metadata": {},
   "source": [
    "Najlepszy wynik dla modelu z interkacjami bez transformacji, ale nadal dużo zmiennych wyszło jako nieistotne statystyczne, nawet te o dużej wartości MI, dlatego przeprowadzimy analizę VIF współliniowości"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf5cbbc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>VIF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Fiction_character</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Fiction_mix</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mix</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>character</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>plot</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Fiction_plot</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Fiction_mysterious</td>\n",
       "      <td>344.819537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>mysterious</td>\n",
       "      <td>344.498437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Fiction_tense</td>\n",
       "      <td>258.057208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>tense</td>\n",
       "      <td>249.380952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Fiction</td>\n",
       "      <td>144.408119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>challenging</td>\n",
       "      <td>141.130846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Fiction_adventurous</td>\n",
       "      <td>136.400122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Fiction_dark</td>\n",
       "      <td>132.472005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Fiction_emotional</td>\n",
       "      <td>131.112724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>dark</td>\n",
       "      <td>125.656214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>adventurous</td>\n",
       "      <td>120.597237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>emotional</td>\n",
       "      <td>120.393405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>hopeful</td>\n",
       "      <td>117.066568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Fiction_challenging</td>\n",
       "      <td>109.349999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Fiction_hopeful</td>\n",
       "      <td>108.979125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>author_stars</td>\n",
       "      <td>98.717317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Fiction_author_stars</td>\n",
       "      <td>87.643297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Fiction_sad</td>\n",
       "      <td>62.776084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>sad</td>\n",
       "      <td>62.525180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>reflective</td>\n",
       "      <td>59.764616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Fiction_reflective</td>\n",
       "      <td>50.978448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Fantasy_mix</td>\n",
       "      <td>31.422285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Nonfiction_challenging</td>\n",
       "      <td>28.597865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Fantasy</td>\n",
       "      <td>26.744810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>series</td>\n",
       "      <td>24.436940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>series_mix</td>\n",
       "      <td>22.584714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Literary</td>\n",
       "      <td>22.319402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>inspiring</td>\n",
       "      <td>21.383063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Literary_emotional</td>\n",
       "      <td>21.132948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Fantasy_adventurous</td>\n",
       "      <td>20.428447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Fiction_inspiring</td>\n",
       "      <td>19.297010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Nonfiction</td>\n",
       "      <td>16.311474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>series_adventurous</td>\n",
       "      <td>15.648094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>lighthearted</td>\n",
       "      <td>15.516182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Crime</td>\n",
       "      <td>14.533389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Crime_mix</td>\n",
       "      <td>13.783349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Nonfiction_hopeful</td>\n",
       "      <td>12.629741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Literary_sad</td>\n",
       "      <td>12.012002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Nonfiction_author_stars</td>\n",
       "      <td>9.689753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Literary_mix</td>\n",
       "      <td>9.470998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pages</td>\n",
       "      <td>8.686974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>series_emotional</td>\n",
       "      <td>8.279990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>series_author_stars</td>\n",
       "      <td>7.849711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Fantasy_author_stars</td>\n",
       "      <td>7.323371</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    feature         VIF\n",
       "40        Fiction_character         inf\n",
       "45              Fiction_mix         inf\n",
       "4                       mix         inf\n",
       "5                 character         inf\n",
       "6                      plot         inf\n",
       "47             Fiction_plot         inf\n",
       "46       Fiction_mysterious  344.819537\n",
       "19               mysterious  344.498437\n",
       "50            Fiction_tense  258.057208\n",
       "13                    tense  249.380952\n",
       "23                  Fiction  144.408119\n",
       "17              challenging  141.130846\n",
       "37      Fiction_adventurous  136.400122\n",
       "41             Fiction_dark  132.472005\n",
       "42        Fiction_emotional  131.112724\n",
       "20                     dark  125.656214\n",
       "16              adventurous  120.597237\n",
       "9                 emotional  120.393405\n",
       "10                  hopeful  117.066568\n",
       "39      Fiction_challenging  109.349999\n",
       "43          Fiction_hopeful  108.979125\n",
       "22             author_stars   98.717317\n",
       "38     Fiction_author_stars   87.643297\n",
       "49              Fiction_sad   62.776084\n",
       "14                      sad   62.525180\n",
       "15               reflective   59.764616\n",
       "48       Fiction_reflective   50.978448\n",
       "36              Fantasy_mix   31.422285\n",
       "58   Nonfiction_challenging   28.597865\n",
       "26                  Fantasy   26.744810\n",
       "3                    series   24.436940\n",
       "65               series_mix   22.584714\n",
       "25                 Literary   22.319402\n",
       "11                inspiring   21.383063\n",
       "52       Literary_emotional   21.132948\n",
       "33      Fantasy_adventurous   20.428447\n",
       "44        Fiction_inspiring   19.297010\n",
       "24               Nonfiction   16.311474\n",
       "62       series_adventurous   15.648094\n",
       "8              lighthearted   15.516182\n",
       "27                    Crime   14.533389\n",
       "32                Crime_mix   13.783349\n",
       "59       Nonfiction_hopeful   12.629741\n",
       "56             Literary_sad   12.012002\n",
       "57  Nonfiction_author_stars    9.689753\n",
       "54             Literary_mix    9.470998\n",
       "1                     pages    8.686974\n",
       "64         series_emotional    8.279990\n",
       "63      series_author_stars    7.849711\n",
       "34     Fantasy_author_stars    7.323371"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the independent variables set \n",
    "X = train_data_interactions[features_interactions]\n",
    "# VIF dataframe \n",
    "vif_data = pd.DataFrame() \n",
    "vif_data[\"feature\"] = X.columns \n",
    "# calculating VIF for each feature \n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(len(X.columns))] \n",
    "vif_data.sort_values(by=[\"VIF\"], ascending=False).head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce49369",
   "metadata": {},
   "source": [
    "Na początek usuniemy z modelu zmienne: mix, character, plot, Fiction_mysterious, Fiction_tense, Fiction_adventurous, Fiction_dark, Fiction_emotional, Fiction_challenging, Fiction_hopeful, Fiction_author_stars, Fiction_sad, Fiction_reflective, Nonfiction_challenging, series_mix, Fiction, Fanstasy_mix i Literary_sad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a24ed3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_remove = [\"mix\", \"character\", \"plot\", \"Fiction_mysterious\", \"Fiction_tense\", \"Fiction_adventurous\", \"Fiction_dark\", \"Fiction_emotional\", \"Fiction_challenging\", \"Fiction_hopeful\", \"Fiction_author_stars\", \"Fiction_sad\", \"Fiction_reflective\", \"Nonfiction_challenging\", \"series_mix\", \"Fiction\", \"Fantasy_mix\", \"Literary_sad\"]\n",
    "for feature in features_to_remove:\n",
    "    features_interactions.remove(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "294d1cdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>stars</td>      <th>  R-squared:         </th> <td>   0.491</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.487</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   110.5</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 11 May 2024</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>19:38:32</td>     <th>  Log-Likelihood:    </th> <td>  657.04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  5544</td>      <th>  AIC:               </th> <td>  -1216.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  5495</td>      <th>  BIC:               </th> <td>  -891.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    48</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "             <td></td>                <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>               <td>    3.0893</td> <td>    0.035</td> <td>   89.400</td> <td> 0.000</td> <td>    3.022</td> <td>    3.157</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>index_0</th>                 <td>-1.223e-05</td> <td> 1.48e-06</td> <td>   -8.264</td> <td> 0.000</td> <td>-1.51e-05</td> <td>-9.33e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pages</th>                   <td>-2.326e-05</td> <td> 2.19e-05</td> <td>   -1.063</td> <td> 0.288</td> <td>-6.61e-05</td> <td> 1.96e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>reviews</th>                 <td> 7.963e-07</td> <td> 1.21e-07</td> <td>    6.567</td> <td> 0.000</td> <td> 5.59e-07</td> <td> 1.03e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>series</th>                  <td>    0.0412</td> <td>    0.020</td> <td>    2.088</td> <td> 0.037</td> <td>    0.003</td> <td>    0.080</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>funny</th>                   <td>    0.3933</td> <td>    0.021</td> <td>   18.793</td> <td> 0.000</td> <td>    0.352</td> <td>    0.434</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lighthearted</th>            <td>   -0.0076</td> <td>    0.036</td> <td>   -0.213</td> <td> 0.832</td> <td>   -0.078</td> <td>    0.063</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>emotional</th>               <td>    0.3710</td> <td>    0.031</td> <td>   11.987</td> <td> 0.000</td> <td>    0.310</td> <td>    0.432</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>hopeful</th>                 <td>    0.2893</td> <td>    0.041</td> <td>    7.032</td> <td> 0.000</td> <td>    0.209</td> <td>    0.370</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>inspiring</th>               <td>    0.2474</td> <td>    0.049</td> <td>    5.092</td> <td> 0.000</td> <td>    0.152</td> <td>    0.343</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>relaxing</th>                <td>    0.7824</td> <td>    0.074</td> <td>   10.567</td> <td> 0.000</td> <td>    0.637</td> <td>    0.928</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tense</th>                   <td>    0.2914</td> <td>    0.033</td> <td>    8.859</td> <td> 0.000</td> <td>    0.227</td> <td>    0.356</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sad</th>                     <td>    0.1910</td> <td>    0.029</td> <td>    6.645</td> <td> 0.000</td> <td>    0.135</td> <td>    0.247</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>reflective</th>              <td>   -0.0250</td> <td>    0.028</td> <td>   -0.909</td> <td> 0.364</td> <td>   -0.079</td> <td>    0.029</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>adventurous</th>             <td>    0.0749</td> <td>    0.023</td> <td>    3.270</td> <td> 0.001</td> <td>    0.030</td> <td>    0.120</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>challenging</th>             <td>    0.4226</td> <td>    0.029</td> <td>   14.359</td> <td> 0.000</td> <td>    0.365</td> <td>    0.480</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>informative</th>             <td>    0.4376</td> <td>    0.025</td> <td>   17.463</td> <td> 0.000</td> <td>    0.388</td> <td>    0.487</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mysterious</th>              <td>    0.1813</td> <td>    0.023</td> <td>    7.983</td> <td> 0.000</td> <td>    0.137</td> <td>    0.226</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>dark</th>                    <td>    0.0346</td> <td>    0.021</td> <td>    1.621</td> <td> 0.105</td> <td>   -0.007</td> <td>    0.076</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>author_count</th>            <td>    0.0022</td> <td>    0.000</td> <td>    4.515</td> <td> 0.000</td> <td>    0.001</td> <td>    0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>author_stars</th>            <td>    0.0111</td> <td>    0.003</td> <td>    3.242</td> <td> 0.001</td> <td>    0.004</td> <td>    0.018</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Nonfiction</th>              <td>    0.1958</td> <td>    0.021</td> <td>    9.442</td> <td> 0.000</td> <td>    0.155</td> <td>    0.237</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Literary</th>                <td>    0.0946</td> <td>    0.023</td> <td>    4.151</td> <td> 0.000</td> <td>    0.050</td> <td>    0.139</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Fantasy</th>                 <td>   -0.0175</td> <td>    0.019</td> <td>   -0.928</td> <td> 0.353</td> <td>   -0.054</td> <td>    0.019</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Crime</th>                   <td>   -0.0422</td> <td>    0.025</td> <td>   -1.687</td> <td> 0.092</td> <td>   -0.091</td> <td>    0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Social</th>                  <td>    0.0210</td> <td>    0.013</td> <td>    1.655</td> <td> 0.098</td> <td>   -0.004</td> <td>    0.046</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Children</th>                <td>   -0.0361</td> <td>    0.009</td> <td>   -4.237</td> <td> 0.000</td> <td>   -0.053</td> <td>   -0.019</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Romans</th>                  <td>   -0.0378</td> <td>    0.015</td> <td>   -2.443</td> <td> 0.015</td> <td>   -0.068</td> <td>   -0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Realism</th>                 <td>   -0.0454</td> <td>    0.009</td> <td>   -5.104</td> <td> 0.000</td> <td>   -0.063</td> <td>   -0.028</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Crime_mix</th>               <td>    0.1118</td> <td>    0.052</td> <td>    2.164</td> <td> 0.030</td> <td>    0.011</td> <td>    0.213</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Fantasy_adventurous</th>     <td>    0.1171</td> <td>    0.028</td> <td>    4.254</td> <td> 0.000</td> <td>    0.063</td> <td>    0.171</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Fantasy_author_stars</th>    <td>   -0.0030</td> <td>    0.004</td> <td>   -0.781</td> <td> 0.435</td> <td>   -0.011</td> <td>    0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Fantasy_inspiring</th>       <td>    0.0173</td> <td>    0.058</td> <td>    0.297</td> <td> 0.766</td> <td>   -0.097</td> <td>    0.131</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Fiction_character</th>       <td>   -0.0785</td> <td>    0.021</td> <td>   -3.719</td> <td> 0.000</td> <td>   -0.120</td> <td>   -0.037</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Fiction_inspiring</th>       <td>    0.2960</td> <td>    0.057</td> <td>    5.156</td> <td> 0.000</td> <td>    0.183</td> <td>    0.409</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Fiction_mix</th>             <td>    0.1598</td> <td>    0.034</td> <td>    4.752</td> <td> 0.000</td> <td>    0.094</td> <td>    0.226</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Fiction_plot</th>            <td>   -0.1299</td> <td>    0.035</td> <td>   -3.742</td> <td> 0.000</td> <td>   -0.198</td> <td>   -0.062</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Literary_author_stars</th>   <td>    0.0050</td> <td>    0.004</td> <td>    1.406</td> <td> 0.160</td> <td>   -0.002</td> <td>    0.012</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Literary_emotional</th>      <td>    0.0796</td> <td>    0.027</td> <td>    2.937</td> <td> 0.003</td> <td>    0.026</td> <td>    0.133</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Literary_inspiring</th>      <td>   -0.1861</td> <td>    0.045</td> <td>   -4.127</td> <td> 0.000</td> <td>   -0.275</td> <td>   -0.098</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Literary_mix</th>            <td>   -0.2765</td> <td>    0.039</td> <td>   -7.067</td> <td> 0.000</td> <td>   -0.353</td> <td>   -0.200</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Literary_mysterious</th>     <td>    0.0454</td> <td>    0.028</td> <td>    1.617</td> <td> 0.106</td> <td>   -0.010</td> <td>    0.101</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Nonfiction_author_stars</th> <td>   -0.0016</td> <td>    0.004</td> <td>   -0.365</td> <td> 0.715</td> <td>   -0.010</td> <td>    0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Nonfiction_hopeful</th>      <td>   -0.1329</td> <td>    0.061</td> <td>   -2.196</td> <td> 0.028</td> <td>   -0.251</td> <td>   -0.014</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Romans_author_stars</th>     <td>   -0.0023</td> <td>    0.004</td> <td>   -0.538</td> <td> 0.591</td> <td>   -0.011</td> <td>    0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Social_author_stars</th>     <td>    0.0107</td> <td>    0.004</td> <td>    2.688</td> <td> 0.007</td> <td>    0.003</td> <td>    0.019</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>series_adventurous</th>      <td>    0.0837</td> <td>    0.023</td> <td>    3.563</td> <td> 0.000</td> <td>    0.038</td> <td>    0.130</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>series_author_stars</th>     <td>    0.0144</td> <td>    0.004</td> <td>    3.848</td> <td> 0.000</td> <td>    0.007</td> <td>    0.022</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>series_emotional</th>        <td>   -0.0958</td> <td>    0.027</td> <td>   -3.594</td> <td> 0.000</td> <td>   -0.148</td> <td>   -0.044</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>220.830</td> <th>  Durbin-Watson:     </th> <td>   2.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 356.180</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.353</td>  <th>  Prob(JB):          </th> <td>4.54e-78</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.022</td>  <th>  Cond. No.          </th> <td>8.30e+05</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 8.3e+05. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}            &      stars       & \\textbf{  R-squared:         } &     0.491   \\\\\n",
       "\\textbf{Model:}                    &       OLS        & \\textbf{  Adj. R-squared:    } &     0.487   \\\\\n",
       "\\textbf{Method:}                   &  Least Squares   & \\textbf{  F-statistic:       } &     110.5   \\\\\n",
       "\\textbf{Date:}                     & Sat, 11 May 2024 & \\textbf{  Prob (F-statistic):} &     0.00    \\\\\n",
       "\\textbf{Time:}                     &     19:38:32     & \\textbf{  Log-Likelihood:    } &    657.04   \\\\\n",
       "\\textbf{No. Observations:}         &        5544      & \\textbf{  AIC:               } &    -1216.   \\\\\n",
       "\\textbf{Df Residuals:}             &        5495      & \\textbf{  BIC:               } &    -891.7   \\\\\n",
       "\\textbf{Df Model:}                 &          48      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}          &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                                   & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept}                 &       3.0893  &        0.035     &    89.400  &         0.000        &        3.022    &        3.157     \\\\\n",
       "\\textbf{index\\_0}                  &   -1.223e-05  &     1.48e-06     &    -8.264  &         0.000        &    -1.51e-05    &    -9.33e-06     \\\\\n",
       "\\textbf{pages}                     &   -2.326e-05  &     2.19e-05     &    -1.063  &         0.288        &    -6.61e-05    &     1.96e-05     \\\\\n",
       "\\textbf{reviews}                   &    7.963e-07  &     1.21e-07     &     6.567  &         0.000        &     5.59e-07    &     1.03e-06     \\\\\n",
       "\\textbf{series}                    &       0.0412  &        0.020     &     2.088  &         0.037        &        0.003    &        0.080     \\\\\n",
       "\\textbf{funny}                     &       0.3933  &        0.021     &    18.793  &         0.000        &        0.352    &        0.434     \\\\\n",
       "\\textbf{lighthearted}              &      -0.0076  &        0.036     &    -0.213  &         0.832        &       -0.078    &        0.063     \\\\\n",
       "\\textbf{emotional}                 &       0.3710  &        0.031     &    11.987  &         0.000        &        0.310    &        0.432     \\\\\n",
       "\\textbf{hopeful}                   &       0.2893  &        0.041     &     7.032  &         0.000        &        0.209    &        0.370     \\\\\n",
       "\\textbf{inspiring}                 &       0.2474  &        0.049     &     5.092  &         0.000        &        0.152    &        0.343     \\\\\n",
       "\\textbf{relaxing}                  &       0.7824  &        0.074     &    10.567  &         0.000        &        0.637    &        0.928     \\\\\n",
       "\\textbf{tense}                     &       0.2914  &        0.033     &     8.859  &         0.000        &        0.227    &        0.356     \\\\\n",
       "\\textbf{sad}                       &       0.1910  &        0.029     &     6.645  &         0.000        &        0.135    &        0.247     \\\\\n",
       "\\textbf{reflective}                &      -0.0250  &        0.028     &    -0.909  &         0.364        &       -0.079    &        0.029     \\\\\n",
       "\\textbf{adventurous}               &       0.0749  &        0.023     &     3.270  &         0.001        &        0.030    &        0.120     \\\\\n",
       "\\textbf{challenging}               &       0.4226  &        0.029     &    14.359  &         0.000        &        0.365    &        0.480     \\\\\n",
       "\\textbf{informative}               &       0.4376  &        0.025     &    17.463  &         0.000        &        0.388    &        0.487     \\\\\n",
       "\\textbf{mysterious}                &       0.1813  &        0.023     &     7.983  &         0.000        &        0.137    &        0.226     \\\\\n",
       "\\textbf{dark}                      &       0.0346  &        0.021     &     1.621  &         0.105        &       -0.007    &        0.076     \\\\\n",
       "\\textbf{author\\_count}             &       0.0022  &        0.000     &     4.515  &         0.000        &        0.001    &        0.003     \\\\\n",
       "\\textbf{author\\_stars}             &       0.0111  &        0.003     &     3.242  &         0.001        &        0.004    &        0.018     \\\\\n",
       "\\textbf{Nonfiction}                &       0.1958  &        0.021     &     9.442  &         0.000        &        0.155    &        0.237     \\\\\n",
       "\\textbf{Literary}                  &       0.0946  &        0.023     &     4.151  &         0.000        &        0.050    &        0.139     \\\\\n",
       "\\textbf{Fantasy}                   &      -0.0175  &        0.019     &    -0.928  &         0.353        &       -0.054    &        0.019     \\\\\n",
       "\\textbf{Crime}                     &      -0.0422  &        0.025     &    -1.687  &         0.092        &       -0.091    &        0.007     \\\\\n",
       "\\textbf{Social}                    &       0.0210  &        0.013     &     1.655  &         0.098        &       -0.004    &        0.046     \\\\\n",
       "\\textbf{Children}                  &      -0.0361  &        0.009     &    -4.237  &         0.000        &       -0.053    &       -0.019     \\\\\n",
       "\\textbf{Romans}                    &      -0.0378  &        0.015     &    -2.443  &         0.015        &       -0.068    &       -0.007     \\\\\n",
       "\\textbf{Realism}                   &      -0.0454  &        0.009     &    -5.104  &         0.000        &       -0.063    &       -0.028     \\\\\n",
       "\\textbf{Crime\\_mix}                &       0.1118  &        0.052     &     2.164  &         0.030        &        0.011    &        0.213     \\\\\n",
       "\\textbf{Fantasy\\_adventurous}      &       0.1171  &        0.028     &     4.254  &         0.000        &        0.063    &        0.171     \\\\\n",
       "\\textbf{Fantasy\\_author\\_stars}    &      -0.0030  &        0.004     &    -0.781  &         0.435        &       -0.011    &        0.005     \\\\\n",
       "\\textbf{Fantasy\\_inspiring}        &       0.0173  &        0.058     &     0.297  &         0.766        &       -0.097    &        0.131     \\\\\n",
       "\\textbf{Fiction\\_character}        &      -0.0785  &        0.021     &    -3.719  &         0.000        &       -0.120    &       -0.037     \\\\\n",
       "\\textbf{Fiction\\_inspiring}        &       0.2960  &        0.057     &     5.156  &         0.000        &        0.183    &        0.409     \\\\\n",
       "\\textbf{Fiction\\_mix}              &       0.1598  &        0.034     &     4.752  &         0.000        &        0.094    &        0.226     \\\\\n",
       "\\textbf{Fiction\\_plot}             &      -0.1299  &        0.035     &    -3.742  &         0.000        &       -0.198    &       -0.062     \\\\\n",
       "\\textbf{Literary\\_author\\_stars}   &       0.0050  &        0.004     &     1.406  &         0.160        &       -0.002    &        0.012     \\\\\n",
       "\\textbf{Literary\\_emotional}       &       0.0796  &        0.027     &     2.937  &         0.003        &        0.026    &        0.133     \\\\\n",
       "\\textbf{Literary\\_inspiring}       &      -0.1861  &        0.045     &    -4.127  &         0.000        &       -0.275    &       -0.098     \\\\\n",
       "\\textbf{Literary\\_mix}             &      -0.2765  &        0.039     &    -7.067  &         0.000        &       -0.353    &       -0.200     \\\\\n",
       "\\textbf{Literary\\_mysterious}      &       0.0454  &        0.028     &     1.617  &         0.106        &       -0.010    &        0.101     \\\\\n",
       "\\textbf{Nonfiction\\_author\\_stars} &      -0.0016  &        0.004     &    -0.365  &         0.715        &       -0.010    &        0.007     \\\\\n",
       "\\textbf{Nonfiction\\_hopeful}       &      -0.1329  &        0.061     &    -2.196  &         0.028        &       -0.251    &       -0.014     \\\\\n",
       "\\textbf{Romans\\_author\\_stars}     &      -0.0023  &        0.004     &    -0.538  &         0.591        &       -0.011    &        0.006     \\\\\n",
       "\\textbf{Social\\_author\\_stars}     &       0.0107  &        0.004     &     2.688  &         0.007        &        0.003    &        0.019     \\\\\n",
       "\\textbf{series\\_adventurous}       &       0.0837  &        0.023     &     3.563  &         0.000        &        0.038    &        0.130     \\\\\n",
       "\\textbf{series\\_author\\_stars}     &       0.0144  &        0.004     &     3.848  &         0.000        &        0.007    &        0.022     \\\\\n",
       "\\textbf{series\\_emotional}         &      -0.0958  &        0.027     &    -3.594  &         0.000        &       -0.148    &       -0.044     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 220.830 & \\textbf{  Durbin-Watson:     } &    2.008  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } &  356.180  \\\\\n",
       "\\textbf{Skew:}          &  -0.353 & \\textbf{  Prob(JB):          } & 4.54e-78  \\\\\n",
       "\\textbf{Kurtosis:}      &   4.022 & \\textbf{  Cond. No.          } & 8.30e+05  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 8.3e+05. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  stars   R-squared:                       0.491\n",
       "Model:                            OLS   Adj. R-squared:                  0.487\n",
       "Method:                 Least Squares   F-statistic:                     110.5\n",
       "Date:                Sat, 11 May 2024   Prob (F-statistic):               0.00\n",
       "Time:                        19:38:32   Log-Likelihood:                 657.04\n",
       "No. Observations:                5544   AIC:                            -1216.\n",
       "Df Residuals:                    5495   BIC:                            -891.7\n",
       "Df Model:                          48                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "===========================================================================================\n",
       "                              coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------------------\n",
       "Intercept                   3.0893      0.035     89.400      0.000       3.022       3.157\n",
       "index_0                 -1.223e-05   1.48e-06     -8.264      0.000   -1.51e-05   -9.33e-06\n",
       "pages                   -2.326e-05   2.19e-05     -1.063      0.288   -6.61e-05    1.96e-05\n",
       "reviews                  7.963e-07   1.21e-07      6.567      0.000    5.59e-07    1.03e-06\n",
       "series                      0.0412      0.020      2.088      0.037       0.003       0.080\n",
       "funny                       0.3933      0.021     18.793      0.000       0.352       0.434\n",
       "lighthearted               -0.0076      0.036     -0.213      0.832      -0.078       0.063\n",
       "emotional                   0.3710      0.031     11.987      0.000       0.310       0.432\n",
       "hopeful                     0.2893      0.041      7.032      0.000       0.209       0.370\n",
       "inspiring                   0.2474      0.049      5.092      0.000       0.152       0.343\n",
       "relaxing                    0.7824      0.074     10.567      0.000       0.637       0.928\n",
       "tense                       0.2914      0.033      8.859      0.000       0.227       0.356\n",
       "sad                         0.1910      0.029      6.645      0.000       0.135       0.247\n",
       "reflective                 -0.0250      0.028     -0.909      0.364      -0.079       0.029\n",
       "adventurous                 0.0749      0.023      3.270      0.001       0.030       0.120\n",
       "challenging                 0.4226      0.029     14.359      0.000       0.365       0.480\n",
       "informative                 0.4376      0.025     17.463      0.000       0.388       0.487\n",
       "mysterious                  0.1813      0.023      7.983      0.000       0.137       0.226\n",
       "dark                        0.0346      0.021      1.621      0.105      -0.007       0.076\n",
       "author_count                0.0022      0.000      4.515      0.000       0.001       0.003\n",
       "author_stars                0.0111      0.003      3.242      0.001       0.004       0.018\n",
       "Nonfiction                  0.1958      0.021      9.442      0.000       0.155       0.237\n",
       "Literary                    0.0946      0.023      4.151      0.000       0.050       0.139\n",
       "Fantasy                    -0.0175      0.019     -0.928      0.353      -0.054       0.019\n",
       "Crime                      -0.0422      0.025     -1.687      0.092      -0.091       0.007\n",
       "Social                      0.0210      0.013      1.655      0.098      -0.004       0.046\n",
       "Children                   -0.0361      0.009     -4.237      0.000      -0.053      -0.019\n",
       "Romans                     -0.0378      0.015     -2.443      0.015      -0.068      -0.007\n",
       "Realism                    -0.0454      0.009     -5.104      0.000      -0.063      -0.028\n",
       "Crime_mix                   0.1118      0.052      2.164      0.030       0.011       0.213\n",
       "Fantasy_adventurous         0.1171      0.028      4.254      0.000       0.063       0.171\n",
       "Fantasy_author_stars       -0.0030      0.004     -0.781      0.435      -0.011       0.005\n",
       "Fantasy_inspiring           0.0173      0.058      0.297      0.766      -0.097       0.131\n",
       "Fiction_character          -0.0785      0.021     -3.719      0.000      -0.120      -0.037\n",
       "Fiction_inspiring           0.2960      0.057      5.156      0.000       0.183       0.409\n",
       "Fiction_mix                 0.1598      0.034      4.752      0.000       0.094       0.226\n",
       "Fiction_plot               -0.1299      0.035     -3.742      0.000      -0.198      -0.062\n",
       "Literary_author_stars       0.0050      0.004      1.406      0.160      -0.002       0.012\n",
       "Literary_emotional          0.0796      0.027      2.937      0.003       0.026       0.133\n",
       "Literary_inspiring         -0.1861      0.045     -4.127      0.000      -0.275      -0.098\n",
       "Literary_mix               -0.2765      0.039     -7.067      0.000      -0.353      -0.200\n",
       "Literary_mysterious         0.0454      0.028      1.617      0.106      -0.010       0.101\n",
       "Nonfiction_author_stars    -0.0016      0.004     -0.365      0.715      -0.010       0.007\n",
       "Nonfiction_hopeful         -0.1329      0.061     -2.196      0.028      -0.251      -0.014\n",
       "Romans_author_stars        -0.0023      0.004     -0.538      0.591      -0.011       0.006\n",
       "Social_author_stars         0.0107      0.004      2.688      0.007       0.003       0.019\n",
       "series_adventurous          0.0837      0.023      3.563      0.000       0.038       0.130\n",
       "series_author_stars         0.0144      0.004      3.848      0.000       0.007       0.022\n",
       "series_emotional           -0.0958      0.027     -3.594      0.000      -0.148      -0.044\n",
       "==============================================================================\n",
       "Omnibus:                      220.830   Durbin-Watson:                   2.008\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              356.180\n",
       "Skew:                          -0.353   Prob(JB):                     4.54e-78\n",
       "Kurtosis:                       4.022   Cond. No.                     8.30e+05\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 8.3e+05. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wzor = 'stars~' + '+'.join(features_interactions)\n",
    "mod = smf.ols(formula = wzor, data = train_data_interactions)\n",
    "res = mod.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543b67d4",
   "metadata": {},
   "source": [
    "Pozostały zmienne nieistotne statystycznie: Fantasy_author_stars, Fantasy_inspiring, Nonfiction_author_stars, Romans_author_stars oraz reflective, które mają niską wartość VIF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d3b21918",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_remove = [\"Fantasy_author_stars\", \"Fantasy_inspiring\", \"Nonfiction_author_stars\", \"Romans_author_stars\", \"reflective\"]\n",
    "for feature in features_to_remove:\n",
    "    features_interactions.remove(feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82145cb4",
   "metadata": {},
   "source": [
    "Również: lighthearted, która mają stosunkową wysoką wartość VIF.\n",
    "Z EDA wiemy, że zmienna lighthearted jest skorelowana z funny oraz relaxing, więc spróbujemy utworzyć nową zmienną."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6c5f11be",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_interactions['lighthearted_relaxing']=train_data_interactions['lighthearted']+train_data_interactions['relaxing']\n",
    "train_data_interactions['lighthearted_funny']=train_data_interactions['lighthearted']+train_data_interactions['funny']\n",
    "features_to_add = [\"lighthearted_funny\", \"lighthearted_relaxing\"]\n",
    "for feature in features_to_add:\n",
    "    features_interactions.append(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "51bbb715",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>stars</td>      <th>  R-squared:         </th> <td>   0.491</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.487</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   123.4</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 11 May 2024</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>19:38:32</td>     <th>  Log-Likelihood:    </th> <td>  656.18</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  5544</td>      <th>  AIC:               </th> <td>  -1224.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  5500</td>      <th>  BIC:               </th> <td>  -933.1</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    43</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "            <td></td>               <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>             <td>    3.0791</td> <td>    0.031</td> <td>  100.632</td> <td> 0.000</td> <td>    3.019</td> <td>    3.139</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>index_0</th>               <td>-1.221e-05</td> <td> 1.48e-06</td> <td>   -8.257</td> <td> 0.000</td> <td>-1.51e-05</td> <td>-9.31e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pages</th>                 <td>-2.215e-05</td> <td> 2.18e-05</td> <td>   -1.014</td> <td> 0.311</td> <td> -6.5e-05</td> <td> 2.07e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>reviews</th>               <td> 7.955e-07</td> <td> 1.21e-07</td> <td>    6.571</td> <td> 0.000</td> <td> 5.58e-07</td> <td> 1.03e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>series</th>                <td>    0.0448</td> <td>    0.019</td> <td>    2.323</td> <td> 0.020</td> <td>    0.007</td> <td>    0.083</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>funny</th>                 <td>    0.3396</td> <td>    0.025</td> <td>   13.849</td> <td> 0.000</td> <td>    0.291</td> <td>    0.388</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lighthearted</th>          <td>   -0.2875</td> <td>    0.033</td> <td>   -8.600</td> <td> 0.000</td> <td>   -0.353</td> <td>   -0.222</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>emotional</th>             <td>    0.3679</td> <td>    0.031</td> <td>   11.953</td> <td> 0.000</td> <td>    0.308</td> <td>    0.428</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>hopeful</th>               <td>    0.2933</td> <td>    0.041</td> <td>    7.178</td> <td> 0.000</td> <td>    0.213</td> <td>    0.373</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>inspiring</th>             <td>    0.2422</td> <td>    0.048</td> <td>    5.041</td> <td> 0.000</td> <td>    0.148</td> <td>    0.336</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>relaxing</th>              <td>    0.5291</td> <td>    0.052</td> <td>   10.261</td> <td> 0.000</td> <td>    0.428</td> <td>    0.630</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tense</th>                 <td>    0.3015</td> <td>    0.031</td> <td>    9.706</td> <td> 0.000</td> <td>    0.241</td> <td>    0.362</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sad</th>                   <td>    0.1920</td> <td>    0.029</td> <td>    6.692</td> <td> 0.000</td> <td>    0.136</td> <td>    0.248</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>adventurous</th>           <td>    0.0783</td> <td>    0.023</td> <td>    3.470</td> <td> 0.001</td> <td>    0.034</td> <td>    0.123</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>challenging</th>           <td>    0.4143</td> <td>    0.028</td> <td>   14.981</td> <td> 0.000</td> <td>    0.360</td> <td>    0.469</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>informative</th>           <td>    0.4404</td> <td>    0.025</td> <td>   17.848</td> <td> 0.000</td> <td>    0.392</td> <td>    0.489</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mysterious</th>            <td>    0.1826</td> <td>    0.023</td> <td>    8.065</td> <td> 0.000</td> <td>    0.138</td> <td>    0.227</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>dark</th>                  <td>    0.0376</td> <td>    0.021</td> <td>    1.805</td> <td> 0.071</td> <td>   -0.003</td> <td>    0.078</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>author_count</th>          <td>    0.0022</td> <td>    0.000</td> <td>    4.571</td> <td> 0.000</td> <td>    0.001</td> <td>    0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>author_stars</th>          <td>    0.0094</td> <td>    0.003</td> <td>    3.366</td> <td> 0.001</td> <td>    0.004</td> <td>    0.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Nonfiction</th>            <td>    0.1932</td> <td>    0.018</td> <td>   10.861</td> <td> 0.000</td> <td>    0.158</td> <td>    0.228</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Literary</th>              <td>    0.0898</td> <td>    0.022</td> <td>    4.018</td> <td> 0.000</td> <td>    0.046</td> <td>    0.134</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Fantasy</th>               <td>   -0.0254</td> <td>    0.015</td> <td>   -1.702</td> <td> 0.089</td> <td>   -0.055</td> <td>    0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Crime</th>                 <td>   -0.0404</td> <td>    0.025</td> <td>   -1.624</td> <td> 0.104</td> <td>   -0.089</td> <td>    0.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Social</th>                <td>    0.0218</td> <td>    0.012</td> <td>    1.744</td> <td> 0.081</td> <td>   -0.003</td> <td>    0.046</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Children</th>              <td>   -0.0353</td> <td>    0.008</td> <td>   -4.172</td> <td> 0.000</td> <td>   -0.052</td> <td>   -0.019</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Romans</th>                <td>   -0.0419</td> <td>    0.010</td> <td>   -4.262</td> <td> 0.000</td> <td>   -0.061</td> <td>   -0.023</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Realism</th>               <td>   -0.0461</td> <td>    0.009</td> <td>   -5.199</td> <td> 0.000</td> <td>   -0.063</td> <td>   -0.029</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Crime_mix</th>             <td>    0.1090</td> <td>    0.051</td> <td>    2.119</td> <td> 0.034</td> <td>    0.008</td> <td>    0.210</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Fantasy_adventurous</th>   <td>    0.1196</td> <td>    0.027</td> <td>    4.372</td> <td> 0.000</td> <td>    0.066</td> <td>    0.173</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Fiction_character</th>     <td>   -0.0789</td> <td>    0.021</td> <td>   -3.748</td> <td> 0.000</td> <td>   -0.120</td> <td>   -0.038</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Fiction_inspiring</th>     <td>    0.2987</td> <td>    0.056</td> <td>    5.296</td> <td> 0.000</td> <td>    0.188</td> <td>    0.409</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Fiction_mix</th>           <td>    0.1621</td> <td>    0.033</td> <td>    4.843</td> <td> 0.000</td> <td>    0.096</td> <td>    0.228</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Fiction_plot</th>          <td>   -0.1263</td> <td>    0.034</td> <td>   -3.672</td> <td> 0.000</td> <td>   -0.194</td> <td>   -0.059</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Literary_author_stars</th> <td>    0.0058</td> <td>    0.003</td> <td>    1.714</td> <td> 0.087</td> <td>   -0.001</td> <td>    0.012</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Literary_emotional</th>    <td>    0.0790</td> <td>    0.027</td> <td>    2.921</td> <td> 0.003</td> <td>    0.026</td> <td>    0.132</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Literary_inspiring</th>    <td>   -0.1846</td> <td>    0.045</td> <td>   -4.136</td> <td> 0.000</td> <td>   -0.272</td> <td>   -0.097</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Literary_mix</th>          <td>   -0.2738</td> <td>    0.039</td> <td>   -7.049</td> <td> 0.000</td> <td>   -0.350</td> <td>   -0.198</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Literary_mysterious</th>   <td>    0.0472</td> <td>    0.028</td> <td>    1.681</td> <td> 0.093</td> <td>   -0.008</td> <td>    0.102</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Nonfiction_hopeful</th>    <td>   -0.1377</td> <td>    0.060</td> <td>   -2.287</td> <td> 0.022</td> <td>   -0.256</td> <td>   -0.020</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Social_author_stars</th>   <td>    0.0104</td> <td>    0.004</td> <td>    2.696</td> <td> 0.007</td> <td>    0.003</td> <td>    0.018</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>series_adventurous</th>    <td>    0.0824</td> <td>    0.023</td> <td>    3.526</td> <td> 0.000</td> <td>    0.037</td> <td>    0.128</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>series_author_stars</th>   <td>    0.0133</td> <td>    0.003</td> <td>    3.874</td> <td> 0.000</td> <td>    0.007</td> <td>    0.020</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>series_emotional</th>      <td>   -0.0946</td> <td>    0.027</td> <td>   -3.562</td> <td> 0.000</td> <td>   -0.147</td> <td>   -0.043</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lighthearted_funny</th>    <td>    0.0520</td> <td>    0.013</td> <td>    3.936</td> <td> 0.000</td> <td>    0.026</td> <td>    0.078</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lighthearted_relaxing</th> <td>    0.2416</td> <td>    0.023</td> <td>   10.400</td> <td> 0.000</td> <td>    0.196</td> <td>    0.287</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>220.368</td> <th>  Durbin-Watson:     </th> <td>   2.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 358.485</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.350</td>  <th>  Prob(JB):          </th> <td>1.43e-78</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.031</td>  <th>  Cond. No.          </th> <td>1.16e+16</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 3.36e-20. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}          &      stars       & \\textbf{  R-squared:         } &     0.491   \\\\\n",
       "\\textbf{Model:}                  &       OLS        & \\textbf{  Adj. R-squared:    } &     0.487   \\\\\n",
       "\\textbf{Method:}                 &  Least Squares   & \\textbf{  F-statistic:       } &     123.4   \\\\\n",
       "\\textbf{Date:}                   & Sat, 11 May 2024 & \\textbf{  Prob (F-statistic):} &     0.00    \\\\\n",
       "\\textbf{Time:}                   &     19:38:32     & \\textbf{  Log-Likelihood:    } &    656.18   \\\\\n",
       "\\textbf{No. Observations:}       &        5544      & \\textbf{  AIC:               } &    -1224.   \\\\\n",
       "\\textbf{Df Residuals:}           &        5500      & \\textbf{  BIC:               } &    -933.1   \\\\\n",
       "\\textbf{Df Model:}               &          43      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}        &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                                 & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept}               &       3.0791  &        0.031     &   100.632  &         0.000        &        3.019    &        3.139     \\\\\n",
       "\\textbf{index\\_0}                &   -1.221e-05  &     1.48e-06     &    -8.257  &         0.000        &    -1.51e-05    &    -9.31e-06     \\\\\n",
       "\\textbf{pages}                   &   -2.215e-05  &     2.18e-05     &    -1.014  &         0.311        &     -6.5e-05    &     2.07e-05     \\\\\n",
       "\\textbf{reviews}                 &    7.955e-07  &     1.21e-07     &     6.571  &         0.000        &     5.58e-07    &     1.03e-06     \\\\\n",
       "\\textbf{series}                  &       0.0448  &        0.019     &     2.323  &         0.020        &        0.007    &        0.083     \\\\\n",
       "\\textbf{funny}                   &       0.3396  &        0.025     &    13.849  &         0.000        &        0.291    &        0.388     \\\\\n",
       "\\textbf{lighthearted}            &      -0.2875  &        0.033     &    -8.600  &         0.000        &       -0.353    &       -0.222     \\\\\n",
       "\\textbf{emotional}               &       0.3679  &        0.031     &    11.953  &         0.000        &        0.308    &        0.428     \\\\\n",
       "\\textbf{hopeful}                 &       0.2933  &        0.041     &     7.178  &         0.000        &        0.213    &        0.373     \\\\\n",
       "\\textbf{inspiring}               &       0.2422  &        0.048     &     5.041  &         0.000        &        0.148    &        0.336     \\\\\n",
       "\\textbf{relaxing}                &       0.5291  &        0.052     &    10.261  &         0.000        &        0.428    &        0.630     \\\\\n",
       "\\textbf{tense}                   &       0.3015  &        0.031     &     9.706  &         0.000        &        0.241    &        0.362     \\\\\n",
       "\\textbf{sad}                     &       0.1920  &        0.029     &     6.692  &         0.000        &        0.136    &        0.248     \\\\\n",
       "\\textbf{adventurous}             &       0.0783  &        0.023     &     3.470  &         0.001        &        0.034    &        0.123     \\\\\n",
       "\\textbf{challenging}             &       0.4143  &        0.028     &    14.981  &         0.000        &        0.360    &        0.469     \\\\\n",
       "\\textbf{informative}             &       0.4404  &        0.025     &    17.848  &         0.000        &        0.392    &        0.489     \\\\\n",
       "\\textbf{mysterious}              &       0.1826  &        0.023     &     8.065  &         0.000        &        0.138    &        0.227     \\\\\n",
       "\\textbf{dark}                    &       0.0376  &        0.021     &     1.805  &         0.071        &       -0.003    &        0.078     \\\\\n",
       "\\textbf{author\\_count}           &       0.0022  &        0.000     &     4.571  &         0.000        &        0.001    &        0.003     \\\\\n",
       "\\textbf{author\\_stars}           &       0.0094  &        0.003     &     3.366  &         0.001        &        0.004    &        0.015     \\\\\n",
       "\\textbf{Nonfiction}              &       0.1932  &        0.018     &    10.861  &         0.000        &        0.158    &        0.228     \\\\\n",
       "\\textbf{Literary}                &       0.0898  &        0.022     &     4.018  &         0.000        &        0.046    &        0.134     \\\\\n",
       "\\textbf{Fantasy}                 &      -0.0254  &        0.015     &    -1.702  &         0.089        &       -0.055    &        0.004     \\\\\n",
       "\\textbf{Crime}                   &      -0.0404  &        0.025     &    -1.624  &         0.104        &       -0.089    &        0.008     \\\\\n",
       "\\textbf{Social}                  &       0.0218  &        0.012     &     1.744  &         0.081        &       -0.003    &        0.046     \\\\\n",
       "\\textbf{Children}                &      -0.0353  &        0.008     &    -4.172  &         0.000        &       -0.052    &       -0.019     \\\\\n",
       "\\textbf{Romans}                  &      -0.0419  &        0.010     &    -4.262  &         0.000        &       -0.061    &       -0.023     \\\\\n",
       "\\textbf{Realism}                 &      -0.0461  &        0.009     &    -5.199  &         0.000        &       -0.063    &       -0.029     \\\\\n",
       "\\textbf{Crime\\_mix}              &       0.1090  &        0.051     &     2.119  &         0.034        &        0.008    &        0.210     \\\\\n",
       "\\textbf{Fantasy\\_adventurous}    &       0.1196  &        0.027     &     4.372  &         0.000        &        0.066    &        0.173     \\\\\n",
       "\\textbf{Fiction\\_character}      &      -0.0789  &        0.021     &    -3.748  &         0.000        &       -0.120    &       -0.038     \\\\\n",
       "\\textbf{Fiction\\_inspiring}      &       0.2987  &        0.056     &     5.296  &         0.000        &        0.188    &        0.409     \\\\\n",
       "\\textbf{Fiction\\_mix}            &       0.1621  &        0.033     &     4.843  &         0.000        &        0.096    &        0.228     \\\\\n",
       "\\textbf{Fiction\\_plot}           &      -0.1263  &        0.034     &    -3.672  &         0.000        &       -0.194    &       -0.059     \\\\\n",
       "\\textbf{Literary\\_author\\_stars} &       0.0058  &        0.003     &     1.714  &         0.087        &       -0.001    &        0.012     \\\\\n",
       "\\textbf{Literary\\_emotional}     &       0.0790  &        0.027     &     2.921  &         0.003        &        0.026    &        0.132     \\\\\n",
       "\\textbf{Literary\\_inspiring}     &      -0.1846  &        0.045     &    -4.136  &         0.000        &       -0.272    &       -0.097     \\\\\n",
       "\\textbf{Literary\\_mix}           &      -0.2738  &        0.039     &    -7.049  &         0.000        &       -0.350    &       -0.198     \\\\\n",
       "\\textbf{Literary\\_mysterious}    &       0.0472  &        0.028     &     1.681  &         0.093        &       -0.008    &        0.102     \\\\\n",
       "\\textbf{Nonfiction\\_hopeful}     &      -0.1377  &        0.060     &    -2.287  &         0.022        &       -0.256    &       -0.020     \\\\\n",
       "\\textbf{Social\\_author\\_stars}   &       0.0104  &        0.004     &     2.696  &         0.007        &        0.003    &        0.018     \\\\\n",
       "\\textbf{series\\_adventurous}     &       0.0824  &        0.023     &     3.526  &         0.000        &        0.037    &        0.128     \\\\\n",
       "\\textbf{series\\_author\\_stars}   &       0.0133  &        0.003     &     3.874  &         0.000        &        0.007    &        0.020     \\\\\n",
       "\\textbf{series\\_emotional}       &      -0.0946  &        0.027     &    -3.562  &         0.000        &       -0.147    &       -0.043     \\\\\n",
       "\\textbf{lighthearted\\_funny}     &       0.0520  &        0.013     &     3.936  &         0.000        &        0.026    &        0.078     \\\\\n",
       "\\textbf{lighthearted\\_relaxing}  &       0.2416  &        0.023     &    10.400  &         0.000        &        0.196    &        0.287     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 220.368 & \\textbf{  Durbin-Watson:     } &    2.008  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } &  358.485  \\\\\n",
       "\\textbf{Skew:}          &  -0.350 & \\textbf{  Prob(JB):          } & 1.43e-78  \\\\\n",
       "\\textbf{Kurtosis:}      &   4.031 & \\textbf{  Cond. No.          } & 1.16e+16  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The smallest eigenvalue is 3.36e-20. This might indicate that there are \\newline\n",
       " strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  stars   R-squared:                       0.491\n",
       "Model:                            OLS   Adj. R-squared:                  0.487\n",
       "Method:                 Least Squares   F-statistic:                     123.4\n",
       "Date:                Sat, 11 May 2024   Prob (F-statistic):               0.00\n",
       "Time:                        19:38:32   Log-Likelihood:                 656.18\n",
       "No. Observations:                5544   AIC:                            -1224.\n",
       "Df Residuals:                    5500   BIC:                            -933.1\n",
       "Df Model:                          43                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=========================================================================================\n",
       "                            coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-----------------------------------------------------------------------------------------\n",
       "Intercept                 3.0791      0.031    100.632      0.000       3.019       3.139\n",
       "index_0               -1.221e-05   1.48e-06     -8.257      0.000   -1.51e-05   -9.31e-06\n",
       "pages                 -2.215e-05   2.18e-05     -1.014      0.311    -6.5e-05    2.07e-05\n",
       "reviews                7.955e-07   1.21e-07      6.571      0.000    5.58e-07    1.03e-06\n",
       "series                    0.0448      0.019      2.323      0.020       0.007       0.083\n",
       "funny                     0.3396      0.025     13.849      0.000       0.291       0.388\n",
       "lighthearted             -0.2875      0.033     -8.600      0.000      -0.353      -0.222\n",
       "emotional                 0.3679      0.031     11.953      0.000       0.308       0.428\n",
       "hopeful                   0.2933      0.041      7.178      0.000       0.213       0.373\n",
       "inspiring                 0.2422      0.048      5.041      0.000       0.148       0.336\n",
       "relaxing                  0.5291      0.052     10.261      0.000       0.428       0.630\n",
       "tense                     0.3015      0.031      9.706      0.000       0.241       0.362\n",
       "sad                       0.1920      0.029      6.692      0.000       0.136       0.248\n",
       "adventurous               0.0783      0.023      3.470      0.001       0.034       0.123\n",
       "challenging               0.4143      0.028     14.981      0.000       0.360       0.469\n",
       "informative               0.4404      0.025     17.848      0.000       0.392       0.489\n",
       "mysterious                0.1826      0.023      8.065      0.000       0.138       0.227\n",
       "dark                      0.0376      0.021      1.805      0.071      -0.003       0.078\n",
       "author_count              0.0022      0.000      4.571      0.000       0.001       0.003\n",
       "author_stars              0.0094      0.003      3.366      0.001       0.004       0.015\n",
       "Nonfiction                0.1932      0.018     10.861      0.000       0.158       0.228\n",
       "Literary                  0.0898      0.022      4.018      0.000       0.046       0.134\n",
       "Fantasy                  -0.0254      0.015     -1.702      0.089      -0.055       0.004\n",
       "Crime                    -0.0404      0.025     -1.624      0.104      -0.089       0.008\n",
       "Social                    0.0218      0.012      1.744      0.081      -0.003       0.046\n",
       "Children                 -0.0353      0.008     -4.172      0.000      -0.052      -0.019\n",
       "Romans                   -0.0419      0.010     -4.262      0.000      -0.061      -0.023\n",
       "Realism                  -0.0461      0.009     -5.199      0.000      -0.063      -0.029\n",
       "Crime_mix                 0.1090      0.051      2.119      0.034       0.008       0.210\n",
       "Fantasy_adventurous       0.1196      0.027      4.372      0.000       0.066       0.173\n",
       "Fiction_character        -0.0789      0.021     -3.748      0.000      -0.120      -0.038\n",
       "Fiction_inspiring         0.2987      0.056      5.296      0.000       0.188       0.409\n",
       "Fiction_mix               0.1621      0.033      4.843      0.000       0.096       0.228\n",
       "Fiction_plot             -0.1263      0.034     -3.672      0.000      -0.194      -0.059\n",
       "Literary_author_stars     0.0058      0.003      1.714      0.087      -0.001       0.012\n",
       "Literary_emotional        0.0790      0.027      2.921      0.003       0.026       0.132\n",
       "Literary_inspiring       -0.1846      0.045     -4.136      0.000      -0.272      -0.097\n",
       "Literary_mix             -0.2738      0.039     -7.049      0.000      -0.350      -0.198\n",
       "Literary_mysterious       0.0472      0.028      1.681      0.093      -0.008       0.102\n",
       "Nonfiction_hopeful       -0.1377      0.060     -2.287      0.022      -0.256      -0.020\n",
       "Social_author_stars       0.0104      0.004      2.696      0.007       0.003       0.018\n",
       "series_adventurous        0.0824      0.023      3.526      0.000       0.037       0.128\n",
       "series_author_stars       0.0133      0.003      3.874      0.000       0.007       0.020\n",
       "series_emotional         -0.0946      0.027     -3.562      0.000      -0.147      -0.043\n",
       "lighthearted_funny        0.0520      0.013      3.936      0.000       0.026       0.078\n",
       "lighthearted_relaxing     0.2416      0.023     10.400      0.000       0.196       0.287\n",
       "==============================================================================\n",
       "Omnibus:                      220.368   Durbin-Watson:                   2.008\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              358.485\n",
       "Skew:                          -0.350   Prob(JB):                     1.43e-78\n",
       "Kurtosis:                       4.031   Cond. No.                     1.16e+16\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 3.36e-20. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wzor = 'stars~' + '+'.join(features_interactions)\n",
    "mod = smf.ols(formula = wzor, data = train_data_interactions)\n",
    "res = mod.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a769b4b",
   "metadata": {},
   "source": [
    "Reszta zmiennych w modelu jest istotna statystycznie"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7052a1",
   "metadata": {},
   "source": [
    "Większość zmiennych wpływa pozytywnie na zmienną objaśnianą oprócz: pages, Fantasy, Crime, Children, Romans, Realism, Fiction_character, Fiction_plot, Literary_inspiring, Literary_mix, Nonfiction_hopeful, series_emotional i lighthearted_funny.\n",
    "Jednak zmienna Fantasy jest również obecna w interakcji z adventurous, a zmienna Crime w interkacji z mix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6ab7a5",
   "metadata": {},
   "source": [
    "Można wyciągnąc wniosek, że dobrze są oceniane ksiązki Fantasy jedynie, gdy mają wysoki wskaźnik przygodowości, a Crime, gdy mają mix postaci i fabuły. Gorzej są oceniane książki z genre fiction jedynie skupione na postaciach lub fabule, a nie mixie. Dodatkowo kategorie Children, Romans i Realism mają średnio niższe oceny. Również mniej lubione są książki z kategorii Literary, które są inspirujące lub mają mix fabułu i postaci, także książki Nonfiction, które są pełne nadziei i emocjonalne serie.\n",
    "Zaskakująco ludzie również gorzej oceniają książki, które są śmieszne jeśli są beztroskie, możliwe, że preferowane są książki, które mają tzw. dark humor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08820671",
   "metadata": {},
   "source": [
    "## Zapisanie modelu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f86055",
   "metadata": {},
   "source": [
    "Nie usuwamy zmiennych z modelu, gdyż w tym przypadku OLS zmniejszyłoby to zdolność predykcyjną."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7017ad2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 0.21124\n",
      "Test RMSE: 0.21884\n"
     ]
    }
   ],
   "source": [
    "data_interactions=pd.read_csv(\"../data/data_add.csv\")\n",
    "data_interactions=data_interactions.drop(columns=['Unnamed: 0'])\n",
    "features_interactions=data_interactions.columns.tolist()\n",
    "features_interactions.remove('stars')\n",
    "data_interactions['lighthearted_relaxing']=data_interactions['lighthearted']+data_interactions['relaxing']\n",
    "data_interactions['lighthearted_funny']=data_interactions['lighthearted']+data_interactions['funny']\n",
    "train_data_interactions, test_data_interactions = train_test_split(data_interactions, test_size=0.2, random_state=SEED)\n",
    "test_indices = test_data_interactions.index\n",
    "features_interactions.append('lighthearted_funny')\n",
    "features_interactions.append('lighthearted_relaxing')\n",
    "target='stars'\n",
    "#Ewaluacja modelu\n",
    "model = LinearRegression(fit_intercept=True)\n",
    "train_results, test_results, y_test_pred = evaluation(train_data_interactions[features_interactions], train_data_interactions[target], test_data_interactions[features_interactions], test_data_interactions[target], model)\n",
    "print(\"Train RMSE: {}\".format(round(train_results, 5)))\n",
    "print(\"Test RMSE: {}\".format(round(test_results, 5)))\n",
    "\n",
    "#Zapisanie modelu\n",
    "modelOLS = {\n",
    "    \"name\": \"OLS\",\n",
    "    \"trainResults\": train_results,\n",
    "    \"testResults\": test_results,\n",
    "    \"predictions\": y_test_pred,\n",
    "    \"indices\": test_indices,\n",
    "}\n",
    "\n",
    "with open(\"../data/model_OLS.p\", \"wb\") as fp:\n",
    "    pickle.dump(modelOLS, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26bf87a",
   "metadata": {},
   "source": [
    "## Podsumowanie"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3586deb",
   "metadata": {},
   "source": [
    "$\\text{Najlepsze wyniki walidacji krzyżowej uzyskano dla modelu bazującego na danych z interakcjami, bez transformacji zmiennych.}$<p>\n",
    "$\\text{Wyniki na zbiorze treningowym (RMSE): 0.21124}$<p>\n",
    "$\\text{Wyniki na zbiorze testowym (RMSE): 0.21884}$<p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
